<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Make More Machines - science</title><link href="http://www.agapow.net/" rel="alternate"></link><link href="http://www.agapow.net/feeds/science.atom.xml" rel="self"></link><id>http://www.agapow.net/</id><updated>2018-11-19T12:00:00+00:00</updated><entry><title>Have you looked on Evoldir?</title><link href="http://www.agapow.net/science/academia/have-you-looked-on-evoldir/" rel="alternate"></link><published>2018-11-19T12:00:00+00:00</published><updated>2018-11-19T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2018-11-19:/science/academia/have-you-looked-on-evoldir/</id><summary type="html">&lt;p&gt;For those who don’t know, EvolDir is a worldwide mailing list on evolutionary biology that has been running since approximately forever. Everyone who works even vaguely in the area of evolution subscribes to it. Every day It typically carries several posts on conferences, book announcements, funding opportunities and job …&lt;/p&gt;</summary><content type="html">&lt;p&gt;For those who don’t know, EvolDir is a worldwide mailing list on evolutionary biology that has been running since approximately forever. Everyone who works even vaguely in the area of evolution subscribes to it. Every day It typically carries several posts on conferences, book announcements, funding opportunities and job ads.&lt;/p&gt;
&lt;p&gt;I first signed up to EvolDir 20 years ago, looking for a postdoc position. Despite shifting fields and disciplines, I stayed subscribed because because you never knew what might turn up, because for 20 years I was looking for the next job. When I secured a new position (invariably on contract, temporary), I started thinking about the next position. When my contract was extended or topped up, I just shifted the time window for which I thought “what next?”&lt;/p&gt;
&lt;p&gt;A few months ago, I unsubscribed from EvolDir.  Shortly I’ll start a new job, a permanent one. For the first time in 20 years, I will not be looking for a job.&lt;/p&gt;
&lt;p&gt;This is an attempt to distill that experience, a loose set of reflections and thoughts on the academia job search. There’s no clear take home message, and I’m unsure if I can give any advice or recommendations. I think my experience has been fairly typical, at least for the life and biomedical sciences, but I can only write what happened to me and what I saw. I made good and bad choices, I was helped and hindered, I was lucky and unlucky.&lt;/p&gt;
&lt;p&gt;I won't mention specific names or institutions. In many cases they’re not difficult to work out but my attention is on the overall scheme and trends not specific instances.&lt;/p&gt;
&lt;p&gt;I have some (many) other thoughts on the evolution of the university but will save them for another post.&lt;/p&gt;
&lt;div class="section" id="useless-advice-and-survivorship-bias"&gt;
&lt;h2&gt;Useless advice and survivorship bias&lt;/h2&gt;
&lt;p&gt;At first blush, it’s astonishing how much advice I received which was dated, irrelevant, bad, well-meaning but pointless, and sometimes bordered on rank superstition:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Faced with an impending end of contract, academics would frequently advise me to “apply for a grant”, failing to consider (a) grants required a permanent member of staff heading them, (b) the success rate even for established academics was poor, and (c) even if successful, it would take 12-18 months for the money to arrive.&lt;/li&gt;
&lt;li&gt;For a while I used to ask senior academics for advice or job pointers. I lost count of the number that would frown and darkly mutter something like “Hmmm, it's tough …” before brightening up and quipping “Never mind, I’m sure something will turn up!” then consider the discussion resolved.&lt;/li&gt;
&lt;li&gt;Likewise, a large number would advise me me to consult job ads or mailing lists (“Have you looked on EvolDir?”), like it was some sort of hidden power move I might not have otherwise considered.&lt;/li&gt;
&lt;li&gt;Career and funding workshops were replete with advice that “I thought I’d never get a job but look at me now” or “good work will be funded”, ignoring that if they hadn’t got that job or that grant, they wouldn’t be in front of an audience talking about it.&lt;/li&gt;
&lt;li&gt;Several candidates for a certain fellowship swore that it was only awarded on your second attempt as the panel wanted to see if you “were serious”. In reality, the panel itself was ignorant of this tradition.&lt;/li&gt;
&lt;li&gt;&amp;quot;I never look past the first page of a resume ... You should include all your education, jobs, papers, teaching experience, hobbies, a proposed research project ...&amp;quot;&lt;/li&gt;
&lt;li&gt;A commonly repeated piece of advice was to get some teaching on your resume, because committees would be looking for that. In reality, committees (at least in the UK) seemed to be unconcerned with teaching and regularly hired lecturers with little or no experience. But the advice-givers did get you to teach their courses …&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the light of such useless advice, you could get bitter but perhaps it’s no surprise. Permanent academics have little or no insight on how or why they got their jobs, often having obtained them years ago in a different environment or simply didn't understand the complex melange of forces and chance that secured them a position. This is not to say that the hiring process is entirely random, but it is complex, inconsistent and unexamined. In the words of William Goldman “no one knows nothing”.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="most-positions-dont-exist"&gt;
&lt;h2&gt;Most positions don’t exist&lt;/h2&gt;
&lt;p&gt;Once, I applied for a job at a department of Classic U. which is in a neighbouring country. Oddly and archaically, they asked for hardcopy: a physical cover letter, a CV and a form to be supplied in triplicate and mailed in.&lt;/p&gt;
&lt;p&gt;I posted my application on a Monday.&lt;/p&gt;
&lt;p&gt;I received my rejection letter on the Wednesday.&lt;/p&gt;
&lt;p&gt;I like to think the same postman carried them in and out on a single visit.&lt;/p&gt;
&lt;p&gt;A few months later at a conference, I got into a conversation with someone from that department. “We really could use people like you,” he enthused. “You should apply for a job with us.”&lt;/p&gt;
&lt;p&gt;I explained that I had.&lt;/p&gt;
&lt;p&gt;He blinked when I described the position. “Oh yes, but that wasn’t a real job. It was earmarked for someone but HR forced us to advertise it. Anyway, you should apply for a job with us ...”&lt;/p&gt;
&lt;p&gt;Hard experience like this and from the other side of the hiring process has convinced me that most jobs don’t exist as advertised. They’re earmarked for someone, the funding isn’t secure, they’re advertised in anticipation, a decision is made behind the scenes that fellowships won’t be awarded that year, the advert doesn’t describe what they’re actually looking for, they’ll be overwhelmed by applications so your application won't even get looked at, the selection process will get pushed back, the actual salary will not be as advertised ...&lt;/p&gt;
&lt;p&gt;I estimate that the fraction of non-existent jobs is about 1/2. This insight lead me to develop a Job Search Drake Equation which assessed the chances of being offered a job I wanted based on compounding circumstances. (Chance of the job actually taking applicants, chance of being shortlisted for interview, chance of being made an offer …) It resulted in the grim maths that to have 50% chance of being offered a job, I needed to apply for 11 positions. To have 90% chance, I had to apply for 23 ...&lt;/p&gt;
&lt;p&gt;It’s poor odds but it also perversely heartening. Little of the process is in your control. You cannot control the fraction of real jobs or whether you are shortlisted or offered a job, beyond applying or performing competently.  Those are controlled by other people and circumstances and are not your fault. You cannot do anything about them. You may be personally brilliant and wonderful and you're still going to fail. You going to fail more times than you succeed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="hustling-costs-everyone"&gt;
&lt;h2&gt;Hustling costs everyone&lt;/h2&gt;
&lt;p&gt;I was once talking abuot opportunities with a more senior - albeit un-tenured - colleague when they stopped and sighed. “I’m so sick and tired of hustling, &amp;quot; he said. &amp;quot;Can’t I just do my job?”&lt;/p&gt;
&lt;p&gt;During one position, I spent three months doing nothing but searching and applying for jobs. I did no research, no actual work. It embarrassed then and still does now but I made a series of flimsy excuses to my increasingly angry line manager why research projects weren’t progressing. It's no excuse, but I was staring down the imminent end of my funding. Yes, a paper might have helped my employment prospects ... next year. I was worried about being employed in three months, cognizant that it would a lot harder to find work if I was out of work.&lt;/p&gt;
&lt;p&gt;During another extended bout of job searching, over 18 months I sent off 100 applications. Each of those applications needed a proposed program of work, a cover letter as to why I was the perfect applicant (and why I’d always dreamed of working at Institute X), a customised CV, forms, statements of teaching philosophy … Even if you suppose each application took just a day to prepare, that’s another 3 months I took from my then employer.&lt;/p&gt;
&lt;p&gt;(Incidentally, only 16 of those applications are acknowledged. Only 1 resulted in an interview. No job offer ensued.)&lt;/p&gt;
&lt;p&gt;This sort of poor return on time spent is &lt;a class="reference external" href="https://chroniclevitae.com/news/1775-i-found-a-tenure-track-job-here-s-what-it-took"&gt;fairly typical&lt;/a&gt;. The academic job search is grossly inefficient, for job seeker, for their current employer and for the employer offering jobs. Precarity leads to staff spending a large amount of their time hustling: hustling for the next position, hustling to raise their profile, hustling to escape the hustle. This &amp;quot;robs&amp;quot; their current employer and results in potential employers being bombarded with applications. Even tenured staff are keenly aware that they’re only as good as their last grant. One distinguished and tenured academician confessed to me that if he failed to keep large money coming in “the university will find a way to get rid of me.&amp;quot;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="things-are-better-and-worse-than-they-were-before"&gt;
&lt;h2&gt;Things are better (and worse) than they were before&lt;/h2&gt;
&lt;p&gt;It used to be that those who departed the university for other fields were spoken of as if they they had died: “Oh, they left science.” Part of it was, no doubt, was from lack of obvious alternatives. (What do you do with a PhD in French medieval literature or hymenopteran social systems?) But part was also due to a pervasive feel that leaving was failure, unthinkable, excommunication. Leaving was death.&lt;/p&gt;
&lt;p&gt;Thankfully, the intervening years have seen a relaxing in this attitude, I posit due to a number of trends:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The odds have got so bad that “alternatives” had to be acknowledged. As someone said, if less than 1% of PhDs are making it to tenure level, a permanent academic career is already your Plan B.&lt;/li&gt;
&lt;li&gt;The opportunities for STEM graduates have grown. This was always the case for programmers and engineers, but broad opportunities for other graduates (genomics, pharma, data science) have grown.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Leaving is no longer unthinkable. For STEM graduates at least, universities are now talking openly of the “brain drain” and what to do about it.&lt;/p&gt;
&lt;p&gt;Conversely, the internal bars have been raised and the rewards less appealing. Where it was accepted that PhD students would sometimes graduate without any publications, now they are expected to have to have multiple high-standard publications. It has even pervaded down to the pre-doctoral level. Applicants for PhD positions are expected to have a masters already and are sometimes asked what publications they have. University holidays are full of summer schools with “networking opportunities”. All of this works to crowd out those from the working class or with an atypical background. I have a creeping fear that if I was starting over now, I’d unable to compete.&lt;/p&gt;
&lt;p&gt;Even if you make it, you haven't made it. While lectureships used to be the recognised prize, these have increasingly become contract positions themselves. In effect, they are post-docs with teaching and admin responsibilities. Meanwhile wages have been stagnant. One second-tier London university advertises for lecturers with a demanding set of requirements but lists a salary that would have their new employee living in shared accommodation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="if-i-had-to-do-it-all-over-again"&gt;
&lt;h2&gt;If I had to do it all over again&lt;/h2&gt;
&lt;p&gt;I’m not sure what I would do. There is a lot to be said for experience, for working with the life you have, but the grotesque levels of inefficiency, stress and chaos in the academic career give me pause. Was it a good use of my life to spend so much of it not in training, not even in paying dues, but in preparing, waiting for my turn, waiting for lightning to strike? Is this the best we can do? I don’t have a comfortable answer.&lt;/p&gt;
&lt;/div&gt;
</content><category term="science"></category><category term="academia"></category><category term="career"></category></entry><entry><title>Tentacles vs arms</title><link href="http://www.agapow.net/science/misc/tentacles/" rel="alternate"></link><published>2018-02-20T00:00:00+00:00</published><updated>2018-02-20T00:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2018-02-20:/science/misc/tentacles/</id><summary type="html">&lt;p&gt;You might have come across confusing statements like &amp;quot;octopuses have arms, squids have tentacles&amp;quot; and wondered what's the difference. I did and here's the (unsatisfactory) answer.&lt;/p&gt;
&lt;p&gt;Cephalopods (squid, octopus, nautilus and a number of other aquatic creatures, which are a class of mollusc) have a number of muscular &amp;quot;limbs&amp;quot;. Traditionally …&lt;/p&gt;</summary><content type="html">&lt;p&gt;You might have come across confusing statements like &amp;quot;octopuses have arms, squids have tentacles&amp;quot; and wondered what's the difference. I did and here's the (unsatisfactory) answer.&lt;/p&gt;
&lt;p&gt;Cephalopods (squid, octopus, nautilus and a number of other aquatic creatures, which are a class of mollusc) have a number of muscular &amp;quot;limbs&amp;quot;. Traditionally experts make the distinction between arms and tentacles. For example:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Octopuses have eight arms and no tentacles&lt;/li&gt;
&lt;li&gt;Squid and cuttlefish have eight arms and two tentacles&lt;/li&gt;
&lt;li&gt;Nautiluses have around 90 (suckerless) tentacles&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What's the difference?&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Arms occur around the mouth&lt;/li&gt;
&lt;li&gt;Arms have suckers all the way along, while tentacles have them only at the tips.&lt;/li&gt;
&lt;li&gt;Arms have finer control&lt;/li&gt;
&lt;li&gt;Tentacles have an elongated shape and are longer than arms&lt;/li&gt;
&lt;li&gt;Tentacles are mainly used to catch prey with the arms assisting and grasping&lt;/li&gt;
&lt;li&gt;The internal structure of tentacles and arms differ.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Easy? Let's confuse the issue:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Variation and anomalies are common within cephalopods, including missing or extra arms, forking limbs, etc.&lt;/li&gt;
&lt;li&gt;The tentacles of squid and cuttlefish appear to be evolutionarily derived from arms&lt;/li&gt;
&lt;li&gt;It's not clear (to me anyway) that what's is called a tentacle in a nautilus is anything to do with a tentacle on a squid.&lt;/li&gt;
&lt;li&gt;It's also unclear that a cephalopod &amp;quot;arm&amp;quot; is in any way related to the arms or limbs found on better known animals like mammals.&lt;/li&gt;
&lt;li&gt;Biologists are prone to getting lazy and using the words interchangeably.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="also-see"&gt;
&lt;h2&gt;Also see&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://en.wikipedia.org/wiki/Cephalopod_limb"&gt;http://en.wikipedia.org/wiki/Cephalopod_limb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.differencebetween.com/difference-between-tentacles-and-vs-arms/"&gt;http://www.differencebetween.com/difference-between-tentacles-and-vs-arms/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://wikidiff.com/arm/tentacle"&gt;http://wikidiff.com/arm/tentacle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="biology"></category></entry><entry><title>Why bioinformaticians don't get no respect</title><link href="http://www.agapow.net/science/computational-biology/no-respect/" rel="alternate"></link><published>2017-06-11T12:00:00+01:00</published><updated>2017-06-11T12:00:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2017-06-11:/science/computational-biology/no-respect/</id><summary type="html">&lt;p&gt;It's a common cry amongst working bioinformaticians that they're unappreciated, undervalued and generally &amp;quot;get no respect&amp;quot;. While people love to complain, from discussions with peers and colleagues, the same stories come up again and again:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Not being consulted when projects are planned&lt;/li&gt;
&lt;li&gt;Technical advice and results not taken seriously&lt;/li&gt;
&lt;li&gt;Being …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;It's a common cry amongst working bioinformaticians that they're unappreciated, undervalued and generally &amp;quot;get no respect&amp;quot;. While people love to complain, from discussions with peers and colleagues, the same stories come up again and again:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Not being consulted when projects are planned&lt;/li&gt;
&lt;li&gt;Technical advice and results not taken seriously&lt;/li&gt;
&lt;li&gt;Being last in line when resources are allocated&lt;/li&gt;
&lt;li&gt;Doing a wide array of highly technical tasks (e.g. genome assembly, biostatistics, integrative biology), yet still be referred as &amp;quot;the database manager&amp;quot;&lt;/li&gt;
&lt;li&gt;Being expected to produce results from incomplete, fragmented and statistically tiny samples&lt;/li&gt;
&lt;li&gt;Assigned a poor position in author lists and sometimes omitted entirely&lt;/li&gt;
&lt;li&gt;Career and advancement not considered important&lt;/li&gt;
&lt;li&gt;As a single person, being expected to handle &amp;quot;all of our bioinformatics&amp;quot; regardless of workload, provision of necessary facilities and whether you possess the necessary specialities&lt;/li&gt;
&lt;li&gt;Being expected to work long stressful &amp;quot;scientist&amp;quot; hours, while being treated as a technician&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;How did we get here? Why are bioinformaticians held in such low regard? To cut to the chase, I don't have a single answer here. But I do have several theories.&lt;/p&gt;
&lt;div class="section" id="theories"&gt;
&lt;h2&gt;Theories&lt;/h2&gt;
&lt;div class="section" id="no-one-gets-any-respect"&gt;
&lt;h3&gt;No one gets any respect&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Proposal:&lt;/strong&gt; This is academia and science. It's a zero sum game. Everyone's climbing the same greasy pole and fighting for the limited resources. Everyone is under stress, everything is under-resourced.  Social niceties are pushed to one side to be replaced with &amp;quot;what have you done for me today?&amp;quot; Why should bioinformatics be any different?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Counterpoint:&lt;/strong&gt; True, but this can't be a complete explanation. Other specialities don't have the job title problem, or get left out of planning discussions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="it-ll-take-time"&gt;
&lt;h3&gt;It'll take time&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Proposal:&lt;/strong&gt; Bioinformatics is too new and academic culture hasn't yet adapted to or understood it. Non-bioinformatic academics don't yet appreciate the way it works, seeing it as partially magic, partially ill-formed voodoo. Give it time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Counterpoint:&lt;/strong&gt;  Certainly, this was true once upon a time. Certainly, some parts of the academy are slow to adapt (try employing a &amp;quot;research software engineer&amp;quot; and see what your HR department reacts). But we've had nearly a generation of working bioinformaticians now. Some aspects of science and technology and business has changed radically (GWAS, open access, mega-journals, etc.) and the academy adapted to that. Why not bioinformatics?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bioinformatics-looks-like-it"&gt;
&lt;h3&gt;Bioinformatics looks like IT&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Proposal:&lt;/strong&gt; Bioinformatics is inherently computational, looks and acts a lot like IT and so it gets treated like IT, a fungible support service:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Early practitioners came from the IT side and many still do. Bioinformaticians leaving science will often move into pure IT.&lt;/li&gt;
&lt;li&gt;Bioinformaticians look and act like IT workers: largely male, hyper-casual dress, an obsession with technical details, an obscurantist style.&lt;/li&gt;
&lt;li&gt;Bioinformaticians are often referred explicitly as &amp;quot;computer guys&amp;quot;, with bioinformatics and informatics / IT tasks are being functionally interleaved and conflated. A cluster needs to be set-up for an analysis, the lab needs a website or database, someone can't figure why a program isn't working: these are all handed to the lab bioinformatician.&lt;/li&gt;
&lt;li&gt;Bioinformatics is treated by outsiders like a black box.&lt;/li&gt;
&lt;li&gt;Bioinformatics &amp;quot;skill&amp;quot; is often equated with being the master of an obscure technical stack.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Counterpoint:&lt;/strong&gt; None. I think this is completely true.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bioinformatics-is-blue-collar"&gt;
&lt;h3&gt;Bioinformatics is blue collar&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Note: I can't find who first made this distinction or used these terms but it's an observant one.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal:&lt;/strong&gt; scientific tasks can be divided into white collar (creative, high profile, seen as &amp;quot;output&amp;quot;, &amp;quot;thinkers&amp;quot; and &amp;quot;doers&amp;quot;) and blue collar (essential but seen as services or purely technical, that support white collar workers). Essentially, researchers versus technicians. Bioinformatics is blue collar.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Counterpoint:&lt;/strong&gt; The white-blue collar divide is absolutely real (quoting a colleague of mine, &amp;quot;in academia, you do not want to become known as a 'doer'&amp;quot;.) While many bioinformaticians willingly slot themselves into blue collar roles, it's unclear what globally labels a speciality as one or the other. Why is someone that coaxes microbes to grow in culture or chains together a drug molecule a white collar worker?  Why is it that scientists doing bioinformatics that is labelled as something else (e.g. evo devo, gene regulation) get treated as white collar? (Dare I say it's because their work is actually about biology not obscure technical shibboleths?)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-work-is-not-tangible"&gt;
&lt;h3&gt;The work is not tangible&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Proposal:&lt;/strong&gt; bioinformatics is &amp;quot;thought work&amp;quot; with little physical output and so is easy to forget about or discount.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Counterpoint:&lt;/strong&gt; This is a problem but it's not one with mathematicians or statisticians, at least not to the same extent.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bioinformatics-isn-t-worthy-of-respect"&gt;
&lt;h3&gt;Bioinformatics isn't worthy of respect&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Proposal:&lt;/strong&gt; The bioinformatics literature and community contains a lot of obscure, deck-chair rearranging about obscure technical details as opposed to than scientific conversation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Counterpoint:&lt;/strong&gt; Fair cop. This is not to devalue methodological assessment or establishment of best practices. But the most visible conversations in the bioinformatic space sound like car enthusiasts barracking for their favourite models and waxing lyrical on how they spent the weekend rebuilding an engine. In a way, this is just another form of the &amp;quot;IT&amp;quot; issue. It doesn't sound like science.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusions"&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;As said, I don't have an answer. And the answer is probably a mix of all of the above. But if I was to boil it all down to a single statement, it might be:&lt;/p&gt;
&lt;blockquote&gt;
Bioinformatics doesn't look like science. Sometimes it doesn't even look like work.&lt;/blockquote&gt;
&lt;p&gt;Before you ask how to fix this, should it be fixed? Bioinformatics is a broad, broad church and trying to fit everyone under one image or label (orone set of expectations) is not going to work.  Many of the people who fill &amp;quot;blue collar&amp;quot; technical posts are happy with that and trying to force everyone to fully commit to being &amp;quot;a scientist&amp;quot; (white collar) incurs a new set of problems. Perhaps what we need more is clarity about roles and responsibilities. If you're supposed to be a scientist, do science, talk abdout science and ask to be treated like a scientist.&lt;/p&gt;
&lt;/div&gt;
</content><category term="bioinformatics"></category><category term="academia"></category></entry><entry><title>Using AWS for research computing</title><link href="http://www.agapow.net/science/computational-biology/aws-for-research/" rel="alternate"></link><published>2017-05-01T12:00:00+01:00</published><updated>2017-05-01T12:00:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2017-05-01:/science/computational-biology/aws-for-research/</id><summary type="html">&lt;p&gt;This is based upon my reply to a question on reddit concerning experiences with using Amazon Web Services (including ELastic Computing, Glacier, etc.) for research.&lt;/p&gt;
&lt;p&gt;I was part of a pan-European research consortium that used it for our shared computing infrastructure: databases, a few web apps and web sites, mailers …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is based upon my reply to a question on reddit concerning experiences with using Amazon Web Services (including ELastic Computing, Glacier, etc.) for research.&lt;/p&gt;
&lt;p&gt;I was part of a pan-European research consortium that used it for our shared computing infrastructure: databases, a few web apps and web sites, mailers, some ad hoc computation for big projects. Here's my distilled wisdom of the experience.&lt;/p&gt;
&lt;div class="section" id="pros"&gt;
&lt;h2&gt;Pros&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;You pay for what you use. If you're not using something, you can switch it off.&lt;/li&gt;
&lt;li&gt;You can reconfigure and set up stuff when and as needed, not having to worry about waiting for institutional IT, delays with ordering, problems with department policies and so on.&lt;/li&gt;
&lt;li&gt;Cloning and copying disks and machines through a web interface was a dream. Need a new machine: click-click. Need to make it bigger: click-click. I set up some &amp;quot;base&amp;quot; configurations, which I used for building individualised systems.&lt;/li&gt;
&lt;li&gt;Doing things through the commandline / scripting interface was very powerful. You could write scripts to duplicate and backup systems, to push data and reboot a system, to monitor their state.&lt;/li&gt;
&lt;li&gt;There's a lot of smart useful stuff in AWS. I especially loved Elastic Beanstalk: being able to deploy and scale a piece of software (not a machine) without all the fiddly details or the hardware and network surrounding it. The storage stuff (S3 and Glacier) was also funky. You could run an entire website out of static (and cheap) S3.&lt;/li&gt;
&lt;li&gt;AWS is robust. You would hear horror stories of companies losing infrastructure and data in AWS but these seemed to be the long tail of experiences and AWS &amp;quot;just worked&amp;quot; around the clock. Anyway, normal resilience procedures should be used just as in any infrastructure.&lt;/li&gt;
&lt;li&gt;AWS has solid and easy security (at least as far as I could tell). You could readily restrict at different portals to different IPs and stack these policies.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="cons"&gt;
&lt;h2&gt;Cons&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Universities and research centers are still struggling to cope with pay-as-you-go computation. They're much more comfortable for paying lump sums for hardware and depreciating it.&lt;/li&gt;
&lt;li&gt;Costs are a little unpredictable, especially data transfer costs which are down right opaque. Don't forget to monitor what you're running or you could get surprised by costs from forgotten machines idling along.&lt;/li&gt;
&lt;li&gt;There's the occasional issue where institutional IT won't let your external (AWS) system talk to or connect to an internal resource because of policy / security. Which I can understand: research IT is a big enough mess without increasing the complexity of the task.&lt;/li&gt;
&lt;li&gt;It's an evolving platform so things change. (Actually changes very rarely broke anything, mostly they actually made things easier.)&lt;/li&gt;
&lt;li&gt;There's the occasional thing that is difficult or impossible under AWS. For example, I remember mailing being a problem because mailing required all legal to and from addresses to be pre-specified. (Amazon is rightly concerned about being used by spammers as disposable mailhost.) I got around it, but it was extra work.&lt;/li&gt;
&lt;li&gt;There's still a lot of technical details and sysadmin work to do, setting up firewall rules, configuring machines, networking etc. And since this is your infrastructure and nothing to do with the research institute, there's no help to be found. And since this is research, you're probably a postdoc or PhD student and not an IT professional, right? AWS makes it easier to setup and run a research computing infrastructure but it is by no means a simple task.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="end-analysis"&gt;
&lt;h2&gt;End analysis&lt;/h2&gt;
&lt;p&gt;In the end, I moved on and I believe the infrastructure largely migrated to one of the collaborators institutes, largely due to the first (cost) and last (expertise) cons. Still, I consider it a success. There was a lot that was good about using AWS.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="also-see"&gt;
&lt;h2&gt;Also see&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.reddit.com/r/bioinformatics/comments/68ugny/how_when_and_why_do_you_use_amazon_web_services/"&gt;How, when and why do you use Amazon Web Services in Bioinformatics?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="programming"></category><category term="software"></category><category term="research"></category><category term="amazon"></category><category term="aws"></category></entry><entry><title>Academic job ad red flags</title><link href="http://www.agapow.net/science/academia/job-ad-red-flags/" rel="alternate"></link><published>2017-02-01T12:00:00+00:00</published><updated>2017-02-01T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2017-02-01:/science/academia/job-ad-red-flags/</id><summary type="html">&lt;dl class="docutils"&gt;
&lt;dt&gt;&amp;quot;competitive salary&amp;quot;:&lt;/dt&gt;
&lt;dd&gt;Like several other terms on this list, this phrase is can be used in a completely sincere manner: &lt;em&gt;We pay decently. If we offer you the job, then we'll negotiate.&lt;/em&gt; Unfortunately, it is just as frequently used as a way of avoiding the subject of remuneration, in the …&lt;/dd&gt;&lt;/dl&gt;</summary><content type="html">&lt;dl class="docutils"&gt;
&lt;dt&gt;&amp;quot;competitive salary&amp;quot;:&lt;/dt&gt;
&lt;dd&gt;Like several other terms on this list, this phrase is can be used in a completely sincere manner: &lt;em&gt;We pay decently. If we offer you the job, then we'll negotiate.&lt;/em&gt; Unfortunately, it is just as frequently used as a way of avoiding the subject of remuneration, in the hope that by the time you learn the unfortunate truth, you'll give in due to sunk time and effort.&lt;/dd&gt;
&lt;dt&gt;&amp;quot;prestigious&amp;quot;:&lt;/dt&gt;
&lt;dd&gt;An institution or award that feels the need to tell you that it's famous and well-regarded, usually isn't.&lt;/dd&gt;
&lt;dt&gt;&amp;quot;salary band&amp;quot;:&lt;/dt&gt;
&lt;dd&gt;Encountered in the job search process at the beginning and the end with different meanings. At the beginning it appears in the job ad as &amp;quot;salary band for the successful applicant will be $X to $Y&amp;quot;. At the end it appears in the offer letter &amp;quot;it is our policy to appoint at the bottom of the salary band&amp;quot;.&lt;/dd&gt;
&lt;dt&gt;&amp;quot;passion&amp;quot;:&lt;/dt&gt;
&lt;dd&gt;We pay poorly and expect you to work long hours.&lt;/dd&gt;
&lt;dt&gt;&amp;quot;manager&amp;quot;:&lt;/dt&gt;
&lt;dd&gt;If the word &amp;quot;manager&amp;quot; is used in any context other than actually managing people, it's just a blatant way of puffing up an menial infrastructure job. (A recruiter actually once confessed this to me.) &amp;quot;Director&amp;quot; is beginning to assume the same meaning.&lt;/dd&gt;
&lt;dt&gt;&amp;quot;starting pay is low but ...&amp;quot;&lt;/dt&gt;
&lt;dd&gt;Your pay will be low.&lt;/dd&gt;
&lt;dt&gt;&amp;quot;... there's plenty of scope for advancement, the sky's the limit&amp;quot;&lt;/dt&gt;
&lt;dd&gt;Your pay will be low.&lt;/dd&gt;
&lt;dt&gt;&amp;quot;critical duties&amp;quot;:&lt;/dt&gt;
&lt;dd&gt;This is a great litmus test of whether the employer has a realistic attitude to what can be done. I once came across a job description that listed 72 &amp;quot;key responsibilities&amp;quot;, which is 29 minutes per responsibility per week. And remember - the listed duties are just the start. There will always be more, always things that were forgotten or get added later.&lt;/dd&gt;
&lt;dt&gt;&amp;quot;essential skills&amp;quot;:&lt;/dt&gt;
&lt;dd&gt;Much like &lt;em&gt;critical duties&lt;/em&gt;, this is a good test of realism. If the job ad is asking for &amp;quot;substantial experience in bioinformatics support&amp;quot; &lt;em&gt;and&lt;/em&gt; &amp;quot;10 years in Java 2EE development&amp;quot; &lt;em&gt;and&lt;/em&gt; &amp;quot;a record of publication in top journals&amp;quot;, you may rightly expect that the employer is thinking of several different people.&lt;/dd&gt;
&lt;dt&gt;&amp;quot;10% of your time will be devoted to ...&amp;quot;:&lt;/dt&gt;
&lt;dd&gt;At least 10% (and probably much more) of your time will be devoted to ...&lt;/dd&gt;
&lt;dt&gt;&amp;quot;Send in 3 copies of your application&amp;quot;:&lt;/dt&gt;
&lt;dd&gt;What is this - the 1970s?&lt;/dd&gt;
&lt;dt&gt;&amp;quot;Must be able to perform under pressure&amp;quot;:&lt;/dt&gt;
&lt;dd&gt;We're going subject you to an undifferentiated torrent of demands, stress and chaos.&lt;/dd&gt;
&lt;dt&gt;&amp;quot;Must be flexible / dynamic role&amp;quot;:&lt;/dt&gt;
&lt;dd&gt;There's no job description. Alternatively, if we told you what the job actually entails, you'd never apply.&lt;/dd&gt;
&lt;dt&gt;&amp;quot;lively social club&amp;quot;:&lt;/dt&gt;
&lt;dd&gt;The work site is in the middle of nowhere.&lt;/dd&gt;
&lt;/dl&gt;
</content><category term="career"></category><category term="job-search"></category></entry><entry><title>Some more things I done learned about REDCap</title><link href="http://www.agapow.net/science/data-science/more-about-redcap/" rel="alternate"></link><published>2016-09-10T00:00:00+01:00</published><updated>2016-09-10T00:00:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2016-09-10:/science/data-science/more-about-redcap/</id><summary type="html">&lt;p&gt;Refer back to the &lt;a class="reference external" href="/science/data-science/what-i-done-learned-about-redcap"&gt;previous article&lt;/a&gt; for the background and some introduction to REDCap.&lt;/p&gt;
&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Note&lt;/p&gt;
&lt;p class="last"&gt;These notes are based upon REDCap version 6.4.4. Different versions may have fixed or adjusted some of this behaviour.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="adding-users"&gt;
&lt;h2&gt;Adding users&lt;/h2&gt;
&lt;p&gt;To add a user, you need an email address to send a …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Refer back to the &lt;a class="reference external" href="/science/data-science/what-i-done-learned-about-redcap"&gt;previous article&lt;/a&gt; for the background and some introduction to REDCap.&lt;/p&gt;
&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Note&lt;/p&gt;
&lt;p class="last"&gt;These notes are based upon REDCap version 6.4.4. Different versions may have fixed or adjusted some of this behaviour.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="adding-users"&gt;
&lt;h2&gt;Adding users&lt;/h2&gt;
&lt;p&gt;To add a user, you need an email address to send a registration link to. No getting around it. (Which may seem like a trivial requirement, but this can be an issue when new staff are joining and IT is yet to assign them an address.)&lt;/p&gt;
&lt;p&gt;A small irritation is that if a new user has to be added to multiple projects, this has to be done, one-by-one, project-by-project. There's no getting around this.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="design"&gt;
&lt;h2&gt;Design&lt;/h2&gt;
&lt;p&gt;You can set the type of a field via validation and use this to control the number of decimal figures a numerical values gets. For example, &lt;tt class="docutils literal"&gt;integer, number, number_1dp, number_2dp&lt;/tt&gt; can have no, any, one or two figures after the decimal point respectively. You can also set minimum and maximum values for the numeric figures.&lt;/p&gt;
&lt;p&gt;Here's the catch:&lt;/p&gt;
&lt;p&gt;Only &lt;tt class="docutils literal"&gt;integer&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;number&lt;/tt&gt; pay any attention to the min/max fields. &lt;tt class="docutils literal"&gt;number_1dp&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;number_2dp&lt;/tt&gt; ignore them. (Some REDCap gurus asserted that you shouldn't even see the mix/max options for &lt;tt class="docutils literal"&gt;number_1dp&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;number_2dp&lt;/tt&gt; but maybe that's version-specific.)&lt;/p&gt;
&lt;p&gt;So here's your choice: to you want to limit the number of decimal figures &lt;em&gt;or&lt;/em&gt; the minimum and maximum values?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="making-project-changes"&gt;
&lt;h2&gt;Making project changes&lt;/h2&gt;
&lt;p&gt;While it would be best for any project to be completely designed before it is released to production, in reality changes will often have to be made to datasets that already in use: adding &amp;amp; renaming columns, tweaking validation, etc. REDCap is good about preserving data in the face of schema change, but caution still needs to be exercised.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;When in doubt, save and re-upload all your data&lt;/li&gt;
&lt;li&gt;Making changes one-by-one in the browser (using the design GUI) tends to be much more robust and preserve more data than by uploading a new data dictionary. REDCap knows what data is being changed from and to in the first, but not in the second.&lt;/li&gt;
&lt;li&gt;Changing the primary key / identifier will likely bork all your data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="choices"&gt;
&lt;h2&gt;Choices&lt;/h2&gt;
&lt;p&gt;You can trip yourself up with single / multiple-choice fields in REDCap, although you have to try hard. Choices are written as id-title pairs, where the first is the value that is stored internally and the second is the value that is shown to users:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
1=foo
2=bar
3=baz
&lt;/pre&gt;
&lt;p&gt;Note that they appear in the order that they are written in the choice options. So in this case:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
3=baz
2=bar
1=foo
&lt;/pre&gt;
&lt;p&gt;sorting does not occur on the internal values, they appear in the order baz-bar-foo. And should you be crazy enough to later edit and shuffle up the ids and titles:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
1=baz
2=foo
3=bar
&lt;/pre&gt;
&lt;p&gt;REDCap will happily let you.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="memory"&gt;
&lt;h2&gt;Memory&lt;/h2&gt;
&lt;p&gt;REDCap report generation is incredibly memory hungry. I've had cases where a 20Mb report needed more than 2Gb of memory. The explanation for this is that any report has to be assembled in memory, to allow for the various filters and selections, before it is converted to the downloadable text. In short: that's just the way it is.&lt;/p&gt;
&lt;p&gt;Downloading only part of the dataset (i.e. a subset of instruments or columns) will consume a correspondingly smaller amount of memory. Thus, a common riposte is to say that users shouldn't download the entire dataset. Good luck with that: you can provide an extensive list of report building and filtering mechanisms but people will insist on just downloading the entire dataset. A useful solution to this end is to install a plugin that dumps the data without filters. There's a useful implementation of this on the REDCap mailing list.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="elastic-beanstalk"&gt;
&lt;h2&gt;Elastic beanstalk&lt;/h2&gt;
&lt;p&gt;REDCap is easily deploy-able to Amazon's EB service, which not only saves you the work of setting up a system but also gets you auto-scaling behaviour. The way I set up an EB-based REDCap system was:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;Set it up the conventional way. This probably isn't necessary but is handy to make sure the configuration values.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Set up your database to use Amazon RDS (their database service)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Set up the reports and files to use Amazon S3. You need to do this because the EB disk space is completely ephemeral. See the previous article for some gotchas about S3.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;You may have to insert a few config files via &lt;tt class="docutils literal"&gt;.ebextensions&lt;/tt&gt;. I've used two to adjust some environmental and PHP variables:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# configure environment variables:
option_settings:
  - option_name: PHP_MEMORY_LIMIT
    value: 4000M

# extra php configuration
# this file will be placed in `php.d` and read after `php.ini`
files:
  &amp;quot;/etc/php.d/project.ini&amp;quot; :
    mode: &amp;quot;000644&amp;quot;
    owner: root
    group: root
    content: |
      upload_max_filesize = 64M
      post_max_size = 64M
      memory_limit = 3900M
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;You may have to adjust some variables on your EB dashboard to configure&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Otherwise, it's a simple case of dropping the REDCap source code into the EB deploy directory and writing the db settings in the appropriate place.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="email-trapped-by-spam"&gt;
&lt;h2&gt;Email trapped by spam&lt;/h2&gt;
&lt;p&gt;This is not a REDCap problem per se, but can be an issue depending on how you deploy it. If you use Elastic Beanstalk or one of the other Amazon deployment methods that pushes mail through Amazon's servers, many systems will mark this email as spam. It seems that many of the other systems sharing the email servers with you may be spamming and so the servers have ended up on blacklists. About the only thing you can do is use your own servers, Amazon SMS (Simple Message Service) or something similar.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="weird-characters"&gt;
&lt;h2&gt;Weird characters&lt;/h2&gt;
&lt;p&gt;Generally, REDCap is alright with handling extended characters (accents, umlauts, etc.) but CSV files and the associated tools often will only handle ASCII. So it may be necessary to normalise everything to plain text or play around with encodings, which is never fun.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="references"&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.biostat.wustl.edu/redcap/wp-content/uploads/2012/02/redcap_avoid_pitfalls.ppt"&gt;Avoiding common pitfalls in REDCap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://https://pycap.readthedocs.org/en/latest/"&gt;PyCap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="data-science"></category><category term="redcap"></category><category term="databases"></category></entry><entry><title>Random observations on the academic-scientific job search</title><link href="http://www.agapow.net/science/academia/observations-on-job-search/" rel="alternate"></link><published>2016-09-01T00:00:00+01:00</published><updated>2016-09-01T00:00:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2016-09-01:/science/academia/observations-on-job-search/</id><summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;Maintain employable, valuable skills. Never evince any technical skills. Never casually offer to help a colleague with computer problems, etc. First you'll end up being known for that. Second, people will keep asking you to encrypt their hard-drive, build a database, etc. Third, technical matters are low status &amp;quot;working class …&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;Maintain employable, valuable skills. Never evince any technical skills. Never casually offer to help a colleague with computer problems, etc. First you'll end up being known for that. Second, people will keep asking you to encrypt their hard-drive, build a database, etc. Third, technical matters are low status &amp;quot;working class&amp;quot; issues to academics and will lower your standing in their eyes, no matter how complex or difficult the tasks are. (This point and some of the wording borrowed from Kevin Boone.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Make your job search as frictionless as possible. Don't let it take over your life. Use alerts, RSS feeds, automatic mailouts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Recruiters mainly deal in the commercial / industrial sector and tend to throw a lot of random random jobs at you. But (a) they have occassional academic / government / non-commercial job, (b) some commercial jobs can be very interesting indeed, and (c) if only one-in-ten of their jobs are useful to you, it's still worth your time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;A large number of job opportunities (I'd guess at least a third), don't really exist. They're earmarked for someone else, there's an internal candidate, the funding isn't actually pinned down, they aren't as advertised ...&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Once you add in jobs that are no good but that's only obvious after the application / interview (e.g. pay too low, project different to advertised, unpleasant co-workers, goalposts shifted, ineffable weirdness about job), that will cross out maybe 2/3 of all jobs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;... and sometimes you have an off day, sometimes one of your interviewers is having an off day ...&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;... but instead of being depressed, look upon this as liberating. Yes, applying to these jobs wastes your time. But your &amp;quot;failure&amp;quot; to be selected is not really your failure. It's out of your hands.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;In any event, if you're not being rejected from most jobs you apply for, you're not aiming high enough.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;In many ways, a job search is like dating:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Desperation is a turn-off. Looking like you have other opportunities and alternatives only attracts more opportunities and alternatives.&lt;/li&gt;
&lt;li&gt;If they like you, you can do no wrong. If they hate you, you can do no right.&lt;/li&gt;
&lt;li&gt;... and they can like or hate you for almost random reasons.&lt;/li&gt;
&lt;li&gt;That first impression (the application and interview process) is them on their best behaviour. They're never going to treat you any better.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Any institute that feels it has to mention a &amp;quot;lively social club&amp;quot; in job ads is admitting they're in the middle of nowhere.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;You can learn a lot about a workplace just by looking at their kitchen.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;If your job title includes the words &amp;quot;manager&amp;quot;, &amp;quot;coordinator&amp;quot; or &amp;quot;administrator&amp;quot; but you're not actually managing / administrating / coordinating people and have no formal management / administration / coordination / powers, beware. (&amp;quot;Director&amp;quot; is now moving in this direction too.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;As the old saying goes, if you're the smartest person in the room, you're in the wrong room.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;To paraphrase Emma Kennedy, according to stats, 3.5% of PhD's will end up in an academic job and 0.45% end up as Professors. An academic career &lt;em&gt;is&lt;/em&gt; already your Plan B. Have you got a Plan A?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;If a job description mentions an unpleasant or irritating task (e.g. sysadmin, register new users, training) that is only supposed to take up a small part of your time, it will actually grow to encompass almost all of your time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;There's so much godawful advice about CVs out there that I can only counteract the most egregious points. So:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Keep it professional, no one's interested in your hobbies or personal life&lt;/li&gt;
&lt;li&gt;Reverse chronological format, role-focused&lt;/li&gt;
&lt;li&gt;Short, bullet points, lots of headings or sections&lt;/li&gt;
&lt;li&gt;Keep a master version but tailor it to every application&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Senior academics will often wring their hands and bleat that HR won't let them advertise the job they want / give you the right salary / employ you long-term etc. I'm torn between wondering (a) who is really running universities and (b) whether HR is just a convenient scapegoat.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Having said that, what is it about university HR departments that they see a job description for a research software engineer, bioinformatician or computational scientist, and feel compelled to label the position &amp;quot;data manager&amp;quot;, &amp;quot;web developer&amp;quot; or some other random IT title? In fact, why should HR even care what a job is called as long as funding is provided for it?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;You'll see people showing up to interviews in comfy jumpers, T shirts or even jeans. They're usually internal candidates. Don't try this yourself.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;You can find out a lot in an interview just by flat-out asking, &amp;quot;What's the big problem here? What's the worse thing about working here?&amp;quot;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Join your local union. It doesn't cost much and basically serves as insurance for Bad Job Stuff. If you need it, you'll be grateful.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;If an employer brags about their &amp;quot;generous&amp;quot; salaries but makes it hard to find out exactly what it is, this doesn't inspire confidence.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;A job application, interview and offer are &lt;em&gt;transactions&lt;/em&gt;. What are you offering? What are they offering? is that good enough? Be prepared to walk away.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;A phrase that you can safely ignore or mentally elide is &lt;em&gt;in the first instance&lt;/em&gt;. For example: &amp;quot;Funding is for 9 months in the first instance&amp;quot; means &amp;quot;Funding is for 9 months&amp;quot;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Universities keep advertising jobs with a salary band and then insisting they have a &amp;quot;policy&amp;quot; of appointing at the bottom of the band. In which case, the advertised band is essentially a lie.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;If you're the only acceptable candidate that applied for a position, there's something wrong with the job.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Modesty is not career enhancing. Narcissistic grandiosity sometimes is. Go figure.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&amp;quot;Unfortunately your application was unsuccessful. We had many excellent candidates ...&amp;quot;: Feedback is essentially bullshit and an ass-covering exercise where the employer seeks to &lt;em&gt;post facto&lt;/em&gt; justify why they selected the person they did.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&amp;quot;... but we'll keep your CV on file in case another position comes up&amp;quot;: This has never happened. I've applied and been interviewed at organisations that already had my &amp;quot;CV on file&amp;quot;. Apparently they never look at the &amp;quot;file&amp;quot;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;If you're employed on a support or technical band, you'll still be expected to work scientist hours, just without any of the benefits, recognition or career path.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Time is a strange thing. Some jobs take months to accept applications, shortlist, interview and make an offer. Others can do it in weeks. Both will expect you to be waiting, available and eager to instantly leap at their callmail.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Get and check your contract before the first day. Always.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content><category term="academia"></category><category term="job-search"></category><category term="interviews"></category></entry><entry><title>Words a data scientist never wants to hear</title><link href="http://www.agapow.net/science/data-science/more-words-not-to-hear/" rel="alternate"></link><published>2016-08-15T00:00:00+01:00</published><updated>2016-08-15T00:00:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2016-08-15:/science/data-science/more-words-not-to-hear/</id><summary type="html">&lt;p&gt;Some years ago I wrote a popular piece &lt;a class="reference external" href="http://www.agapow.net/science/computational-biology/words-not-to-hear/"&gt;Words a bioinformatician doesn't want to hear&lt;/a&gt;. Sadly, a lot of practitioners found it all too real. This time, I'm concentrating on the data end of things.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&amp;quot;We really need a database / webapp, so I can query / analyse / visualise this data!&amp;quot;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;[database …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some years ago I wrote a popular piece &lt;a class="reference external" href="http://www.agapow.net/science/computational-biology/words-not-to-hear/"&gt;Words a bioinformatician doesn't want to hear&lt;/a&gt;. Sadly, a lot of practitioners found it all too real. This time, I'm concentrating on the data end of things.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&amp;quot;We really need a database / webapp, so I can query / analyse / visualise this data!&amp;quot;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;[database / webapp is completed]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&amp;quot;Great! Now, can you use it to query / analyse / visualise this data for me ...&amp;quot;&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“The software doesn't automatically correct all the malformed and garbage data that we give it? Doesn't it 'know' that it's wrong?”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&amp;quot;Oh my god, this data is completely incorrect! The figures are corrupted, the rows are in the wrong order, and the values are wrong! This is a disaster!&amp;quot;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;[Email returned, politely pointing out they are looking at the wrong dataset, have misunderstood what it says, are looking for information that was not in the original data, or have loaded it into Excel which has helpfully 'corrected it'. ]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;[No reply is received.]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;[Repeat three weeks later.]&lt;/em&gt;&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;em&gt;[Looking at a reporting interface for a complex dataset]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&amp;quot;There's a lot of buttons here to click and things to select. Can't you just include a button that will select and analyse everything I'm interested in?&amp;quot;&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&amp;quot;That database is a real problem. It doesn't work at all. You should fix it.&amp;quot;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Uh, yes. But that's not ours. It's run by an external organisation.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&amp;quot;I don't understand. Why won't you fix it?&amp;quot;&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;em&gt;[Job ad]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&amp;quot;We're looking for someone who is deeply passionate about time series analysis of train movements / analysing advertising revenue for off-shore sneaker vendors / functional javascript handling of streaming video ...&amp;quot;&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&amp;quot;Let's dockerize the instance and use Spark to visualise it with D3 on tablets.&amp;quot;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Yes. Yes, let's do that.&lt;/em&gt;&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&amp;quot;You've messed up. This value used to be 3.7 and your spreadsheet is showing it as 3.69999999999.&amp;quot;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;[You explain floating point precision]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&amp;quot;Uh ... no, you don't understand. You've messed up. This value used to be ...&amp;quot;&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&amp;quot;I was thinking about the project the other day and had the idea [... BLAH BLAH BLAH ...] but on the other hand perhaps it would introduce problems similar to those encountered by [... BLAH BLAH BLAH ...] so perhaps it would be useful to have a feature like this. I'm not really sure of how it would work but [... BLAH BLAH BLAH ...] did some creditable work that is maybe of relevance to our current situation. Perhaps you can email her and [... BLAH BLAH BLAH ...] off to Switzerland next week, which is a terrible annoyance. Anyway, while I'm there I may talk to [... BLAH BLAH BLAH ...] will be joining us and Hal is very eager to get her involved [...]&amp;quot;&lt;/p&gt;
&lt;p&gt;&amp;quot;Anyway, what do you think?&amp;quot;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Did you ask a question in there?&lt;/em&gt;&lt;/p&gt;
</content><category term="data-science"></category><category term="databases"></category><category term="career"></category><category term="humour"></category></entry><entry><title>Bayesian stats in very plain language</title><link href="http://www.agapow.net/science/data-science/bayesian-stats-in-very-plain-language/" rel="alternate"></link><published>2016-07-01T12:00:00+01:00</published><updated>2016-07-01T12:00:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2016-07-01:/science/data-science/bayesian-stats-in-very-plain-language/</id><summary type="html">&lt;div class="section" id="introduction"&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Some years ago, I got into an argument with someone abut the relative merits of Bayesian versus Maximum Likelihood in phylogenetics. They asserted the two were basically the same or would come to the same answers. I countered that while they would often agree, they were measuring different things …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="introduction"&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Some years ago, I got into an argument with someone abut the relative merits of Bayesian versus Maximum Likelihood in phylogenetics. They asserted the two were basically the same or would come to the same answers. I countered that while they would often agree, they were measuring different things. Our conversation subsequently got bogged down in a technical discussion that clarified nothing.&lt;/p&gt;
&lt;p&gt;Bayesian statistics can be difficult to explain, can involve several foggy and seemingly obscure concepts, and explanations are frequently illustrated (obsfucated?) with cryptic maths. So here is a maths-light approach to help you get an intuitive grasp on the concept.&lt;/p&gt;
&lt;p&gt;(Experts, be warned that I'll cut a few corners and gloss over a few things. Criticism is welcome, but be aware of what I'm trying to do here.)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="take-1-outcomes-and-models"&gt;
&lt;h2&gt;Take 1: outcomes and models&lt;/h2&gt;
&lt;p&gt;I'll use a few ugly words here, but persist to the nice examples following.&lt;/p&gt;
&lt;p&gt;When talking about probability, we usually talk about &lt;strong&gt;data&lt;/strong&gt; and &lt;strong&gt;models&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Outcomes&lt;/strong&gt; (or &lt;em&gt;observations&lt;/em&gt; or &lt;em&gt;data&lt;/em&gt;) are the results, the countable things we are directly observing and counting: how many dice come up with a 6, which horse wins a race, how many red balls are pulled out of a bag, etc.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;model&lt;/strong&gt; (or &lt;em&gt;hypothesis&lt;/em&gt; or &lt;em&gt;system&lt;/em&gt;) is the thing that is producing the data, giving rise to it. So it's the set of dice you're rolling (and wether any of them are loaded), all the horses in the race and their relative speeds, the number and colour of all the balls in the bag.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Armed with this idea, we can start to compare bayesian and conventional statistics ...&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="take-2-explaining-the-model"&gt;
&lt;h2&gt;Take 2: explaining the model&lt;/h2&gt;
&lt;p&gt;When we talk about chance and probability in everyday life, we usually talk about how a model explains or causes an outcome:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The dice were loaded, so that's why you rolled three 6s.&lt;/li&gt;
&lt;li&gt;That horse was the fastest in the race, so it won.&lt;/li&gt;
&lt;li&gt;The bag has hardly any red balls in it, so you probably won't draw any.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These conventional statistics, what we call &lt;strong&gt;frequentism&lt;/strong&gt;, starts with a known model and predict or explain the results: &lt;em&gt;If half the balls in a bag are red, then it's likely half the balls we draw out of the bag will be red too ...&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;But there's a problem here: often in life, it's not the result or outcome that we need to know or understand. We can see the result, what has happened. Instead we want to know about the system that produced the results:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;If I roll three 6s in a row, does that mean these dice are loaded?&lt;/li&gt;
&lt;li&gt;If a specific horse wins a race, what does that tell me about the relative speeds of all horses in the race?&lt;/li&gt;
&lt;li&gt;If I draw 6 red and 3 black balls out of a bag, what does that tell me about the contents of the bag?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This sort of problem is common in scientific research. We do experiments to see how a complicated system (e.g. the human body, millions of years of evolution) behaves and use that to try and deduce how it works.&lt;/p&gt;
&lt;p&gt;It's a backwards sort of reasoning, and this is exactly what Bayesian statistics do: using the outcomes, look for the model that is best explained by the data. In contrast, methods like maximum likelihood looks for the model with the highest probability of producing the data.&lt;/p&gt;
&lt;p&gt;Confused? These two things are subtly different. Let me explain.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="take-3-cancer"&gt;
&lt;h2&gt;Take 3: Cancer&lt;/h2&gt;
&lt;p&gt;This is a classic toy example that I've modified slightly.&lt;/p&gt;
&lt;p&gt;Assume there's a test for cancer. If someone has cancer, it will always detect it, 100% of the time. If they don't have cancer, it will usually correctly call this result, 90% of the time. However in 10% of these cases, it will incorrectly report they do have cancer. Looking at this in a table:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="43%" /&gt;
&lt;col width="25%" /&gt;
&lt;col width="31%" /&gt;
&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;Cancer detected&lt;/td&gt;
&lt;td&gt;Cancer not detected&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Patient has cancer&lt;/td&gt;
&lt;td&gt;100%&lt;/td&gt;
&lt;td&gt;0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Patient doesn't have cancer&lt;/td&gt;
&lt;td&gt;10%&lt;/td&gt;
&lt;td&gt;90%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This is what we'd call a 0% false negative and 10% false positive.&lt;/p&gt;
&lt;p&gt;Now let's assume that 1% of people actually have cancer. You go in for a test and unfortunately it reports you have cancer. Statistically, do you actually have cancer?&lt;/p&gt;
&lt;p&gt;By conventional statistical approaches, we would say yes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;If you have cancer, there is a 100% probability we would get the result seen&lt;/li&gt;
&lt;li&gt;If you don't have cancer, theres a 10% result we would get a positive result&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, the scenario with the greatest chance of probability of producing the result we've seen is that you have cancer. Sorry.&lt;/p&gt;
&lt;p&gt;What this approach misses out is the relative probability of the different scenarios. Bayesian stats refers to these things as a &lt;strong&gt;prior&lt;/strong&gt;, what we know or believe about a system before we see any result. (Prior? Before? Get it?)&lt;/p&gt;
&lt;p&gt;Let's think of a population of 1000 people and put them into the table:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="43%" /&gt;
&lt;col width="25%" /&gt;
&lt;col width="31%" /&gt;
&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;Cancer detected&lt;/td&gt;
&lt;td&gt;Cancer not detected&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;10 patients with cancer&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;990 patients without cancer&lt;/td&gt;
&lt;td&gt;99&lt;/td&gt;
&lt;td&gt;891&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So, of the 109 people that are detected with cancer, only 10 actually do have it. If you are detected as having cancer, there is a roughly 9% chance you actually do. It's far more likely that the test has got it wrong and you're a false positive.&lt;/p&gt;
&lt;p&gt;Put it this way:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The explanation (model) that is most likely to say you have cancer, is that you have cancer&lt;/li&gt;
&lt;li&gt;If you have cancer, the most likely explanation (model) is that you do not have cancer&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="take-4-maths"&gt;
&lt;h2&gt;Take 4: maths!&lt;/h2&gt;
&lt;p&gt;I'll give way and actually put it into an equation here. This is Bayes Theorem:&lt;/p&gt;
&lt;blockquote&gt;
P(A|B) = P(B|A) * P(A) / P(B)&lt;/blockquote&gt;
&lt;p&gt;Which in our case means:&lt;/p&gt;
&lt;blockquote&gt;
Probability (you have cancer if you get a positive test) = Probability (you get a positive test if you have cancer) * Probability (you have cancer regardless of test result) / Probability (you get a positive result regardless of whether you have cancer)&lt;/blockquote&gt;
&lt;p&gt;Which is:&lt;/p&gt;
&lt;blockquote&gt;
1.0 * 0.01 / 0.109 = 0.092&lt;/blockquote&gt;
&lt;p&gt;So, if you get a positive result, there's only about 9% chance you have cancer. Obviously this is a grossly simplified situation, and using Bayes theorem is overkill. But it illustrates a general principle: maximum likelihood picks the single &amp;quot;best&amp;quot; answer, while Bayesian approaches consider how likely the individual answers are.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="also-see"&gt;
&lt;h2&gt;Also see&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://oscarbonilla.com/2009/05/visualizing-bayes-theorem/"&gt;Thinking about Bayes theorem graphically&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.math.umass.edu/~lavine/whatisbayes.pdf"&gt;A more intricate example, that illustrates how things work when you don't have good prior knowledge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://yudkowsky.net/rational/bayes"&gt;A more complicated and nuanced treatment of the cancer problem&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="bayesian"></category><category term="statistics"></category><category term="likelihood"></category></entry><entry><title>What I done learned about REDCap</title><link href="http://www.agapow.net/science/data-science/what-i-done-learned-about-redcap/" rel="alternate"></link><published>2015-07-15T00:00:00+01:00</published><updated>2015-07-15T00:00:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2015-07-15:/science/data-science/what-i-done-learned-about-redcap/</id><summary type="html">&lt;p&gt;For those not in the know, REDCap is a platform for creating and editing databases through the web. And by and large, it works fine. It saves a lot of development effort. It provides good reporting tools for users. It's secure and robust. But there are some things to be …&lt;/p&gt;</summary><content type="html">&lt;p&gt;For those not in the know, REDCap is a platform for creating and editing databases through the web. And by and large, it works fine. It saves a lot of development effort. It provides good reporting tools for users. It's secure and robust. But there are some things to be aware of, perhaps because of being insufficiently documented, perhaps because of expectations.&lt;/p&gt;
&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Note&lt;/p&gt;
&lt;p&gt;REDCap jargon is a little odd. To avoid confusion, I'll use the REDCap terms but just to remind you how REDCap-ese maps to some common terms:&lt;/p&gt;
&lt;dl class="last docutils"&gt;
&lt;dt&gt;an instrument:&lt;/dt&gt;
&lt;dd&gt;is a form&lt;/dd&gt;
&lt;dt&gt;a field:&lt;/dt&gt;
&lt;dd&gt;is a field or column&lt;/dd&gt;
&lt;dt&gt;a label:&lt;/dt&gt;
&lt;dd&gt;is a field title&lt;/dd&gt;
&lt;dt&gt;a name:&lt;/dt&gt;
&lt;dd&gt;is an field ID, identifier or internal ID&lt;/dd&gt;
&lt;dt&gt;a record:&lt;/dt&gt;
&lt;dd&gt;is a record or row&lt;/dd&gt;
&lt;dt&gt;a record ID:&lt;/dt&gt;
&lt;dd&gt;is a unique ID or key&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Note&lt;/p&gt;
&lt;p class="last"&gt;Most of these experiences are with REDCap version 5.12 through to 6.4.4. Of course, later versions may have fixed or adjusted some of this behaviour.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="field-labels"&gt;
&lt;h2&gt;Field labels&lt;/h2&gt;
&lt;p&gt;You may be tempted to have fields with the same labels (i.e. the visible title). For example, you have a instrument for a subject's initial assessment. Within it, you record the date of that visit as &amp;quot;Date&amp;quot;. Then you have a later instrument for a later visit, which you again equip with a field &amp;quot;Date&amp;quot;. Don't do this. When data is exported in the &amp;quot;labels&amp;quot; format, you'll end up multiple columns with similar titles and confuse people. Give each field a unique label: &amp;quot;Date of initial visit&amp;quot;, &amp;quot;Date of second visit&amp;quot; ...&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="character-or-less-ids"&gt;
&lt;h2&gt;26 character or less IDs&lt;/h2&gt;
&lt;p&gt;REDCap warns you if you create a field with an name that is more than 26 characters long, but lets you do it anyway. &lt;strong&gt;Don't&lt;/strong&gt;. I naively assumed that as it let me, the problems wouldn't be great and if there were any problems, they would be flagged-up.&lt;/p&gt;
&lt;p&gt;Foolish me.&lt;/p&gt;
&lt;p&gt;Eventually I discovered cases where the fields with the long names weren't appearing in downloaded data and reports, silent errors that caused huge problems. This may be dependent upon the format of exported data (e.g. R, CSV), but every field's name must be no more than 26 characters. Be very aware of this for checkboxes and radio buttons (see elsewhere). But also see notes on the &amp;quot;complete&amp;quot; fields below.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="checkboxes"&gt;
&lt;h2&gt;Checkboxes&lt;/h2&gt;
&lt;p&gt;I used checkboxes for a number of REDCap fields, which on reflection may have been better or more simply implemented otherwise. Don't mistake me, they work, but there were some unobvious implications to using them.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;Automatic formation of choice values:&lt;/dt&gt;
&lt;dd&gt;It's hard to see how REDCap could do this better, but when you give it a list of choices (say for a multiple-choice checkbox), it just assigns them consecutive numbers. &lt;tt class="docutils literal"&gt;Bar&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;Baz&lt;/tt&gt; will be represented by the coded internal values &lt;tt class="docutils literal"&gt;0&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;1&lt;/tt&gt;. Which isn't very meaningful. There's no way around this but to insert more meaningful names yourself. Remember they are limited to an alphanumeric string with underscores. (No spaces!)&lt;/dd&gt;
&lt;dt&gt;Name formation:&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;If a REDCap checkbox (multichoice) field has the label &lt;tt class="docutils literal"&gt;Foo&lt;/tt&gt; (name &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt;) and the choice values &lt;tt class="docutils literal"&gt;bar, Bar&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;baz, Baz&lt;/tt&gt;, this will actually be represented as multiple fields: &lt;tt class="docutils literal"&gt;Foo (Bar)&lt;/tt&gt; (name &lt;tt class="docutils literal"&gt;foo___bar&lt;/tt&gt;) and &lt;tt class="docutils literal"&gt;Foo (Baz) &lt;span class="pre"&gt;``(name&lt;/span&gt; ``foo___baz&lt;/tt&gt;). Users can sometimes find these a bit confusing.&lt;/p&gt;
&lt;p class="last"&gt;A far greater problem is that while REDCap warns you if you create a field with an name greater than 26 characters (see above), it does not alert you if a checkbox or radio button will result in a similar long name. (For example: &lt;tt class="docutils literal"&gt;longfieldname___longchoicename&lt;/tt&gt;). Watch out for these, they will result in the same problems as other long names.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Data export:&lt;/dt&gt;
&lt;dd&gt;If you export checkbox data in the &amp;quot;labels&amp;quot; format, it is rendered as the values &lt;tt class="docutils literal"&gt;Checked&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;Unchecked&lt;/tt&gt;. Which is logical but a little surprising and frightens some users. (I have some easily scared users.)&lt;/dd&gt;
&lt;dt&gt;Blank values:&lt;/dt&gt;
&lt;dd&gt;REDCap is generally very tolerate of blank or missing values but checkboxes is one place where it is not. Say you have a checkbox name &lt;tt class="docutils literal"&gt;foo&lt;/tt&gt; with choices &lt;tt class="docutils literal"&gt;bar&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;baz&lt;/tt&gt; and thus the columns &lt;tt class="docutils literal"&gt;foo___bar&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;foo___baz&lt;/tt&gt;. If either is checked, they will have the value &lt;tt class="docutils literal"&gt;1&lt;/tt&gt;, otherwise &lt;tt class="docutils literal"&gt;0&lt;/tt&gt;. If you import data with those values, it will be set accordingly. However, there's the (logical) temptation to set unchecked fields as blank. Don't do this. I found cases where these blank checkbox fields acquired a random value. As near as I could tell, while imported blank fields are usually recorded faithfully (e.g. an empty field in the input leads to an empty text field in the database), if an imported checkbox field is blank, its value is not recorded and it seems like it might acquire a random value. Unchecked checkboxes and radiobuttons must be explicitly set as unchecked (i.e. recorded as '0')&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="complete-fields"&gt;
&lt;h2&gt;Complete fields&lt;/h2&gt;
&lt;p&gt;Each instrument automatically acquires the field &lt;tt class="docutils literal"&gt;foo_complete&lt;/tt&gt;, which captures whether the form has been marked as complete. Users can be surprised by these fields when they &amp;quot;mysteriously&amp;quot; appear in exports, bearing values like &amp;quot;unverified&amp;quot;. For reference (and if you are importing data and wish to mark &amp;quot;completeness&amp;quot;), the possible values of this field are &amp;quot;Incomplete&amp;quot; (&lt;tt class="docutils literal"&gt;0&lt;/tt&gt;), &amp;quot;Unverified&amp;quot; (&lt;tt class="docutils literal"&gt;1&lt;/tt&gt;) and &amp;quot;Complete&amp;quot; (&lt;tt class="docutils literal"&gt;2&lt;/tt&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="importing-data"&gt;
&lt;h2&gt;Importing data&lt;/h2&gt;
&lt;p&gt;REDCap import &amp;quot;just works&amp;quot; but it's worth underlining how it works.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;Record IDs:&lt;/dt&gt;
&lt;dd&gt;If you import a record with the same ID as a pre-existing record, the previous record is over-written. There is no exception or way of getting around this, it's a fundamental and largely useful behaviour of REDCap. See &amp;quot;checkboxes&amp;quot; for a delightful exception to this.&lt;/dd&gt;
&lt;dt&gt;Data import tool:&lt;/dt&gt;
&lt;dd&gt;&amp;quot;Manually&amp;quot; filling in a data import template and uploading works fine. However, REDCap is fairly slow at importing data and the process consumes a lot of memory, such as to limit the size of file you can upload. (It will depend on how your server is set up but as a rule of thumb, watch out as you tend towards megabyte-sized uploads.) So then you have to split your upload into multiple files, while retaining the header. There's a number of command-line and online tools for doing this, but the upload task gets to be fairly tedious. Select file, click upload, wait, confirm you want to commit records, select file ... If you have to a lot of data often, you can instead script something to use the REST interface. See &amp;quot;PyCap&amp;quot;.&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="exporting-data"&gt;
&lt;h2&gt;Exporting data&lt;/h2&gt;
&lt;p&gt;Exporting is another thing that largely just works, but there are a few surprises on the system size:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The process takes a &lt;em&gt;huge&lt;/em&gt; amount of memory. Apparently the files are created entirely in-memory, and I would frequently see report and export fails because of running out of memory. Nothing for it but to boost the memory specs.&lt;/li&gt;
&lt;li&gt;If you look in the file storage area, you'll see lots and lots of files in lots of formats. It seems that when you generate a report, REDCap generates it in every possible format (&lt;cite&gt;.R&lt;/cite&gt;, &lt;cite&gt;.sps&lt;/cite&gt;, &lt;cite&gt;.csv&lt;/cite&gt;, etc.) and then leaves it in the file storage area forever. I had a system run out of space due to a huge number of reports building up. It may help to periodically purge this area.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="pycap"&gt;
&lt;h2&gt;PyCap&lt;/h2&gt;
&lt;p&gt;REDCap has a REST interface, which for those of you with a life means that there's a way to &amp;quot;talk&amp;quot; to the database over the web with other programs. This is very useful for writing scripts that automatically upload or download data. You could write these scripts direct to the interface, but there are a few libraries to help you out by wrapping the complexities of the interface. R has &lt;a class="reference external" href="https://github.com/OuhscBbmc/REDCapR"&gt;REDCapR&lt;/a&gt; and &lt;a class="reference external" href="http://cran.r-project.org/web/packages/redcapAPI/index.html"&gt;redcapAPI&lt;/a&gt; but I work largely in Python using &lt;a class="reference external" href="https://pycap.readthedocs.org/en/latest/"&gt;PyCap&lt;/a&gt;. It's a great module, but as always there are a few surprises.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;Not &lt;cite&gt;py&lt;/cite&gt;, &lt;cite&gt;red&lt;/cite&gt;:&lt;/dt&gt;
&lt;dd&gt;Remember, the module is called &lt;tt class="docutils literal"&gt;PyCap&lt;/tt&gt;, but it is imported under the name &lt;tt class="docutils literal"&gt;redcap&lt;/tt&gt;.&lt;/dd&gt;
&lt;dt&gt;Import scripts:&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;One of the most com on uses of the REST interface is to automate the (tedious) process of uploading a very large dataset. (See &amp;quot;importing data&amp;quot;.) But note that this doesn't get you around the issue of REDCap's memory limits. You may have to break up the dataset into smaller chunks. Even despite this I've often found the CPU of the REDCap server racing as it is bombarded with successive uploads. So you may want to pause between &amp;quot;chunks&amp;quot;. A piece of code like this will help:&lt;/p&gt;
&lt;pre class="last literal-block"&gt;
def upload_recs (proj, recs, chunk_sz, sleep=0):
   total_len = len (recs)
   for x in range (0, total_len, chunk_sz):
      start = x
      stop = min (total_len, x+chunk_sz)
      print (&amp;quot;Uploading records %s-%s of %s&amp;quot; % (start, stop-1, total_len))
      print (proj.import_records (recs[start:stop], overwrite='overwrite'))
      if sleep and (stop != total_len):
        time.sleep (sleep)
&lt;/pre&gt;
&lt;/dd&gt;
&lt;dt&gt;Downloading data:&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;Once, when using PyCap to download data from a series of REdCap databases, for some reason it keep flaking out on a particular db. This was made even stranger by the fact that it had previously worked. The error was:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
...
File &amp;quot;/Users/pagapow/anaconda/lib/python3.4/site-packages/redcap/project.py&amp;quot;,
   line 271, in export_records
   pl[key] = ','.join(data)
TypeError: sequence item 0: expected str instance, int found
&lt;/pre&gt;
&lt;p&gt;What seemed to have happened here is that new records were added with a different naming scheme, i.e. what was &lt;tt class="docutils literal"&gt;KDG102301&lt;/tt&gt; was joined by &lt;tt class="docutils literal"&gt;1510061&lt;/tt&gt;. PyCap was forcing new identifiers to be interpreted as integers, but later expects them to be strings, tries to &lt;tt class="docutils literal"&gt;join&lt;/tt&gt; them together into a single comma delimited string and fails.&lt;/p&gt;
&lt;p&gt;The solution is to hack on PyCap, inserting a line like this around line 269 of &lt;tt class="docutils literal"&gt;project.py&lt;/tt&gt; just before it does the join:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
data = [str(x) for x in data]
&lt;/pre&gt;
&lt;p&gt;My &lt;tt class="docutils literal"&gt;redcaphelper&lt;/tt&gt; module does this for you.&lt;/p&gt;
&lt;p&gt;Much like the upload &amp;quot;chunking&amp;quot; problem, sometimes you have to break up downloads into smaller bits to avoid overloading REDCap. Code like this will do the download in parts and join it all together:&lt;/p&gt;
&lt;pre class="last literal-block"&gt;
def chunked_export (project, chunk_size=200):
   &amp;quot;&amp;quot;&amp;quot;
   Download data in chunks to avoid memory errors.
   &amp;quot;&amp;quot;&amp;quot;
   def chunks(l, n):
      &amp;quot;&amp;quot;&amp;quot;Yield successive n-sized chunks from list l&amp;quot;&amp;quot;&amp;quot;
      for i in range (0, len(l), n):
         yield l[i:i+n]

   record_list = project.export_records(fields=[project.def_field])
   records = [r[project.def_field] for r in record_list]
   try:
      response = []
      for record_chunk in chunks(records, chunk_size):
         chunked_response = project.export_records(records=record_chunk)
         response.extend(chunked_response)
   except redcap.RedcapError:
      msg = &amp;quot;Chunked export failed for chunk_size={:d}&amp;quot;.format(chunk_size)
      raise ValueError (msg)
   else:
      return response
&lt;/pre&gt;
&lt;/dd&gt;
&lt;dt&gt;Downloading the data dictionary:&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;Is a logical and useful thing to do. I make it part of my regular backup of REDCap. The data within isn't as useful if you don't have the so I the schema and layout of each database. PyCap actually captures the schema within it's &lt;tt class="docutils literal"&gt;Project&lt;/tt&gt; object, although in a way that's different to the data dictionary layout. Use a bit of script like this to record it:&lt;/p&gt;
&lt;pre class="last literal-block"&gt;
csv_txt = proj.export_metadata (format='csv')
csv_rdr = csv.DictReader (io.StringIO (csv_txt))
csv_recs = [r for r in csv_rdr]
SCHEMA_FLD_ORDER = [
  'field_name',
  'form_name',
  'section_header',
  'field_type',
  'field_label',
  'select_choices_or_calculations',
  'field_note',
  'text_validation_type_or_show_slider_number',
  'text_validation_min',
  'text_validation_max',
  'identifier',
  'branching_logic',
  'required_field',
  'custom_alignment',
  'question_number',
  'matrix_group_name',
  'matrix_ranking',
]
out_hndl = open ('datadict.csv', 'w')
wrtr = csv.DictWriter (out_hndl, fieldnames=SCHEMA_FLD_ORDER)
wrtr.writerows (csv_recs)
&lt;/pre&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="s3-storage"&gt;
&lt;h2&gt;S3 storage&lt;/h2&gt;
&lt;p&gt;Good news! You can use Amazon (AWS) to store all the files generated and uploaded to REDCap, allowing you to load balance REDCap across multiple machines and abstract the service to things like Beanstalk or Docker images. Bad news! It's not as simple as it seems.&lt;/p&gt;
&lt;p&gt;The first (and easy) step is that you have to create an S3 bucket. Then you have to create a user - with access key and secret key - and give them access to that bucket. This is where it gets tricky: the permissions needed by REDCap are a little exotic. Here's the security policy I used, where &lt;cite&gt;redcap-file-storage&lt;/cite&gt; is the name of the bucket:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{
    &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
    &amp;quot;Statement&amp;quot;: [
        {
            &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
            &amp;quot;Action&amp;quot;: [
                &amp;quot;s3:ListBucket&amp;quot;
            ],
            &amp;quot;Resource&amp;quot;: [
                &amp;quot;arn:aws:s3:::redcap-file-storage&amp;quot;
            ]
        },
        {
            &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
            &amp;quot;Action&amp;quot;: [
                &amp;quot;s3:PutObject&amp;quot;,
                &amp;quot;s3:GetObject&amp;quot;,
                &amp;quot;s3:DeleteObject&amp;quot;,
                &amp;quot;s3:PutObjectAcl&amp;quot;
            ],
            &amp;quot;Resource&amp;quot;: [
                &amp;quot;arn:aws:s3:::redcap-file-storage/*&amp;quot;
            ]
        }
    ]
}
&lt;/pre&gt;
&lt;p&gt;So note: the user list the bucket, they can put-get-delete objects in the bucket and they can put ACLs on objects in the bucket. (This last one gave me the greatest trouble - it's not obvious unless you read the REDCap code.) (Also note: the version field in AWS policies is under-explained in documentation. It's the version number for the &lt;em&gt;format&lt;/em&gt;, and so it is fixed. It cannot be any other value.)&lt;/p&gt;
&lt;p&gt;Tools and code like &lt;cite&gt;boto&lt;/cite&gt; and &lt;cite&gt;s3cmd&lt;/cite&gt; are useful for debugging S3 connectivity.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="references"&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://redcap.vanderbilt.edu/"&gt;REDCap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://https://pycap.readthedocs.org/en/latest/"&gt;PyCap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="data-science"></category><category term="redcap"></category><category term="databases"></category></entry><entry><title>Markdown in R Studio</title><link href="http://www.agapow.net/science/data-science/markdown-in-rstudio/" rel="alternate"></link><published>2015-05-01T00:00:00+01:00</published><updated>2015-05-01T00:00:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2015-05-01:/science/data-science/markdown-in-rstudio/</id><summary type="html">&lt;p&gt;If you're doing reproducbility in &lt;a class="reference external" href="http://www.rstuio.com"&gt;R Studio&lt;/a&gt;, you're probably using knitr. And if you're using &lt;a class="reference external" href="http://yihui.name/knitr/"&gt;knitr&lt;/a&gt;, you're probably using &lt;a class="reference external" href="https://daringfireball.net/projects/markdown/syntax"&gt;Markdown&lt;/a&gt;. Unfortunately, due to the lack of a standard for Markdown (and the &lt;a class="reference external" href="http://blog.codinghorror.com/the-future-of-markdown/"&gt;subsequent proliferation of various flavours and extensions&lt;/a&gt;), it's sometimes not clear what syntax is available to you. Consequently …&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you're doing reproducbility in &lt;a class="reference external" href="http://www.rstuio.com"&gt;R Studio&lt;/a&gt;, you're probably using knitr. And if you're using &lt;a class="reference external" href="http://yihui.name/knitr/"&gt;knitr&lt;/a&gt;, you're probably using &lt;a class="reference external" href="https://daringfireball.net/projects/markdown/syntax"&gt;Markdown&lt;/a&gt;. Unfortunately, due to the lack of a standard for Markdown (and the &lt;a class="reference external" href="http://blog.codinghorror.com/the-future-of-markdown/"&gt;subsequent proliferation of various flavours and extensions&lt;/a&gt;), it's sometimes not clear what syntax is available to you. Consequently, you tend to write in the lowest common denominator / most common syntax.&lt;/p&gt;
&lt;p&gt;This is an exploration of what markup is available should you use Markdown in R Studio, based on the &lt;a class="reference external" href="https://github.com/rstudio/rmarkdown"&gt;source distribution&lt;/a&gt;, &lt;a class="reference external" href="http://rmarkdown.rstudio.com/authoring_pandoc_markdown.html"&gt;documentation&lt;/a&gt; and some experiments. I'm not trying to explain all of Markdown, just the oddities and extras you'll find in R Studio.&lt;/p&gt;
&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Note&lt;/p&gt;
&lt;p class="last"&gt;You can use reStructured Text instead of Markdown, it's more powerful and has more features, but Markdown is the first class citizen in the R Studio universe and you'll always be fighting the system in some way.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="technical-details"&gt;
&lt;h2&gt;Technical details&lt;/h2&gt;
&lt;p&gt;R Studio v0.98 on Mac OSX 10.9, April 2015.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="general-issues"&gt;
&lt;h2&gt;General issues&lt;/h2&gt;
&lt;p&gt;R Studio Markdown (henceforth &lt;em&gt;RSMarkdown&lt;/em&gt;) is an R package that is based on &lt;a class="reference external" href="http://pandoc.org/"&gt;pandoc&lt;/a&gt;. While it is possible to install extensions for the package, it's not clear to me how to get RSMarkdown to use these extensions.&lt;/p&gt;
&lt;p&gt;Markdown is generally focused on HTML as an output. RSMarkdown is more general and allows other and mutliple output formats.&lt;/p&gt;
&lt;p&gt;Where a block of text must be indented, that indentation is a tab or at least 4 spaces.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="metadata-headers"&gt;
&lt;h2&gt;Metadata &amp;amp; headers&lt;/h2&gt;
&lt;p&gt;RSMarkdown explicitly allows for metadata, which may define title and output format. Multiple outputs can be defined, with variables that apply just in those contexts:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
---
title: &amp;quot;Sample Document&amp;quot;
output:
  html_document:
    toc: true
    theme: united
  pdf_document:
    toc: true
    highlight: zenburn
---
&lt;/pre&gt;
&lt;p&gt;Possible output formats are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;html_document&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;pdf_document&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;word_document&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;md_document&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;beamer_presentation&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;ioslides_presentation&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;slidy_presentation&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This style of metadata is in fact &lt;a class="reference external" href="http://yaml.org"&gt;YAML&lt;/a&gt; and can include other fields:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
---
title:  'This is the title: it contains a colon'
author:
- name: Author One
  affiliation: University of Somewhere
- name: Author Two
  affiliation: University of Nowhere
tags: [nothing, nothingness]
abstract: |
  This is the abstract.

  It consists of two paragraphs.
---
&lt;/pre&gt;
&lt;p&gt;Obscurely, RSMarkdown includes a second type of metadata, where the intial lines of a file can include 3 lines beginning with percent signs, giving bibliographic information:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% title
% author(s)
% date
&lt;/pre&gt;
&lt;p&gt;The order and number of lines are fixed. It is unclear whether R Studio does anything with this info.&lt;/p&gt;
&lt;p&gt;Two styles of headers are permitted, covering slightly different levels of headings:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
A level-one header
==================

A level-two header
------------------

## A level-two header

### A level-three header

#### etcetera
&lt;/pre&gt;
&lt;p&gt;&amp;quot;Leading hash&amp;quot; style headers can have matching trailing hashes, e.g. &lt;tt class="docutils literal"&gt;## FOO ##&lt;/tt&gt;, which is arguably more readable.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="text-styling"&gt;
&lt;h2&gt;Text styling&lt;/h2&gt;
&lt;p&gt;Strike-through text is flanked with double-tildes:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
This ~~is deleted text.~~
&lt;/pre&gt;
&lt;p&gt;Superscripts are flanked with the &amp;quot;hat&amp;quot; symbol, subscripts are flanked with a single tilde:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
2^10^ is 1024, H~2~O is a liquid.
&lt;/pre&gt;
&lt;p&gt;Verbatim / literal text is placed inside backticks:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
What is the difference between `&amp;gt;&amp;gt;=` and `&amp;gt;&amp;gt;`?
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="quotes-code-blocks"&gt;
&lt;h2&gt;Quotes &amp;amp; code blocks&lt;/h2&gt;
&lt;p&gt;Quotes are precded with &lt;tt class="docutils literal"&gt;&amp;gt;&lt;/tt&gt; marks. Only the first line need have one if subsequent lines are flush against the left margin:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt; This is a block quote. This
&amp;gt; paragraph has two lines.

&amp;gt; This is a block quote. This
paragraph has two lines.
&lt;/pre&gt;
&lt;p&gt;Literal quote blocks preserve linebreaks, such as you might want to do for addresses or for poetry. This are preceded with vertical bars &lt;tt class="docutils literal"&gt;|&lt;/tt&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
| 200 Main St.
| Berkeley, CA 94718
&lt;/pre&gt;
&lt;p&gt;Code blocks are &amp;quot;fenced&amp;quot; with lines of 3 or more tildes, or indented:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
~~~~~~~
if (a &amp;gt; 3) {
 moveShip(5 * gravity, DOWN);
}
~~~~~~~

   if (a &amp;gt; 3) {
     moveShip(5 * gravity, DOWN);
   }
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="lists"&gt;
&lt;h2&gt;Lists&lt;/h2&gt;
&lt;p&gt;Definition lists can be used, with the initial definition line preceded with &lt;tt class="docutils literal"&gt;:&lt;/tt&gt; and subsequent lines at the same depth. These lists must be indented:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Term 1

:  Definition 1

Term 2

:  Definition 2

   Third paragraph of definition 2.
&lt;/pre&gt;
&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Note&lt;/p&gt;
&lt;p class="last"&gt;I've had a lot of trouble with definition lists, even after reading the spec and documentation. Regardless of what is written elsewhere, it seems like the whole list has to be indented and the definition has to be at the same level of indentation as the term.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Numbered lists can be constructed with &lt;tt class="docutils literal"&gt;(&amp;#64;)&lt;/tt&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
(&amp;#64;)  My first example will be numbered (1).
(&amp;#64;)  My second example will be numbered (2)
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="tables"&gt;
&lt;h2&gt;Tables&lt;/h2&gt;
&lt;p&gt;You can do tables in RSMarkdown. Lord, can you do tables. There's multiple ways to do them, but I'll drop a few simple examples here, from which the general form can be inferred. Note that no header is required and horizontal lines are
fairly freeform:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
 Right     Left     Center     Default
-------    ------ ----------   -------
    12     12        12           12
   123     123       123          123
     1     1         1            1

-------  ------  ----------  -------
     12  12           12          12
    123  123         123         123
      1  1            1            1
-------  ------  ----------  -------

-------------------------------------------------------------
Centered    Default           Right  Left
 Header     Aligned         Aligned  Aligned
----------- ------- ---------------  ------------------------
  First      row               12.0  Example of a row that
                                     spans multiple lines.

 Second      row                5.0  Here's another one. Note
                                     the blank line between
                                     rows.
-------------------------------------------------------------
&lt;/pre&gt;
&lt;p&gt;Tables can also be given a label that either proceeds or follows them:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Table:  Demonstration of simple table syntax.
&lt;/pre&gt;
&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Note&lt;/p&gt;
&lt;p class="last"&gt;Tables are tremendously fiddly. Get even a single character out of the column and RSMarkdown will foul it up. I've even had cases where a seemingly valid table won't format correctly for unclear reasons.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="r"></category><category term="r-studio"></category><category term="markdown"></category><category term="markup"></category><category term="knitr"></category></entry><entry><title>(Re-)building databases with csvsql</title><link href="http://www.agapow.net/science/data-science/rebuilding-databases-with-csv2sql/" rel="alternate"></link><published>2015-03-24T10:10:48+00:00</published><updated>2015-03-24T10:10:48+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2015-03-24:/science/data-science/rebuilding-databases-with-csv2sql/</id><summary type="html">&lt;div class="section" id="the-scenario"&gt;
&lt;h2&gt;The scenario&lt;/h2&gt;
&lt;p&gt;You have a bunch of related CSV files.&lt;/p&gt;
&lt;p&gt;Maybe they're the result of a raw database dump. Maybe they've been generated
in some other way: experimental results, various public data sets, whatever. But the important thing is that you need to make a database from them. Perhaps because …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="the-scenario"&gt;
&lt;h2&gt;The scenario&lt;/h2&gt;
&lt;p&gt;You have a bunch of related CSV files.&lt;/p&gt;
&lt;p&gt;Maybe they're the result of a raw database dump. Maybe they've been generated
in some other way: experimental results, various public data sets, whatever. But the important thing is that you need to make a database from them. Perhaps because you need to query them in some way that's best suited to an SQL query  (references across tables, selecting some fields but not others, etc.) Perhaps you need to work with the information in a particular database but in the absence of a working db connection, you have to make do with a raw data dump. Perhaps the original database has been lost or is so severely dysfunctional that normal exttraction and reporting tools don't work.&lt;/p&gt;
&lt;p&gt;Just for example.&lt;/p&gt;
&lt;p&gt;In any event, you need to turn a bunch of CSV files into a working database.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-solution"&gt;
&lt;h2&gt;The solution&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;csvsql&lt;/em&gt; is part of the csvkit package and it does what the name suggests: converts a csv file into a table in an SQL database:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% csvsql --db sqlite:///foo.db --insert bar.csv
&lt;/pre&gt;
&lt;p&gt;The above line converts the contents of &lt;em&gt;bar.csv&lt;/em&gt; into the table &lt;em&gt;bar&lt;/em&gt; in the sqlite database &lt;em&gt;foo.db&lt;/em&gt;.  There are a multitude of options and features, but to pick a few:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Instead of inserting the data, just generate the relevant SQL.&lt;/li&gt;
&lt;li&gt;Name the table to be created and specify a schema for it.&lt;/li&gt;
&lt;li&gt;Work with assorted databases like Access, Firebird, MySQL, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Multiple tables can be inserted with repeated calls:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% csvsql --db sqlite:///foo.db --insert bar.csv
% csvsql --db sqlite:///foo.db --insert baz.csv
% csvsql --db sqlite:///foo.db --insert quux.csv
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="possible-problems"&gt;
&lt;h2&gt;Possible problems&lt;/h2&gt;
&lt;p&gt;When making a databse, &lt;em&gt;csvsql&lt;/em&gt; has to construct a database schema, inferring a type (CHAR, INT, DATE, etc.) for every column from the original table structure.  All in all, it does a creditable job of this and guesses reasonable types that that you can later work with. Sometimes, however, it messes up and infers incorrectly. More to the point, this happens silently, so the problems may remain hidden.&lt;/p&gt;
&lt;p&gt;Text fields are generally not an issue. Where problems seem to result are with numeric data and dates. The first instance I ran across of this was with a record id column that was recorded as a number: 23456, 67890, etc. &lt;em&gt;csvsql&lt;/em&gt; mostly and sensibly interpreted that as an integer. However, for a few tables it would occasionally cast it as a string. This problem only became obvious when I queried for certain records and was unable to find them, as I was looking for an integer value not a string. &lt;em&gt;csvsql&lt;/em&gt; conversion was consistent for a table, but I was never able to discern what in the ids triggered the difference.&lt;/p&gt;
&lt;p&gt;This problem could be overcome in code in a number of ways: converting all ids to integer, doing a pre-processing step in which the database column types were altered, etc. However, a greater problem arose when &lt;em&gt;csvsql&lt;/em&gt; interpreted columns with dates in them. It correctly recognised them as dates and cast the resultant database column as a date type, but incorrectly parsed the dates. As in, the year might be correct but the month and day were wrong.&lt;/p&gt;
&lt;p&gt;This was obviously a huge problem. Ultimately, it was probably a problem with date formats in the source tables, as it used three different datetime formats, one of which had double-spaces between the date and time. But the datetimes were formatted consistently, so &lt;em&gt;csvsql&lt;/em&gt; messed up bad.&lt;/p&gt;
&lt;p&gt;There's a few possible solutions for these issues. &lt;em&gt;csvsql&lt;/em&gt; can accept a schema, so it would be possible to do an initial conversion, alter the schema as desired and use it for the proper import. However, this fixes the integer issues but not the dates. Perhaps, some preprocessing of dates into a suitable and robust format might work, but I instead opted for a brute force approach. &lt;em&gt;csvsql&lt;/em&gt; includes an option where no inference on column type takes place and everything is treated as text:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% csvsql --no-inference --db sqlite:///foo.db --insert bar.csv
&lt;/pre&gt;
&lt;p&gt;Now, all keys are text (everything is text) and all dates are exactly as they are in the source. This may create additional problems. If you have a column without any data, &lt;em&gt;csvsql&lt;/em&gt; bugs out when using &lt;em&gt;no-inference&lt;/em&gt;, although a little bit of hacking can get you around this. Also, in a database where every column is text, comparative queries like &lt;tt class="docutils literal"&gt;WHERE DepartmentSize &amp;gt;= 100&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;DateOfBirth &amp;gt;= &lt;span class="pre"&gt;'2000-12-25&lt;/span&gt; 00:00:00.000&lt;/tt&gt; will be impossible, and &lt;tt class="docutils literal"&gt;ORDER&lt;/tt&gt; will work on textual not numeric order. I settled for the all text conversion, and then writing a script to extract and transform data from the all-text database into a new database, so I could sculpt and change the schema.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="references"&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/onyxfish/csvkit"&gt;csvkit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="database"></category><category term="data-science"></category><category term="csv"></category><category term="cssql"></category><category term="csvkit"></category></entry><entry><title>Words a bioinformatician never wants to hear</title><link href="http://www.agapow.net/science/computational-biology/words-not-to-hear/" rel="alternate"></link><published>2015-02-25T23:29:00+00:00</published><updated>2015-02-25T23:29:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2015-02-25:/science/computational-biology/words-not-to-hear/</id><summary type="html">&lt;p&gt;(This first appeared on biocodershub.net courtesy of Rad, and has since popped up on coderscrowd.com. It enjoyed some moments of viral popularity, with many aggrieved practitioners chipping in on the comments of the article. Following the resurrection of my website, it's a good opportunity to bring this piece …&lt;/p&gt;</summary><content type="html">&lt;p&gt;(This first appeared on biocodershub.net courtesy of Rad, and has since popped up on coderscrowd.com. It enjoyed some moments of viral popularity, with many aggrieved practitioners chipping in on the comments of the article. Following the resurrection of my website, it's a good opportunity to bring this piece home.)&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“The data is all in these [proprietary and undocumented format] files.”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“What I want is a program to browse, edit and validate gigabyte-size whole genome sequencing runs. It should import and export all known formats. And it has to run in a browser. And some of our staff refuse to use anything but IE6.”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;em&gt;(After delivering an insignificant or negative result)&lt;/em&gt; “Can’t you analyse it again?”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“Why don’t we put the new server rack in your office?”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“That software you wrote is buggy!&lt;/p&gt;
&lt;p&gt;[What happened?]&lt;/p&gt;
&lt;p&gt;It’s not working!&lt;/p&gt;
&lt;p&gt;[How do you know that?]&lt;/p&gt;
&lt;p&gt;It’s broken!&lt;/p&gt;
&lt;p&gt;[In what way?]&lt;/p&gt;
&lt;p&gt;Can’t you just fix it?&lt;/p&gt;
&lt;p&gt;[How? I don't know what's wrong ...]&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“I don’t understand - [large research institute / multinational commercial company] has software that can do this. Can’t you just write something similar?”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“This is a great / exciting opportunity …”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“This program is great. But could you rewrite it in another programming language?”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“That database and web service you wrote for X? We need one that works just like that. Except for …&amp;quot;
[lists dozens of ways in which the new service actually differs entirely from the previous one]&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“You want to know what feature or task is the most important? They all are!”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;em&gt;(After being told that the data sample is too small, or incorrectly sampled such that analysis is impossible.)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;“You don’t understand – we really need this result.”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“Here’s the data. I haven’t had time to clean it up, so it might be incomplete. And some of the identifiers might not agree. And there are mis-spellings …”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;em&gt;(After delivering the outcome of an analysis)&lt;/em&gt; “Pth – that result is obvious.”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“Don’t worry about who’s going to [maintain the new database / monitor the new service / curate the data / come in on the weekends to restart the system]. We’ll work that out later …”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“So X wrote us this pipeline before he left. I’m not sure if he finished it. No, there’s no documentation. Can you get it working? By next week?”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“I think I read a way to do this: it was in a journal, maybe. Or on a webpage. Done by some lab in France. Or was it China? Anyway, it should be simple.”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“Do you really need that much disk space for this NGS data?”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“So your program crashed when I tried to load data. What format? Does that matter? They were Word documents. Really, the program doesn’t read those?”&lt;/p&gt;
&lt;p&gt;“So, what you’re saying is that a Word document isn’t a text file. But I used Courier as a font.”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“We need this program. It’s really simple … [30 minutes of essential features follow]“&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&amp;quot;I'm sure it can't be that complicated ...&amp;quot;&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;em&gt;(While waiting for the result of a Bayesian calculation)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;“Why does it take so long to get this answer? Can’t you just make it go faster?”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“I know you said that 30 data points were the minimum for statistical rigour. But we only got 5. Can’t you analyze it anyway?”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“We keep all those records in Excel files … uh, I think this is the most current version …”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“The Z lab showed you could do this [with 10 genes and a computing cluster]. So do you think you could this this with our data [200 whole genomes, on a PC]?”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“Good news – we got a huge grant for sequencing and annotating 6 squillion whole genomes. You’re not on the grant and we didn’t budget for any bioinformatic work but here’s the data. Can you have this done by next week?”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;em&gt;(After being told that an analysis is impossible or ill-considered)&lt;/em&gt; “But X over in Y’s lab does it all the time.”&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;“Uh, so what is it that you do again?”&lt;/p&gt;
</content><category term="bioinformatics"></category><category term="career"></category><category term="humour"></category></entry><entry><title>Tools for data</title><link href="http://www.agapow.net/science/data-science/tools-for-data/" rel="alternate"></link><published>2015-02-20T00:00:00+00:00</published><updated>2015-02-20T00:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2015-02-20:/science/data-science/tools-for-data/</id><summary type="html">&lt;p&gt;Prompted by a recent tweet asking what people used for storing and managing their data, I wrote down my own hard-won lessons on the topic. In rough order of preference and data complexity:&lt;/p&gt;
&lt;div class="section" id="a-hierarchical-strategy"&gt;
&lt;h2&gt;A hierarchical strategy&lt;/h2&gt;
&lt;div class="section" id="use-restructured-text-for-documentation"&gt;
&lt;h3&gt;Use restructured text for documentation&lt;/h3&gt;
&lt;p&gt;Or markdown / asciidoc. The advantages of this being:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;It's …&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Prompted by a recent tweet asking what people used for storing and managing their data, I wrote down my own hard-won lessons on the topic. In rough order of preference and data complexity:&lt;/p&gt;
&lt;div class="section" id="a-hierarchical-strategy"&gt;
&lt;h2&gt;A hierarchical strategy&lt;/h2&gt;
&lt;div class="section" id="use-restructured-text-for-documentation"&gt;
&lt;h3&gt;Use restructured text for documentation&lt;/h3&gt;
&lt;p&gt;Or markdown / asciidoc. The advantages of this being:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;It's a plain text format, you can write or read it anywhere&lt;/li&gt;
&lt;li&gt;It's a format that's more about structure, information and relationships than presentation, i.e. what you should be worrying about rather than look-and-feel&lt;/li&gt;
&lt;li&gt;There are many tools for exporting it to other formats.&lt;/li&gt;
&lt;li&gt;If necessary, it can be parsed for extracting information.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="use-csv-for-tables"&gt;
&lt;h3&gt;Use CSV for tables&lt;/h3&gt;
&lt;p&gt;Because:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Every spreadsheet and stats tool can use it&lt;/li&gt;
&lt;li&gt;Every programming language can parse it without problems&lt;/li&gt;
&lt;li&gt;Again, it's a plain text format&lt;/li&gt;
&lt;li&gt;It doesn't mangle or transform values like Excel has a habit of silently doing&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="use-sqlite-for-relational-data"&gt;
&lt;h3&gt;Use SQLite for relational data&lt;/h3&gt;
&lt;p&gt;If you have to store relational data and/or use a database (and I suggest you question this need very closely), use one that&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;is easily portable&lt;/li&gt;
&lt;li&gt;not beholden to any company&lt;/li&gt;
&lt;li&gt;uses fairly standard SQL&lt;/li&gt;
&lt;li&gt;is easy to get data in and out of&lt;/li&gt;
&lt;li&gt;is just sophisticated enough to store your data and no more&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the context of data science, the lack of permissions / access control in SQLite is in fact an advantage. You're usually just throwing together a database to analyse, not to mount on the web, so a permissions structure is surplus to requirements and can only cause problems.&lt;/p&gt;
&lt;p&gt;Should you push beyond the limits of SQLite data-size-wise, retreat to other vanilla SQL databases: MySQL, Postgres.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="use-yaml-or-xml-or-hdf5-for-complex-datasets"&gt;
&lt;h3&gt;Use YAML or XML or HDF5 for complex datasets&lt;/h3&gt;
&lt;p&gt;YAML for humans, XML for computers.&lt;/p&gt;
&lt;p&gt;Why YAML:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;It's highly readable (and nearly valid javascript)&lt;/li&gt;
&lt;li&gt;It's easy to write by hand&lt;/li&gt;
&lt;li&gt;There are parsers for many languages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'm tempted to says that YAML should always be used instead of XML. However there are more complex datatypes that are a bit fiddly to manipulate in YAML. And there may be the need for interoperability with XML-friendly tools. If so, you should use XML, because:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;It's super-standard&lt;/li&gt;
&lt;li&gt;There are many tools in every language for handling it.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you end up with very large complicated, heterogeneous data, use CDF or HDF5. Why?&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;At this point, readability is moot. May as well use something that is easy for computers.&lt;/li&gt;
&lt;li&gt;It's a standard. That's a good enough reason.&lt;/li&gt;
&lt;li&gt;You can store anything in it.&lt;/li&gt;
&lt;li&gt;It was made for just this use case.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="admonition warning"&gt;
&lt;p class="first admonition-title"&gt;Warning&lt;/p&gt;
&lt;p class="last"&gt;Just, for godsake, don't not write your own &lt;em&gt;de novo&lt;/em&gt; format. It's not as easy if it looks and untold hours have been consumed by dodgy home-grown formats. Write any format you use on top of YAML or XML. Even then, it's very easy to cock it up.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="for-web-databases"&gt;
&lt;h3&gt;For web databases&lt;/h3&gt;
&lt;p&gt;Use REDCap. Really. It does most everything you want to do, has sophisticated access control, a nice body of reporting tools, it's easy to design / revise databases, it's easy to import and export data, there's a large body of expertise, it's secure, there's a body of expertise and experience out there.&lt;/p&gt;
&lt;p&gt;(CKAN and opendatakitr may be good fits for this niche but I have less firsthand knowledge.)&lt;/p&gt;
&lt;p&gt;If you have to go beyond this - say for a database with heavy relational elements, or a lot of custom tools and datatypes, use Ruby-on-Rails. It is built for quickly doing this sort of CRUD database, making a lot of assumptions to speed development that will almost certainly hold for your data needs. It can't do everything, but it can almost certainly do what you need to do. Actually, use Hobo, which is like the next level RoR, allowing very rapid db development.&lt;/p&gt;
&lt;p&gt;The one downside is the dizzying rate of change in the RoR ecosystem, where yesterdays way is Old-and-Busted and tomorrow's New Hotness doesn't quite work yet. But a little bit of careful and conservative development can get you around this.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="alternatives"&gt;
&lt;h2&gt;Alternatives&lt;/h2&gt;
&lt;div class="section" id="json"&gt;
&lt;h3&gt;JSON&lt;/h3&gt;
&lt;p&gt;Certainly if you're working in Javascript (WHY?) or interacting with web-services, your data may pass through JSON. But as a primary data format? No. And that's before we consider the lack of data manipulation and search tools.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="excel"&gt;
&lt;h3&gt;Excel&lt;/h3&gt;
&lt;p&gt;No.&lt;/p&gt;
&lt;p&gt;Just wait until you come across your very important piece of data that Excel silently &amp;quot;corrects&amp;quot;, or try and untangle the difference between a number that is contained in a numeric cell and one that is stored in a text cell. Then you'll understand. Look here:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.biomedcentral.com/1471-2105/5/80"&gt;http://www.biomedcentral.com/1471-2105/5/80&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://dontuseexcel.wordpress.com/2013/02/07/dont-use-excel-for-biological-data/"&gt;https://dontuseexcel.wordpress.com/2013/02/07/dont-use-excel-for-biological-data/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.bioinformatics.fr/resources.php?id=2528&amp;amp;name=Genes"&gt;http://www.bioinformatics.fr/resources.php?id=2528&amp;amp;name=Genes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://info.5amsolutions.com/blog/bid/120220/Using-Excel-for-Bioinformatics-Data-Five-Issues-Five-Solutions"&gt;http://info.5amsolutions.com/blog/bid/120220/Using-Excel-for-Bioinformatics-Data-Five-Issues-Five-Solutions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Digression: It's often quite hard to avoid Excel, it's so embedded in everyone's workflow. Of course if someone needs a spreadsheet, they're going to use Excel, and so you are forced to deal with it. Even if you personally don't use Excel, it can still cause problems. I once set up a database and a user complained vociferously about how I'd &amp;quot;corrupted the data&amp;quot;. They'd downloaded the data, imported it into Excel, the program 'corrected' the data ...&lt;/p&gt;
&lt;p&gt;On the other hand, Excel has little competition in the 'point and click' creation of graphs and the pivot-table feature is actually very useful. The only thing you can do is aim for least-corruptible formatting. Send and receive data as CSV. Export data in forms that Excel can't interpret and has to treat as plain un-normalisable text.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="open-libreoffice"&gt;
&lt;h3&gt;Open/LibreOffice&lt;/h3&gt;
&lt;p&gt;And now it's okay to poke yourself in the eye with a stick because the stick is ideologically correct?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="langauge-specific-encodings"&gt;
&lt;h3&gt;Langauge-specific encodings&lt;/h3&gt;
&lt;p&gt;Python pickles, .RData, SPSS .spv and .sav files ...  Ask if you always and forever will be using this program. Ask if you and everyone you work with will always have access to this program. Ask  if this format and program that reads it will never change.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="general-rules"&gt;
&lt;h2&gt;General rules&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Where possible, use open, data and platform-agnostic formats. Avoid proprietary formats.&lt;/li&gt;
&lt;li&gt;Where possible, use human readable formats&lt;/li&gt;
&lt;li&gt;Use as simple a format (or tool) as you can get away with.&lt;/li&gt;
&lt;li&gt;Do not invent your own format.&lt;/li&gt;
&lt;li&gt;Seriously, do not invent your own format.&lt;/li&gt;
&lt;li&gt;Go with the crowd and use common tools and formats, so as to leverage others experience.&lt;/li&gt;
&lt;li&gt;Remember the object is not the formatting or storage of the data but the analysis of the data.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="references"&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://redcap.vanderbilt.edu/"&gt;REDCap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://yaml.org/"&gt;YAML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.hobocentral.net/"&gt;Hobo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="Ruby-on-Rails"></category><category term="Rails"></category><category term="data science"></category><category term="CSV"></category><category term="JSON"></category><category term="Excel"></category><category term="SQLite"></category><category term="XML"></category><category term="REDCap"></category></entry><entry><title>Philosophical considerations in manuscript preparation</title><link href="http://www.agapow.net/science/academia/philosophical-considerations-in-manuscript-preparation/" rel="alternate"></link><published>2013-11-11T17:39:00+00:00</published><updated>2013-11-11T17:39:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2013-11-11:/science/academia/philosophical-considerations-in-manuscript-preparation/</id><summary type="html">&lt;div class="section" id="xeno-s-paradox-of-manuscript-completeness"&gt;
&lt;h2&gt;Xeno's paradox of manuscript completeness&lt;/h2&gt;
&lt;p&gt;No matter how many drafts you go through, the number of helpful
suggestions make by your co-authors will approach but never quite reach
zero.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="plato-s-allegory-of-collaborators-and-the-cave-wall"&gt;
&lt;h2&gt;Plato's allegory of collaborators and the cave wall&lt;/h2&gt;
&lt;p&gt;Distinguished or influential co-authors have a tendency to invite,
introduce or insist upon …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="xeno-s-paradox-of-manuscript-completeness"&gt;
&lt;h2&gt;Xeno's paradox of manuscript completeness&lt;/h2&gt;
&lt;p&gt;No matter how many drafts you go through, the number of helpful
suggestions make by your co-authors will approach but never quite reach
zero.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="plato-s-allegory-of-collaborators-and-the-cave-wall"&gt;
&lt;h2&gt;Plato's allegory of collaborators and the cave wall&lt;/h2&gt;
&lt;p&gt;Distinguished or influential co-authors have a tendency to invite,
introduce or insist upon the addition of other co-authors, typically
their staff, old lab-mates or senior scientists they are hoping to
impress. Our circumstances are such that we are unable to directly
observe the actual contribution of these co-authors, but only see it
indirectly, like shadows cast on a cave wall. Or more accurately, as an
entries on the authorship byline.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="sapir-whorf-complaint-hypothesis"&gt;
&lt;h2&gt;Sapir-Whorf complaint hypothesis&lt;/h2&gt;
&lt;p&gt;Linguistic relativity holds that language affects the ways in which its
speakers conceptualize their world, implying there is no guarantee that
two individuals can communicate certain concepts. This why you will
occasionally encounter a co-author who will repeatedly say they are
&amp;quot;dissatisfied&amp;quot; or &amp;quot;unhappy&amp;quot; with a manuscript, but be unable to
articulate what gives rise to this objection or how to correct it. Often
they will only be able to say that &amp;quot;It should be fixed&amp;quot;, without saying
what &amp;quot;it&amp;quot; or the &amp;quot;fix&amp;quot; is.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="relativity-and-the-twin-paradox"&gt;
&lt;h2&gt;Relativity and the twin paradox&lt;/h2&gt;
&lt;p&gt;In this thought experiment, there are two identical twins, one stays on
Earth while the other makes a journey into space in a high-speed rocket.
You ask both for comments on a manuscript &amp;quot;by the end of the week&amp;quot;. The
one on Earth sends you their comments within the week, while the second
sends you their comments two months later, on a now out-dated version of
the manuscript. Clearly the second has experienced time-dilation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="searle-s-chinese-room"&gt;
&lt;h2&gt;Searle's Chinese Room&lt;/h2&gt;
&lt;p&gt;A thought experiment which asks whether it is possible to distinguish an
intelligent, well-written broad review from one that is randomly packed
full of references to a Talmudic melange of subjects.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="revision-orbits-and-attractors"&gt;
&lt;h2&gt;Revision orbits and attractors&lt;/h2&gt;
&lt;p&gt;Certain complex systems settle into stable dynamics where they oscillate
through a repeating set of states. This is why the first reviews of your
manuscript will ask for a section to be deleted, the second set of
reviews will lament the absence of the same section and the third set
will label it unnecessary. Regrettably, journal editors are apparently
unschooled in chaos mathematics and refuse to acknowledge this
phenomena.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="parable-of-the-blind-men-and-the-elephant"&gt;
&lt;h2&gt;Parable of the blind men and the elephant&lt;/h2&gt;
&lt;p&gt;In this tale, a group of blind men touch an elephant to learn what it is
like. Each one feels a different part, such as the leg or the tusk,
compares notes and learns that they are in complete disagreement as to
what they have encountered. Similarly, teams of co-authors sometimes
exist in a state where it is unclear what manuscript they are writing or
commenting on, even seeming to disagree what the point of the paper is
and the findings are.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="revising-brain-in-a-vat"&gt;
&lt;h2&gt;Revising brain in a vat&lt;/h2&gt;
&lt;p&gt;In this philosophical experiment, a naked brain in placed in a vat of
life-sustaining fluids and wired up such that it receives the same
impulses it would as if it were in a body walking around. The question
therefore is whether a brain - merely from the evidence of its own
sense - can tell whether it is actually in a body or a vat. After 8 hours
sitting in front of a computer, refreshing Mendeley, trying to decipher
referee's comments and failing to get to the gym for the 3rd time this
week, the distinction may be moot.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="lifeboat-ethics"&gt;
&lt;h2&gt;Lifeboat ethics&lt;/h2&gt;
&lt;p&gt;In this metaphor for resource distribution, a group of co-authors are
gathered on a lifeboat at ocean surrounded by hundreds of potential
collaborators. The central dilemma is whether to invite other people
on-board, at the risk of over-loading the boat.&lt;/p&gt;
&lt;p&gt;Most solutions involve ejecting the data analysts and technicians from
the boat, while exhorting the lone grad student at the oars to &amp;quot;row
faster&amp;quot;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="schrodinger-s-citation"&gt;
&lt;h2&gt;Schrodinger's citation&lt;/h2&gt;
&lt;p&gt;Consider a journal submission system as a black box. It cannot be opened
or examined in anyway. A manuscript is submitted into the black box.
What happens inside the box is unclear but in time a response is
emitted, listing many changes that are needed, including requests to
include seemingly irrelevant work (&amp;quot;gene conversion in salamanders&amp;quot;),
calls to cite vaguely described papers which may or may not exist
(&amp;quot;Dubois's work that was in PNAS or PLoS six or eight years ago&amp;quot;), or
the need to compare your work against an arbitrary other study (&amp;quot;how do
your findings on plastid co-evolution reflect on distemper in
muntjacs?&amp;quot;). At this point you wonder what could possibly be going on at
the journal or in the referee's head.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="lady-or-the-tiger"&gt;
&lt;h2&gt;Lady or the Tiger&lt;/h2&gt;
&lt;p&gt;You are presented with two indistinguishable doors. Behind one is a lady
who will accept your manuscript graciously, offer erudite comments,
correct misspellings and then publish it. Behind the other is a tiger.
It devour you and then criticise your choice of controls. You must
choose a door. Which one do you pick?&lt;/p&gt;
&lt;p&gt;Note: experience says that no matter what your strategy, you will always
end up picking the tiger. Better justify those controls better.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="trolley-problem-of-stating-results"&gt;
&lt;h2&gt;Trolley problem of stating results&lt;/h2&gt;
&lt;p&gt;Envisage your manuscript as a trolley-car headed down a set of tracks
towards publication. Looking ahead, you notice that your findings will
run into several other researchers (highlight the limitations of their
approach and invalidating their results). Your co-author points out that
by switching tracks (omitting some discussion, inventing a caveat and
focusing on an improbable explanation), you will instead collide with
the work of a different but lone researcher. What should you do?&lt;/p&gt;
&lt;p&gt;Answer: who is likely to be on your next interview committee?&lt;/p&gt;
&lt;/div&gt;
</content><category term="academia"></category><category term="humour"></category><category term="publications"></category></entry><entry><title>Hitchhikers guide to Biopython: Sequences &amp; alphabets</title><link href="http://www.agapow.net/science/computational-biology/biofoo/hitchhikers-guide-to-biopython-sequences-alphabets/" rel="alternate"></link><published>2013-07-11T13:30:00+01:00</published><updated>2013-07-11T13:30:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2013-07-11:/science/computational-biology/biofoo/hitchhikers-guide-to-biopython-sequences-alphabets/</id><summary type="html">&lt;p&gt;(Originally published on BiocodersHub.)&lt;/p&gt;
&lt;p&gt;If you’re doing bioinformatics in Python, you’re probably
using  &lt;a class="reference external" href="http://biopython.org/"&gt;Biopython&lt;/a&gt;. Actually, Biopython is a
good reason for using Python. But it can be formidable to newcomers:
there’s a lot there and there’s not a huge amount of learning material.
This then is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;(Originally published on BiocodersHub.)&lt;/p&gt;
&lt;p&gt;If you’re doing bioinformatics in Python, you’re probably
using  &lt;a class="reference external" href="http://biopython.org/"&gt;Biopython&lt;/a&gt;. Actually, Biopython is a
good reason for using Python. But it can be formidable to newcomers:
there’s a lot there and there’s not a huge amount of learning material.
This then is the first of a series of rapid introductions to Biopython.&lt;/p&gt;
&lt;div class="section" id="what-is-it-for"&gt;
&lt;h2&gt;What Is It For?&lt;/h2&gt;
&lt;p&gt;What sort of features does it provide? Seemingly everything:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Reading and writing common sequence (and other) file formats&lt;/li&gt;
&lt;li&gt;Classes for the usual datatypes (sequences, alignments etc.)&lt;/li&gt;
&lt;li&gt;Functions for the usual things you’d do with those datatypes (alignments, Blasting)&lt;/li&gt;
&lt;li&gt;Facilities for data base queries&lt;/li&gt;
&lt;li&gt;A very large etc., etc. There’s a lot in there.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The downsides are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Some of it is frankly under-documented&lt;/li&gt;
&lt;li&gt;Having been written by many different authors, there’s a certain inconsistency across the library&lt;/li&gt;
&lt;li&gt;The library is still evolving and some of it is a little bleeding edge&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However these points are improving steadily. There’s been a marked
improvement over the last few years to where BioPython could arguably be
regarded as the best of the BioFoo libraries.&lt;/p&gt;
&lt;div class="section" id="installation"&gt;
&lt;h3&gt;Installation&lt;/h3&gt;
&lt;p&gt;Installing Biopython is mercifully easy:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% easy_install biopython
&lt;/pre&gt;
&lt;p&gt;if you
have  &lt;a class="reference external" href="https://pypi.python.org/pypi/setuptools"&gt;setuptools&lt;/a&gt; or
something similar installed. If not, there are tarballs and binary
packages available. If you’re on a Linux system, there should be a
prebuilt package for most package managers. If you don’t have root
access, Biopython works well with things
like  &lt;a class="reference external" href="https://github.com/utahta/pythonbrew"&gt;python-brew&lt;/a&gt;. There are
a few suggested dependencies (NumPy, ReportLab) but you can install
these later.&lt;/p&gt;
&lt;p&gt;So how do you call the Biopython library? Like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; import Bio
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="sequences"&gt;
&lt;h2&gt;Sequences&lt;/h2&gt;
&lt;p&gt;The most ubiquitous entity in BioPython would be  &lt;em&gt;Seq&lt;/em&gt;, a class for
simple biosequences:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; from Bio import Seq
&amp;gt;&amp;gt;&amp;gt; mySeq = Seq.Seq('ACGTTTGCGC')
&lt;/pre&gt;
&lt;p&gt;This represents a biosequence in the simplest possible way, with it
acting like a string, allowing indexing, using  &lt;em&gt;len()&lt;/em&gt; to get
length, slicing, etc.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; import Bio
&amp;gt;&amp;gt;&amp;gt; from Bio import Seq
&amp;gt;&amp;gt;&amp;gt; mySeq = Seq.Seq ('acggtcggtggggccc')
&amp;gt;&amp;gt;&amp;gt; mySeq
Seq ('acggtcggtggggccc', Alphabet())
&amp;gt;&amp;gt;&amp;gt; mySeq[0]
Seq ('a', Alphabet())
&amp;gt;&amp;gt;&amp;gt; mySeq[:5]
Seq ('acggt', Alphabet())
&amp;gt;&amp;gt;&amp;gt; mySeq[:5] + mySeq[-3:]
Seq ('acggtccc', Alphabet())
&lt;/pre&gt;
&lt;p&gt;Note that the  &lt;em&gt;Seq&lt;/em&gt; class is found inside the  &lt;em&gt;Seq&lt;/em&gt; module,
which invariably confuses novices.&lt;/p&gt;
&lt;p&gt;Another point for confusion is that there is another
class  &lt;em&gt;SeqRecord&lt;/em&gt;. What’s the different? A  &lt;em&gt;SeqRecord&lt;/em&gt; wraps
a  &lt;em&gt;Seq&lt;/em&gt; and all the ancillary information about a sequence, like
annotations and so on. A  &lt;em&gt;Seq&lt;/em&gt; is &lt;em&gt;just&lt;/em&gt; the sequence,
a  &lt;em&gt;SeqRecord&lt;/em&gt; is the sequence and all associated data. Be warned:
some Biopython functions take Seqs, others take SeqRecords.&lt;/p&gt;
&lt;p&gt;Just for the moment, I’m going to ignore  &lt;em&gt;SeqRecords&lt;/em&gt; because we
need to talk about …&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="alphabets"&gt;
&lt;h2&gt;Alphabets&lt;/h2&gt;
&lt;p&gt;You would have noticed  &lt;em&gt;Alpbabet&lt;/em&gt; in the code up above. Obviously
the legal “letters” in a (say) mRNA sequence differ from those in a
protein transcript. A Biopython alphabet dictates the allowable symbols
in a sequence and how they are used. An  &lt;em&gt;Alphabet&lt;/em&gt; governs the
conversion &amp;amp; compatibility of sequences. You can’t combine two Seqs with
incompatible alphabets. Common alphabets are defined
in  &lt;em&gt;Bio.Alphabet.IUPAC&lt;/em&gt;, with useful functions being held
in &lt;em&gt;Bio.Alphabet&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;(It may seem like I’m spending a lot of words on Alphabets: this is due
to my observation that they’re one of the more neglected and
misunderstood areas in Biopython. But once you know what they do, you
largely can ignore them.)&lt;/p&gt;
&lt;p&gt;There’s a whole hots of standard alphabets defined by Biopython. But
what if you need to make your own?&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; import Bio
&amp;gt;&amp;gt;&amp;gt; from Bio import Alphabet
&amp;gt;&amp;gt;&amp;gt; from Alphabet import IUPAC
&amp;gt;&amp;gt;&amp;gt; GAPPEDAMBIG_DNA_ALPHABET = Alphabet.Gapped (
IUPAC.ambiguous_dna, '-')
&amp;gt;&amp;gt;&amp;gt; LegalDnaLetters = IUPAC.ambiguous_dna.letters
&amp;gt;&amp;gt;&amp;gt; LegalGappedDnaLetters = GAPPEDAMBIG_DNA_ALPHABET.letters
&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;Simple.&lt;/p&gt;
&lt;p&gt;As said, you can only combine sequences with compatible alphabets types.
This means, DNA with DNA, protein with protein etc. If you combined two
sequences with compatible but different alphabets, the result ‘promotes’
to more general type. By and large, this works as you would expect:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; seq_ud = Seq ('acgt', unambiguous_dna)
&amp;gt;&amp;gt;&amp;gt; seq_ad = Seq ('acgt', ambiguous_dna)
&amp;gt;&amp;gt;&amp;gt; seq_ur = Seq ('acgt', unambiguous_rna)
&amp;gt;&amp;gt;&amp;gt; seq_p = Seq ('acgt', protein)
&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;What happens?:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; seq_ud + seq_ad
Seq('acgtacgt', IUPACAmbiguousDNA())
&amp;gt;&amp;gt;&amp;gt; seq_ud + seq_ur
TypeError Traceback (most recent call last)
...
TypeError: Incompatible alphabets IUPACUnambiguousDNA() and IUPACUnambiguousRNA()
&amp;gt;&amp;gt;&amp;gt; seq_ud + seq_p
TypeError Traceback (most recent call last)
...
TypeError: Incompatible alphabets IUPACUnambiguousDNA() and IUPACProtein()
&lt;/pre&gt;
&lt;p&gt;Note that alphabets are no guarantee. It is still entirely possible to
assign rubbish letters into a sequence. The
method  &lt;em&gt;Seq.verify_alphabet()&lt;/em&gt; can be used to manually check if a
seq conforms to an alphabet.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="back-to-sequences"&gt;
&lt;h2&gt;Back to sequences&lt;/h2&gt;
&lt;p&gt;Having considered alphabets, we can now look at some of
the  &lt;em&gt;Seq&lt;/em&gt; methods that use alphabets. For example, getting the
complement of a sequence will obviously depend on the alphabet:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; mySeq = Seq ('acggtcggtggggccc')
&amp;gt;&amp;gt;&amp;gt; mySeq.complement()
Seq('tgccagccaccccggg', Alphabet())
&amp;gt;&amp;gt;&amp;gt; mySeq.reverse_complement()
Seq('gggccccaccgaccgt', Alphabet())
&lt;/pre&gt;
&lt;p&gt;Transcription can be handled by standalone functions in  &lt;em&gt;Seq&lt;/em&gt; (the
module) not  &lt;em&gt;Seq&lt;/em&gt; (the class):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;em&gt;transcribe(seq_or_str)&lt;/em&gt;: DNA to RNA&lt;/li&gt;
&lt;li&gt;&lt;em&gt;back_transcribe(seq_or_str)&lt;/em&gt;: RNA to DNA&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DNA to protein Translation can be most simply handled by the
method  &lt;em&gt;translate&lt;/em&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; mySeq.translate()
Seq('TVGGA', ExtendedIUPACProtein())
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="reading-and-writing-sequences"&gt;
&lt;h2&gt;Reading and writing sequences&lt;/h2&gt;
&lt;p&gt;A warning: there are actually many ways of reading and writing sequence
data in Biopython. Most of them are old, clunky and deprecated. The new
hotness is  &lt;em&gt;SeqIO&lt;/em&gt; and you should use only that. Behold:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; from Bio import SeqIO
&amp;gt;&amp;gt;&amp;gt; in_hndl = open ('myseqs.fasta', 'rU')
&amp;gt;&amp;gt;&amp;gt; for s in SeqIO.parse (in_hndl, 'fasta'):
# do something with the sequence you just read
print s
&amp;gt;&amp;gt;&amp;gt; in_hndl.close()
&lt;/pre&gt;
&lt;p&gt;In plain English:  &lt;em&gt;SeqIO.parse&lt;/em&gt; takes an open file (or file-like
object) and the name of the format (in lower case) and iterates over the
SeqRecords within. (Note:: SeqRecords not Seqs). Format  &lt;em&gt;SeqIo&lt;/em&gt; can
understand include clustal, genbank, qual, fastq, nexus …&lt;/p&gt;
&lt;p&gt;What if you just want to capture of the the sequences in a file, say in
a list. Do something like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; in_hndl = open (&amp;quot;opuntia.aln&amp;quot;, &amp;quot;rU&amp;quot;)
&amp;gt;&amp;gt;&amp;gt; seq_list = [s for s in SeqIO.parse (in_hndl, &amp;quot;clustal&amp;quot;)]
&amp;gt;&amp;gt;&amp;gt; in_hndl.close()
&lt;/pre&gt;
&lt;p&gt;or even:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; records = list (SeqIO.parse (open (&amp;quot;myaln.fasta&amp;quot;, 'rU'), &amp;quot;fasta&amp;quot;)
&lt;/pre&gt;
&lt;p&gt;Note: SeqIO will not guess at the format of a file from the name.
Conversely, the file name extension doesn’t have to match the actual
format.&lt;/p&gt;
&lt;p&gt;Writing out sequences is just as deliriously easy. Feed a list of
SeqRecords, a file handle and a format to  &lt;em&gt;Bio.SeqIO.write()&lt;/em&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# my_seqs is a list or iterator of seqrecords
&amp;gt;&amp;gt;&amp;gt; out_hndl = open (&amp;quot;dump.fasta&amp;quot;, &amp;quot;w&amp;quot;)
&amp;gt;&amp;gt;&amp;gt; SeqIO.write (my_seqs, out_hndl, &amp;quot;fasta&amp;quot;)
&amp;gt;&amp;gt;&amp;gt; out_hndl.close()
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="resources"&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www2.warwick.ac.uk/fac/sci/moac/currentstudents/peter_cock/python/sequences/"&gt;Coming to grips with BioPythons alphabet system&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.pasteur.fr/recherche/unites/sis/formation/python/ch11s03.html"&gt;Seq &amp;amp; SeqRecord&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://biopython.org/wiki/SeqIO"&gt;SeqIO&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="BioPython"></category><category term="biosequences"></category><category term="computational biology"></category><category term="Python"></category></entry><entry><title>Writing knitr in restructured text</title><link href="http://www.agapow.net/science/data-science/writing-knitr-in-restructured-text/" rel="alternate"></link><published>2012-09-01T12:00:00+01:00</published><updated>2012-09-01T12:00:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2012-09-01:/science/data-science/writing-knitr-in-restructured-text/</id><summary type="html">&lt;p&gt;&lt;em&gt;knitr&lt;/em&gt; is a useful R package/tool for documenting analysis. Basically,
it allows the embedding of R code &amp;quot;chunks&amp;quot; within a simple text
document. This document can then be &amp;quot;knitted&amp;quot;, which means that the R
code is interpreted and reinserted in the document along with the
results of that code …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;knitr&lt;/em&gt; is a useful R package/tool for documenting analysis. Basically,
it allows the embedding of R code &amp;quot;chunks&amp;quot; within a simple text
document. This document can then be &amp;quot;knitted&amp;quot;, which means that the R
code is interpreted and reinserted in the document along with the
results of that code. Thus analyses can accompany their results, be they
numeric or graphical.&lt;/p&gt;
&lt;p&gt;An arguably problematic point with knitr is the primary document markup
language: Markdown. Markdown is easy to write, but a little
under-powered compared to its competitor, restructured Text (rst), which
is very popular amongst Python users. Fortunately, knitr also
understands rst. Unfortunately, it's not completely clear how you use
it. This then is my set of notes about writing knitr documents in rst.&lt;/p&gt;
&lt;div class="section" id="technical-environment"&gt;
&lt;h2&gt;Technical environment&lt;/h2&gt;
&lt;p&gt;R 2.15.3 on R Studio 0.97, running under Ubuntu 12.10, using knitr
version 1.1.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="file-extensions"&gt;
&lt;h2&gt;File extensions&lt;/h2&gt;
&lt;p&gt;The commonly suggested extension for a knitr restructured text file
is  &lt;tt class="docutils literal"&gt;.Rst&lt;/tt&gt;. The standard restructured text extension is, of
course,  &lt;tt class="docutils literal"&gt;.rst&lt;/tt&gt;. Apart from causing some confusion (i.e. a &lt;tt class="docutils literal"&gt;.Rst&lt;/tt&gt;
file is converted to a &lt;tt class="docutils literal"&gt;.rst&lt;/tt&gt; file), this may cause legitimate problems
in filesystems that are case insensitive (e.g. MacOS). It's far better
to use  &lt;tt class="docutils literal"&gt;.Rrst&lt;/tt&gt;. This is logical and while not a three letter
extension, it shouldn't cause any problem in this day and age. It's also
recognised automatically by knitr.&lt;/p&gt;
&lt;p&gt;There is an alternative naming scheme where  &lt;tt class="docutils literal"&gt;_knit_&lt;/tt&gt; is embedded in
the file name and stripped in conversion. That
is  &lt;tt class="docutils literal"&gt;my_exp_knit_.rst&lt;/tt&gt; becomes &lt;tt class="docutils literal"&gt;my_exp.rst&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ides-and-production"&gt;
&lt;h2&gt;IDEs and production&lt;/h2&gt;
&lt;p&gt;Unfortunately, R Studio doesn't handle rst-formatted knitr docs, so
several of the steps that it handles gracefully for Markdown-flavoured
knitr have to be done manually:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Create the rst-knitr doc as a text file. Name it appropriately.&lt;/li&gt;
&lt;li&gt;Edit your document as rst.&lt;/li&gt;
&lt;li&gt;Prepare for conversion by loading the knitr libraries (&lt;tt class="docutils literal"&gt;library (knitr)&lt;/tt&gt;) and changing to the directory of your source (e.g. &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;setwd(&amp;quot;~/Documents/Projects/R/Writing&amp;quot;)&lt;/span&gt;&lt;/tt&gt;).&lt;/li&gt;
&lt;li&gt;Convert your document with  &lt;tt class="docutils literal"&gt;knit (&amp;quot;mydo.Rrst&amp;quot;)&lt;/tt&gt; (or &lt;tt class="docutils literal"&gt;knit2html&lt;/tt&gt; etc.)&lt;/li&gt;
&lt;li&gt;Examine the output&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The actual R code is embedded in rst with an explicit directive. Start
the code chunk with  &lt;tt class="docutils literal"&gt;.. {r [label] [, option_list]}&lt;/tt&gt; and end it
with  &lt;tt class="docutils literal"&gt;.. ..&lt;/tt&gt; (note the space between). For example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
.. {r example_code}

x &amp;lt;- 1+1
rnorm(5)

.. ..
&lt;/pre&gt;
&lt;p&gt;which will output something like:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
.. sourcecode:: r

x &amp;lt;- 1 + 1
rnorm(5)

::

## [1] -1.0678 -0.2180 -1.0260 -0.7289 -0.6250
&lt;/pre&gt;
&lt;p&gt;Inline R code can be written with the  &lt;tt class="docutils literal"&gt;:r:&lt;/tt&gt; role. For example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
This is text with the value :r:`pi` embedded within it.
&lt;/pre&gt;
&lt;p&gt;becomes:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
This is text with the value 3.1416 embedded within it.
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="shortcomings-and-other-notes"&gt;
&lt;h2&gt;Shortcomings and other notes&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;There doesn't seem to be any issue with indenting or using blank lines inside a chunk. The delimiters are the important part.&lt;/li&gt;
&lt;li&gt;Conversely, trying to literally quote a chunk (i.e. using  &lt;tt class="docutils literal"&gt;::&lt;/tt&gt; and indenting to display a chunk and not actually interpret it) or inline code is problematic - knitr will process it regardless of the indenting. Presumably this is because the knitting works on a brute force pattern match rather than the directive and role interpretation it looks like.&lt;/li&gt;
&lt;li&gt;There is another way of marking out code chunks, which is to preface each line with a double dot  &lt;tt class="docutils literal"&gt;..&lt;/tt&gt;. However, I have never been able to get this to work as it is always marked as a parser error.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;knit2pdf&lt;/tt&gt; doesn't seems to work with rst documents, because of some malformed intermediate  &lt;tt class="docutils literal"&gt;texi&lt;/tt&gt; file being generated. However  &lt;tt class="docutils literal"&gt;rst2pdf&lt;/tt&gt; could be used instead.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="references"&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;knitr:  &lt;a class="reference external" href="http://yihui.name/knitr/"&gt;http://yihui.name/knitr/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Restructured text:  &lt;a class="reference external" href="http://docutils.sourceforge.net/rst.html"&gt;http://docutils.sourceforge.net/rst.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R Studio:  &lt;a class="reference external" href="http://www.rstudio.com"&gt;http://www.rstudio.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="knitr"></category><category term="r"></category><category term="reproducibility"></category><category term="restructured-text"></category></entry><entry><title>Common tasks in Galaxy</title><link href="http://www.agapow.net/science/computational-biology/galaxy/common-tasks-in-galaxy/" rel="alternate"></link><published>2012-06-14T12:56:00+01:00</published><updated>2012-06-14T12:56:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2012-06-14:/science/computational-biology/galaxy/common-tasks-in-galaxy/</id><summary type="html">&lt;p&gt;&lt;em&gt;It's all there in the documentation, but sometimes it's hard to find.
This document gives you another place to look.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So how do I ...&lt;/p&gt;
&lt;div class="section" id="create-admin-users"&gt;
&lt;h2&gt;... create admin users?&lt;/h2&gt;
&lt;p&gt;Curiously, the identity of admin users is hardcoded into the Galaxy
configuration file. (Which makes it secure, I guess, but separate from
the …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;It's all there in the documentation, but sometimes it's hard to find.
This document gives you another place to look.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So how do I ...&lt;/p&gt;
&lt;div class="section" id="create-admin-users"&gt;
&lt;h2&gt;... create admin users?&lt;/h2&gt;
&lt;p&gt;Curiously, the identity of admin users is hardcoded into the Galaxy
configuration file. (Which makes it secure, I guess, but separate from
the rest of Galaxy's role mechanism.) Edit universe_wsgi.ini and set
admin_users to a comma delimited list of user emails:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
admin_users = user1&amp;#64;hpa.org.uk,user2&amp;#64;bbsrc.ac.uk
&lt;/pre&gt;
&lt;p&gt;The Admin menu will then appear on the top menubar.&lt;/p&gt;
&lt;p&gt;See
&lt;a class="reference external" href="https://bitbucket.org/galaxy/galaxy-central/wiki/Admin/AdminInterface"&gt;https://bitbucket.org/galaxy/galaxy-central/wiki/Admin/AdminInterface&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Note: The admin document is as yet, a trifle incomplete. It's unclear
what happens if one of these addresses is invalid (i.e. is for a
non-existent user). Also note a confusion about identifying a user -
sometimes Galaxy refers to user name and sometimes to user email
address.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="disable-guest-access"&gt;
&lt;h2&gt;... disable guest access?&lt;/h2&gt;
&lt;p&gt;By default, galaxy allows any jackass with a web-browser to run tools.
(Although their history is not retained.) Again, edit universe_wsgi.ini
and set require_login:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# Force everyone to log in (disable anonymous access).
require_login = True
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="disable-self-registration"&gt;
&lt;h2&gt;... disable self-registration?&lt;/h2&gt;
&lt;p&gt;By default, any guest (visitor) can register an account on a Galaxy
instance. Once again, edit universe_wsgi.ini and set
allow_user_creation&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# Allow unregistered users to create new accounts (otherwise,
# they will have to be created by an admin).
#allow_user_creation = True
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="reset-a-user-s-password"&gt;
&lt;h2&gt;... reset a user's password?&lt;/h2&gt;
&lt;p&gt;(Digression: of course, if a user forgets their password, they could
just reset it themselves to have email sent to them. But we have a
Galaxy instance without email configured an so another way is needed.)&lt;/p&gt;
&lt;p&gt;In the admin menu, go to manage users, select the user and then &amp;quot;reset
password&amp;quot;. You'll come to a page where you can actually set their
password.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="stop-a-job"&gt;
&lt;h2&gt;... stop a job?&lt;/h2&gt;
&lt;p&gt;Perhaps it's a runaway job. Perhaps it's been running for too long.
Maybe you're just bored. The important thing is that THE JOB MUST DIE.&lt;/p&gt;
&lt;p&gt;When logged in as an adminstrator, go to the admin menu and then the
manage jobs tool. A message can be sent to the user when this is done.
This can also be used to stop new jobs from being dispatched, such as
when preparing for shutdown.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="make-someone-an-admin-for-this-data-library-whatever-and-nothing-else"&gt;
&lt;h2&gt;... make someone an admin for this data / library / whatever and nothing else?&lt;/h2&gt;
&lt;p&gt;Can't be done. Galaxy has a fairly simple idea of admins: a superuser is
a superuser is a superuser. An administrator can do _anything_. You
can give someone permissions management over a data library, but that's
it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="do-x-by-directly-editing-the-database"&gt;
&lt;h2&gt;... do X by directly editing the database?&lt;/h2&gt;
&lt;p&gt;Don't. It's severely messy down there and anything could go wrong.
Seriously - the schema is complex and it's hard to make even simple
edits.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="maintain-galaxy"&gt;
&lt;h2&gt;... maintain Galaxy?&lt;/h2&gt;
&lt;p&gt;Users are advised to run the scripts in
&lt;em&gt;&amp;lt;galaxy-dist&amp;gt;/scripts/cleanup_datasets/cleanup_dataset.py&lt;/em&gt; regularly
/ daily, so as to mop up old and deleted data. (Although there's so many
scripts in that dir, it'd be nice to get a heads-up about which did what
and were how important.) A cron'd script to call them all like this
should do the job:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#!/bin/sh
cd /home/galaxy/galaxy-dist
bash ./scripts/cleanup_datasets/delete_datasets_main.sh
bash ./scripts/cleanup_datasets/delete_userless_histories_main.sh
bash ./scripts/cleanup_datasets/purge_histories_main.sh
bash ./scripts/cleanup_datasets/purge_datasets_main.sh
&lt;/pre&gt;
&lt;p&gt;From Greg Von Kuster
&amp;lt;&lt;a class="reference external" href="http://lists.bx.psu.edu/pipermail/galaxy-dev/2010-February/001987.html"&gt;http://lists.bx.psu.edu/pipermail/galaxy-dev/2010-February/001987.html&lt;/a&gt; &amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="make-development-easier"&gt;
&lt;h2&gt;... make development easier?&lt;/h2&gt;
&lt;p&gt;Strangely, there's a really useful utility for devs hidden in the Admin
menu: &amp;quot;Reload a tool's configuration&amp;quot;. It seesm to do what it says on
the tin - reload the tooo configuration files, which normally would take
an instance restart. Oddly, the reload is only offered for a subset of
the installed tools, so there may be some subtleties involved here.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="also-see"&gt;
&lt;h2&gt;Also see&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Notes from the Mattick Lab &lt;a class="reference external" href="http://matticklab.com/index.php?title=Setting_up_Galaxy"&gt;http://matticklab.com/index.php?title=Setting_up_Galaxy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The Galaxy wiki &lt;a class="reference external" href="http://bitbucket.org/galaxy/galaxy-central/wiki"&gt;http://bitbucket.org/galaxy/galaxy-central/wiki&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="computational biology"></category><category term="galaxy"></category></entry><entry><title>Compiling Quickjoin and file formats</title><link href="http://www.agapow.net/science/computational-biology/tools/compiling-quickjoin-and-file-formats/" rel="alternate"></link><published>2012-06-14T12:56:00+01:00</published><updated>2012-06-14T12:56:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2012-06-14:/science/computational-biology/tools/compiling-quickjoin-and-file-formats/</id><summary type="html">&lt;p&gt;&lt;em&gt;Problems with building qjoin and getting it to read stockholm files.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.birc.dk/Software/QuickJoin"&gt;Quickjoin / qjoin&lt;/a&gt; is an
excellent commandline program for rapid construction of
neighbour-joining trees. However, while using it recently, I had a few
problems getting it to read Stockholm files, the most accessible of the
formats it can use.&lt;/p&gt;
&lt;p&gt;The …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;Problems with building qjoin and getting it to read stockholm files.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.birc.dk/Software/QuickJoin"&gt;Quickjoin / qjoin&lt;/a&gt; is an
excellent commandline program for rapid construction of
neighbour-joining trees. However, while using it recently, I had a few
problems getting it to read Stockholm files, the most accessible of the
formats it can use.&lt;/p&gt;
&lt;p&gt;The initial problem was that qjoin uses the &lt;em&gt;popt&lt;/em&gt; library for
commandline option parsing. This library is on most Unix(-like) systems,
but if not available, qjoin will compile anyway but with a much reduced
series of options and capabilities. Two of the missing capabilities are
the ability to read stockholm&amp;nbsp;formatted&amp;nbsp;files and do bootstraps. So,
installing popt is advised. However this can a lengthy and intricate
procedure, so getting an install from a package manager like
&lt;a class="reference external" href="http://www.macports.org/"&gt;MacPorts&lt;/a&gt; is advised.&lt;/p&gt;
&lt;p&gt;(In the authors defence, this is made clear in the documentation,
although the implications aren't clear.)&lt;/p&gt;
&lt;p&gt;The next problem is that sometimes the software will refuse to compile.
The ./configure command can fail with an error like:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
./config.status: line 426: syntax error near unexpected token `}' ./config.status: line 426: `} &amp;gt;&amp;amp;5'
&lt;/pre&gt;
&lt;p&gt;This is not a problem with qjoin, but with the underlying configuration
software which can't handle being in a directory with an apostrophe in
it's name (i.e. &amp;quot;can't compile qjoin&amp;quot;). Changing the name of the
directory (i.e. &amp;quot;cant compile qjoin&amp;quot;) fixed things.&lt;/p&gt;
&lt;p&gt;A final issue occurred when it failed to read certain input sequence
files, reporting that no sequences were present and:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Assertion failed: (seq), function read_alignment, file alignment.cc, line 234.
&lt;/pre&gt;
&lt;p&gt;This issue here is that qjoin has a maximum allowed line length when
reading Stockholm files and if the line exceeds that length, it is just
skipped. This behaviour (and the&amp;nbsp;length&amp;nbsp;limit) can be changed by editing
line 192 in the file alignment.cc:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#define MAX_LINE_LEN 4096
&lt;/pre&gt;
&lt;p&gt;to the value required.&lt;/p&gt;
&lt;div class="section" id="one-more-thing"&gt;
&lt;h2&gt;One more thing&lt;/h2&gt;
&lt;p&gt;More recent versions of gcc have done some header cleanup (see
&lt;a class="reference external" href="http://gcc.gnu.org/gcc-4.3/porting_to.html"&gt;http://gcc.gnu.org/gcc-4.3/porting_to.html&lt;/a&gt;), which means that certain
functions which used to be automatically or incidentally included are no
longer, which means that a world of pain and editing the source to get
this to compile. You need to add explicit inclusions of libraries to a
number of files. These are all of the form:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#include &amp;lt;foo&amp;gt;
&lt;/pre&gt;
&lt;p&gt;So, profile.cc and profile2.cc need:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#include &amp;lt;cstring&amp;gt;
&lt;/pre&gt;
&lt;p&gt;alignment-test.cc needs:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#include &amp;lt;cstdio&amp;gt;
&lt;/pre&gt;
&lt;p&gt;qjoin.cc needs:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#include &amp;lt;memory&amp;gt; #include &amp;lt;cstring&amp;gt;
&lt;/pre&gt;
&lt;p&gt;result-tree.cc needs:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#include &amp;lt;algorithm&amp;gt;
&lt;/pre&gt;
&lt;p&gt;result-tree.cc needs:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#include &amp;lt;algorithm&amp;gt;
&lt;/pre&gt;
&lt;p&gt;matrix.cc needs:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#include &amp;lt;cstdio&amp;gt; #include &amp;lt;memory&amp;gt;
&lt;/pre&gt;
&lt;p&gt;alignment.cc needs:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#include &amp;lt;memory&amp;gt; #include &amp;lt;cstring&amp;gt; #include &amp;lt;cstdio&amp;gt;
&lt;/pre&gt;
&lt;p&gt;(For reasons that aren't clear to me, a different installation of qjoin
required only a few of these to be fixed. Subtly different versions of
gcc?)&lt;/p&gt;
&lt;/div&gt;
</content></entry><entry><title>Galaxy toolsheds</title><link href="http://www.agapow.net/science/computational-biology/galaxy/galaxy-toolsheds/" rel="alternate"></link><published>2012-06-14T12:56:00+01:00</published><updated>2012-06-14T12:56:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2012-06-14:/science/computational-biology/galaxy/galaxy-toolsheds/</id><summary type="html">&lt;p&gt;Galaxy toolsheds&lt;/p&gt;
&lt;p&gt;Relatively painless tool-sharing&lt;/p&gt;
&lt;p&gt;This is a more recent innovation in Galaxy, which can make it a
somewhat confused one: the concept of the toolshed has changed over its
lifetime, the documentation is incomplete, and there's a slightly
strange emphasis in the documentation that exists. So …&lt;/p&gt;
&lt;div class="section" id="mile-high-description"&gt;
&lt;h2&gt;Mile-high description&lt;/h2&gt;
&lt;p&gt;Toolsheds …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Galaxy toolsheds&lt;/p&gt;
&lt;p&gt;Relatively painless tool-sharing&lt;/p&gt;
&lt;p&gt;This is a more recent innovation in Galaxy, which can make it a
somewhat confused one: the concept of the toolshed has changed over its
lifetime, the documentation is incomplete, and there's a slightly
strange emphasis in the documentation that exists. So …&lt;/p&gt;
&lt;div class="section" id="mile-high-description"&gt;
&lt;h2&gt;Mile-high description&lt;/h2&gt;
&lt;p&gt;Toolsheds are webapps just like Galaxy. They provides a way of sharing
Galaxy tools, installing them into a Galaxy instance from within that
instance (i.e. through the web), and being notified and obtaining
updates to those tools. There's an official toolshed, a test one and you
can set up your own.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="installing-tools-from-the-standard-sheds"&gt;
&lt;h2&gt;Installing tools from the standard sheds&lt;/h2&gt;
&lt;p&gt;You need to be an administrator. Go into the admin menu and on the
side you will see “Search and browse tool sheds”. Click this and you
will get a list of the sheds available to you. Click on any of these and
you get the choices for the individual repository: browse, search for
tools, search for workflows.  **
** &lt;strong&gt;NOTE:&lt;/strong&gt; an irritating feature of the way the sheds are set up is
that as you descend into the shed, there's few explicit up/back links to
take you to where you just were or a category higher. You'll have to use
your back button.    By search or browse, you'll end up on an index page
listing tools. These will (strangely) give a button going to the tool, a
description, the versions available and the owner/creator. Click on the
button for one and you'll get a popup “Preview and install”. This is a
complicated way of saying “go to the individual tool page”. Do that. The
tool page will a bunch of information of the tool - actually tools if
the package installs more than one. But the important button is in the
top-right: “Install to Local Galaxy”. (the other button “Too shed
asctions”, is a duplicate of the top level button giving you browse or
search choices. It's an odd UI.) If you click the install button, you'll
be offered the choice of putting the new tool(s) in a pre-existing
section or a new one you create. Make a choice and then click “install”
at the bottom of the page. After some minutes, it will appear in your
instance.    &lt;strong&gt;NOTE:&lt;/strong&gt; downloaded tools are actually placed in a
directory ../shed_tools, i.e. outside your actual galaxy directory.
(Strange, but an illustration of the point that tools can actually live
anywhere.) They're also stored
as  &lt;a class="reference external" href="http://mercurial.selenic.com/"&gt;mercurial&lt;/a&gt; repositories.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="running-your-own-toolshed"&gt;
&lt;h2&gt;Running your own toolshed&lt;/h2&gt;
&lt;p&gt;You might want to do this if you want to manage custom tools for your
own Galaxy instance that you don't want to pass to the outside world.
And it's dead easy. The toolshed app is included with the main Galaxy
distribution and lives alongside it. Three key points:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The configuration details for the toolshed live
in community_wsgi.ini&lt;/li&gt;
&lt;li&gt;You run the toolshed with sh run_community.sh&lt;/li&gt;
&lt;li&gt;The toolshed uses a different database to the main Galaxy instance&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Various of the necessary web configuration details can be found in the
links below and are similar to those used by Galaxy. Some points worth
highlighting:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;port &amp;amp; host: should be set to where you want the toolshed to be
available from&lt;/li&gt;
&lt;li&gt;database_file: this is if you want to use the sqlite3 db. I had some
problems with this, which were eventually solved by setting the path
correctly for insertion in an sqlite protocol string
(e.g./database/community.sqlite for a relative path setting the file
in the database folder&lt;/li&gt;
&lt;li&gt;file_path: again, had some problems with this, which were solved by
creating the directory for the file (e.g. &amp;lt;galaxy
inst&amp;gt;/database/community_files) explicitly&lt;/li&gt;
&lt;li&gt;admin_users: like the main Galaxy installation, for setting the
admins&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One more thing must be done before users can upload tools to your
shed: an admin has to create categories before any tools can be
uploaded. Look under Admin / Browse catgeories. (Oddly, users don't
actually have to assign a tool to categories when they create them, But
there must be a category.)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="using-a-local-toolshed"&gt;
&lt;h2&gt;Using a local toolshed&lt;/h2&gt;
&lt;p&gt;Here we mean “using” in terms of putting tools up for other Galaxy
installations to download. You'll have to sign up to your toolshed to do
this - it may live in the same directory as the main app, but it doesn't
share data. Look on the toolbar under  &lt;em&gt;User / Register&lt;/em&gt; Now you have
to create a create a repository to store your tool. Check out on the
sidebar  &lt;em&gt;Create new repository&lt;/em&gt;. You'll have to enter a bunch of
descriptive text / metadata. Afterwards, you'll have the choice of
uploading files to your new repo. While you can upload bz2 and gzipped
archives, which are unpacked automagically. (There's some confusion
here, where the examples also indicates that tar is unpacked, which some
opaque nesting rules.)    You may run into an infuriating TypeError:
array item must be char which is a problem that apparently occurs
randomly, but is solved in more recent versions of the toolshed. Update
your code.   Your account that the toolshed is running under will also
need credentials for using mercurial. In it's home directory, there'll
be a .hgrc file, which should look something like this:   [ui] username
= My Name &amp;lt;&lt;a class="reference external" href="mailto:my-name&amp;#64;example.com"&gt;my-name&amp;#64;example.com&lt;/a&gt;&amp;gt; [web] allow_archive = bz2, gz, zip The
last line defines the archive types that you can download source code
as. Confusingly, the toolshed will offer you the choice of downloading
types that aren't allowed (&amp;quot;Download as [tar.gz|tar.bz2 ...]&amp;quot;) and then
spit back an error  &amp;quot;Archive type is not allowed&amp;quot;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="further-reading"&gt;
&lt;h2&gt;Further reading&lt;/h2&gt;
&lt;p&gt;Toolsheds have their  &lt;a class="reference external" href="http://wiki.g2.bx.psu.edu/Tool%20Shed"&gt;wiki
page&lt;/a&gt;, although it is
strangely preoccupied with running your own toolshed and the technical
underpinnings&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="installing-a-tool-manually"&gt;
&lt;h2&gt;Installing a tool manually&lt;/h2&gt;
&lt;p&gt;The easiest way to get a tool is by using a recent version of Galaxy and
downloading from the toolshed. But sometimes it happens that a tool is
not available in the toolshed, or that it is a toolshed you're not
linked to, or that a more recent version is available from elsewhere. So
you're going to have to manually install the tool from source. The steps
are essentially:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Obtain tarball/archive of tool&lt;/li&gt;
&lt;li&gt;Unpack&lt;/li&gt;
&lt;li&gt;Put folder in the tools folder of the galaxy instance&lt;/li&gt;
&lt;li&gt;Add the tool entry to the tool_conf.xml file&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="manually-downloading-from-toolshed"&gt;
&lt;h3&gt;Manually downloading from toolshed&lt;/h3&gt;
&lt;p&gt;You can download a tool tarball from a toolshed, it's just a bit hidden.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Go to the toolshed site of your choice&lt;/li&gt;
&lt;li&gt;Find the index listing containing the tool you are interested in (the
page with a table headed “Name … Synopsis … Author”)&lt;/li&gt;
&lt;li&gt;Click on the tool name/button to get to the individual tool page&lt;/li&gt;
&lt;li&gt;Click the button in the upper right labelled “repository actions” and
on the popup select “Download as a ” in the desired format&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="configure-tool"&gt;
&lt;h4&gt;Configure tool&lt;/h4&gt;
&lt;p&gt;Add an entry in an appropriate place to the tool-conf.xml in the root
of your galaxy instance. It should look something like this: &amp;lt;section
name=&amp;quot;Get Data&amp;quot; id=&amp;quot;getext&amp;quot;&amp;gt; &amp;lt;tool file=&amp;quot;data_source/upload.xml&amp;quot;/&amp;gt;
&amp;lt;tool file=&amp;quot;MY_TOOL_DIR/MY_TOOL_CONF.xml&amp;quot; /&amp;gt; &amp;lt;tool
file=&amp;quot;data_source/ucsc_tablebrowser.xml&amp;quot; /&amp;gt; ... where MY_TOOL_DIR is
the name of the folder you placed in the tools dir and
MY_TOOL_CONF.xml is the xml configuration file in that folder. See
notes on tool development for further details. Restart your Galaxy
instance to get it to pick up the new tool. If the tool does not show up
in the right place on the tool menu, you've fucked up.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="what-it-looks-like-in-the-end"&gt;
&lt;h4&gt;What it looks like in the end&lt;/h4&gt;
&lt;p&gt;So at the end your file hierarchy should look something like this:
galaxy_dist (instance folder) - tool_conf.xml - tools - MY_TOOL_DIR
- MY_TOOL_CONF.xml - (other tool files including executables)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="computational biology"></category><category term="galaxy"></category></entry><entry><title>Language Wars</title><link href="http://www.agapow.net/science/computational-biology/language-wars/" rel="alternate"></link><published>2012-06-01T12:00:00+01:00</published><updated>2012-06-01T12:00:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2012-06-01:/science/computational-biology/language-wars/</id><summary type="html">&lt;p&gt;(Originally published on BiocodersHub)&lt;/p&gt;
&lt;p&gt;Following several lengthy and passionate discussions in different venues
on what language to use for teaching bioinformatics, I've started
cutting and pasting my reply. And here it is.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;You'll get a lot of different opinions on this because:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;It's a religious issue. That is, it comes …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;(Originally published on BiocodersHub)&lt;/p&gt;
&lt;p&gt;Following several lengthy and passionate discussions in different venues
on what language to use for teaching bioinformatics, I've started
cutting and pasting my reply. And here it is.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;You'll get a lot of different opinions on this because:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;It's a religious issue. That is, it comes down a lot to subjective
judgements and personal experience.&lt;/li&gt;
&lt;li&gt;There's a lot of possible considerations for language choice in
bioinformatics courses:&amp;nbsp;teachable to people who aren't just going to
be programmers and may not have programmed before, has a lot of
useful libraries, has a community behind it, good for quick and dirty
/ one off scripting solutions, useful for web development, fast
enough, etc.&lt;/li&gt;
&lt;li&gt;What &amp;quot;bioinformatics&amp;quot; means to one person and another can be quite
different. &lt;em&gt;I'm a bioinformaticist, you're a computational biologist,
you're a genomicist and they just do a few stats ...&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So a few thoughts about different languages:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Old school compiled languages, e.g. C/C++:&lt;/strong&gt; No. Learning curve too
high, no good for quick-and-dirty problems, weak in web development.
Relatively little bioinformatic work happening here. Not a good place to
start. Sure, it's fast, but Java would be a better place to look.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Java:&lt;/strong&gt; Lots of libraries and BioJava is pretty damn good. However
it's not a great first language, and always feels a bit &amp;quot;heavy&amp;quot; when I'm
trying to do solve a small problem. Still, I expect to see a lot of
development in this area with the JVM enabled languages like Jython,
JRuby, Groovy, where you can script and still use the Java libraries.
Not for novices. Scala may be an interesting new entrance in the high
performance stakes, although I've yet to find anyone using it for
bioinformatics.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Perl:&lt;/strong&gt; was the undisputed choice for bioinformatics 10 years ago but
that lead has evaporated. Quirky, opaque and write once. The whole Perl
6 morass doesn't help. I think you can do better. Still, there's a lot
of code here and a lot of the older significant tools are written in
this (e.g. GBrowse etc.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ruby:&lt;/strong&gt; I've got a love-hate relationship with Ruby. There's a lot of
Good Stuff there, and the web development is excellent. People seem to
like learning Ruby too. But there are a few quirks in the language and
BioRuby is still a work in progress. Still, a lot of enthusiasm here.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Python:&lt;/strong&gt; this is where the weight of attention is. BioPython has
really come along in the last few years and many of the newer, excellent
tools (e.g. Galaxy) are written in it. Easy to learn, kind to beginners,
big community, good scientific computing support (IPython, NumPy, etc.),
decent web programming tools, lots of resources for learning the
language. There's an odd aspect or two I wish was developed more (I'd
really like anonymous closures and better functional programming) but
you couldn't go wrong here.&lt;/p&gt;
&lt;p&gt;(Declaration of interest: This is my choice. I've taught classes using
Python. I've used Python in my own work for a decade. I think Python is
the best general choice. But I think some other choices are defensible -
or at least not ridiculous - especially in particular contexts.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Javascript:&lt;/strong&gt; many people rave about what a great language JS is, and
there are occasional feints at doing bioinformatics in it. True, there
are useful things that you could do in a browser with, perhaps involving
microformatted sequence data. But while you &lt;em&gt;can&lt;/em&gt; do work in it,
&lt;em&gt;should&lt;/em&gt; you? Mostly, it seems like a case of &lt;a class="reference external" href="http://www.codinghorror.com/blog/2007/07/the-principle-of-least-power.html"&gt;Atwood's
law&lt;/a&gt;:
&amp;quot;Any application that can be written in JavaScript, will eventually be
written in JavaScript.&amp;quot; No Bio library (or really any standard libraries
at all), non-existent bio community. You could do web-development
entirely in JS, but it's still a fringe activity. Nope.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;R:&lt;/strong&gt; A lot of ecologists &amp;amp; mathematical biologists use R, a lot of
expression data is analysed using R, and it's got graphics &amp;amp;
visualization to die for. The IDE is great for beginners as well,
allowing packages to easily be installed locally. There's a big
commercial effort behind getting serious IDE and computation tools for R
(see Revolution Analytics). I confess to a bit of a blindspot with R
(some of the syntax is a bit weird), but this could be the right choice
for the right group of students.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Matlab, Mathematica, Octave, etc.:&lt;/strong&gt; There's a few people who do their
work in one of the specialised analytical or mathematical languages. My
experience here is admitttedly limited, and some of the visualizations
and models produced are nice, but the community is tiny, library choice
and coverage is limited, web development tools are not common, and using
proprietory tools may not suit. (That Mathematica yearly subscription
still smarts.) For the right person and project, these might work but
I'm not persuaded any of these are a good general answer.&lt;/p&gt;
&lt;p&gt;Clarification: Of course, these languages are not related or very
similar, but I've grouped them because they occupy similar niches.
Bioinformatic library choice is low. There's tonnes of libraries in
general, but as far as a Bio community goes for these languages, it
seems to be a set of islands: this research group does structural
bioinformatics, this investigator does ecological simulations, this
project does some phylogenetics ... unless you're attached to a group
working with one of these tools, you're pretty much on your own.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lisp, Scheme, etc.:&lt;/strong&gt; What? You're kidding me.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PHP:&lt;/strong&gt; Despite the routine denigration PHP gets, it does drive a huge
number of websites (including Facebook and the NHS) and is easy to pick
up and there's a cornucopia of resources for (non-bioinformatic)
programming. There's also a BioPHP. But there's not a lot of activity
here, and outside of web development it would be different to find any
positive reason why you should opt for this choice.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(Visual/Real/whatever) Basic:&lt;/strong&gt; I know that Basic has been used to do
bioinformatics, because I've done it. It seemed like a good idea at the
time to quickly throw together a user interface in an afternoon, the
program looked good. Fast-forward a few years and some feature creep,
and I'm trying to write simulated annealing and tree-walking code in
Basic. Admittedly, it may be simple for people to learn and get pretty
apps up on the screen fast, but scientific computation are not a natural
fit. The developer community is large but the bio community is near
non-existent. And you're dealing with proprietary tools again,
complicated by non-standardized dialects across competing tools. Maybe
suitable for a simple one-off GUI with a very restricted scope.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;C# / .Net / etc.:&lt;/strong&gt; There's a small number of C-Sharp bioinformatic
apps about. Apart from the obvious community-size problems, I'm not sure
if it would be suited for one-off scripts, and there doesn't seem to
much activity in the way of bioinformatic libraries (for exceptions see
&lt;a class="reference external" href="http://biocoders.net/groups/biomono/"&gt;here&lt;/a&gt; and
&lt;a class="reference external" href="http://www.bioinformatica.mx/biomono/"&gt;here&lt;/a&gt;). The status of the
non-proprietary implementation (Mono) is a little worrying. Still, this
may be useful for doing a desktop GUI app.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shell languages / Awk / etc.:&lt;/strong&gt; Yes, you could do bio-analysis with
shell scripts. But why would you? Again, see &lt;a class="reference external" href="http://www.codinghorror.com/blog/2007/07/the-principle-of-least-power.html"&gt;Atwood's
law&lt;/a&gt;.
Stop punching yourself in the face and use a proper language.&lt;/p&gt;
&lt;div class="section" id="links"&gt;
&lt;h2&gt;Links&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.linkedin.com/groupAnswers?viewQuestionAndAnswers=&amp;amp;discussionID=56367017&amp;amp;gid=54503&amp;amp;commentID=43829102&amp;amp;trk=view_disc"&gt;Linked-in&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://ask.metafilter.com/125801/Best-language-for-highschool-bioinformatics-course"&gt;Metafilter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Biostar has had several goes at this question:
&lt;a class="reference external" href="http://biostar.stackexchange.com/questions/10098/best-language-for-introductory-programming-course-from-within-an-introduction-cou/10111"&gt;here&lt;/a&gt;
and
&lt;a class="reference external" href="http://biostar.stackexchange.com/questions/34/which-are-the-best-programming-languages-for-a-bioinformatician"&gt;here&lt;/a&gt;
and &lt;a class="reference external" href="http://biostar.stackexchange.com/questions/1995/what-programming-language-is-best-to-learn-for-getting-into-web-based-bioinformat"&gt;once about bioinformatics web
programming&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;A &lt;a class="reference external" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2267699/"&gt;BMC Bioinformatics article comparing
languages&lt;/a&gt;
although it looks a lot at performance which I'm not convinced is all
that important.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="computational-biology"></category><category term="programming"></category><category term="programming-langauges"></category><category term="python"></category><category term="ruby"></category></entry><entry><title>Hitchhikers guide to BioPython: SeqRecords</title><link href="http://www.agapow.net/science/computational-biology/biofoo/hitchhikers-guide-to-biopython-seqrecords/" rel="alternate"></link><published>2012-02-01T12:00:00+00:00</published><updated>2012-02-01T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2012-02-01:/science/computational-biology/biofoo/hitchhikers-guide-to-biopython-seqrecords/</id><summary type="html">&lt;p&gt;(Previously published on BiocodersHub.)&lt;/p&gt;
&lt;p&gt;Previously I'd spoken about how Biopython represents sequence data with
the Seq class. But there is also the SeqRecord class:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;A Seq is just raw sequence data and information about what type of sequence it is.&lt;/li&gt;
&lt;li&gt;A SeqRecord is a Seq and all the other information …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;(Previously published on BiocodersHub.)&lt;/p&gt;
&lt;p&gt;Previously I'd spoken about how Biopython represents sequence data with
the Seq class. But there is also the SeqRecord class:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;A Seq is just raw sequence data and information about what type of sequence it is.&lt;/li&gt;
&lt;li&gt;A SeqRecord is a Seq and all the other information that is associated with that sequence: identifiers, annotataions, features and so on.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It can be confusing working out if a Biopython function uses or returns
Seqs or SeqRecords. As a rule of thumb if a function uses or produces
anything more than the raw sequence data, or retrieves the sequence
information from a file or database, it uses a SeqRecord. Thus the I/O
functions all read and write SeqRecords.&lt;/p&gt;
&lt;p&gt;To create a SeqRecord you need a Seq:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; from Bio.Seq import Seq
&amp;gt;&amp;gt;&amp;gt; from Bio.Alphabet import IUPAC
&amp;gt;&amp;gt;&amp;gt; s = Seq(&amp;quot;MKQHKAMIVALIVICITAVVAALV&amp;quot;, IUPAC.protein)
&amp;gt;&amp;gt;&amp;gt; from Bio.SeqRecord import SeqRecord
&amp;gt;&amp;gt;&amp;gt; sr = SeqRecord (s)
&lt;/pre&gt;
&lt;p&gt;This produce the simplest possible SeqRecord, being a simple sequence
with no identifiers or annotations.&lt;/p&gt;
&lt;p&gt;The main optional arguments for the SeqRecord constructor are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;id (string): the primary identifier for the sequence, usually a database accession number.&lt;/li&gt;
&lt;li&gt;name (string): the title of the sequence. Often the same as the id, but sometimes a clone name or similar.&lt;/li&gt;
&lt;li&gt;description (string): free text notes associated with the sequence. Often, additional information associated that is not covered by the other fields is included in ther description is a structured format.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These also are the names of respective object members the arguments are
assigned to:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; from Bio.Seq import Seq
&amp;gt;&amp;gt;&amp;gt; from Bio.Alphabet import IUPAC
&amp;gt;&amp;gt;&amp;gt; from Bio.SeqRecord import SeqRecord
&amp;gt;&amp;gt;&amp;gt; sr = SeqRecord (Seq(&amp;quot;MKQHKAMIVALIVI&amp;quot;, IUPAC.protein), id=&amp;quot;A73456&amp;quot;,
name=&amp;quot;E. coli phosphatase&amp;quot;)
&amp;gt;&amp;gt;&amp;gt; sr.id
'A73456'
&amp;gt;&amp;gt;&amp;gt; sr.name
'E. coli phosphatase'
&amp;gt;&amp;gt;&amp;gt; sr.description
'&amp;lt;unknown description&amp;gt;'
&lt;/pre&gt;
&lt;p&gt;If no value is given for the id, name and description of a SeqFeature,
those members default to the warning message ‘&amp;lt;unknown FOO&amp;gt;’. This can
create problems if you try to test whether the member is set or equal to
another if you assume that an unset field is an empty string or false:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
for s in seqs:
if (not s.id):
   # this doesn't work
   print &amp;quot;%s has no id&amp;quot;
&lt;/pre&gt;
&lt;p&gt;By wide convention in metadata, &lt;em&gt;identifiers&lt;/em&gt; or &lt;em&gt;IDs&lt;/em&gt; are required and
unique, at least locally, while &lt;em&gt;names&lt;/em&gt; or &lt;em&gt;titles&lt;/em&gt; are optional and
duplicates. In practice, Biopython is unlikely to malfunction or care
about either. However duplicate or missing IDs or names may cause
dependent programs to complain or crash and create confusion for anyone
reading the output. So it’s advisable to use both and make them unique.&lt;/p&gt;
&lt;p&gt;There are three additional SeqRecord optional arguments (and members)
for SeqRecord:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;dbxrefs (list):&lt;/strong&gt; This is simply a list of reference or accession numbers to the sequence in other databases (i.e. not the one that you’ve retreived the
sequence from). It is often empty, but when present the entries are
simply strings:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; sr.dbxrefs
[&amp;quot;ASAP:13298&amp;quot;, &amp;quot;GI:16131885&amp;quot;, &amp;quot;GeneID:948570&amp;quot;]
&lt;/pre&gt;
&lt;p&gt;The database references are often of the form
&lt;em&gt;database_name:id_in_database&lt;/em&gt; and manipulating the database
references is as list as changing the strings in the dbxrefs list:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; sr.dbxrefs.append ('PrmDb:12345')
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;annotations (dictionary):&lt;/strong&gt; Additional information about the sequence not associated with or linked to a location in the sequence as key-values where the key is the type of information. This tends to be more unstructured information like the organism and taxonomy involved, the date of modification, etc.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; sr.annotations
{'accessions': ['U49845'],
'data_file_division': 'PLN',
'date': '21-JUN-1999',
'gi': '1293613',
'keywords': [''],
'organism': 'Saccharomyces cerevisiae',
'references': [Reference(title='Cloning and sequence of REV7, a gene whose function is required for DNA damage-induced mutagenesis in Saccharomyces cerevisiae', ...),
Reference(title='Selection of axial growth sites in yeast requires Axl2p, a novel plasma membrane glycoprotein', ...),
Reference(title='Direct Submission', ...)],
'sequence_version': 1,
'source': &amp;quot;Saccharomyces cerevisiae (baker's yeast)&amp;quot;,
'taxonomy': ['Eukaryota',
'Fungi',
'Ascomycota',
'Saccharomycotina',
'Saccharomycetes',
'Saccharomycetales',
'Saccharomycetaceae',
'Saccharomyces']}
&lt;/pre&gt;
&lt;p&gt;Note that the keys are almost always
&lt;em&gt;lowercase_separated_by_underscores&lt;/em&gt;. There’s little agreement about
standard key names, although the records you get from one database or
source will tend to agree with each other. You’ll also notice there’s a
great deal of heterogeneity in what’s used for an annotation value. Some
are plain text (‘organism’), others are a list of strings (‘taxonomy’,
‘keywords’) and some use special Biopython classes to represent complex
information (‘references’). This means that accessing or modifying the
annotations can be easy or complicated:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; if 'Saccharomycetales' in sr.annotations['taxonomy']:
   print 'correct taxa'
correct taxa

# add a reference to the annotations
&amp;gt;&amp;gt;&amp;gt; new_ref = Reference (title=&amp;quot;The 5' end of the ...&amp;quot; ...)
&amp;gt;&amp;gt;&amp;gt; sr.annotations.references.append (new_ref)

# find out what the date is, where the format may not be consistent
&amp;gt;&amp;gt;&amp;gt; import datetime
&amp;gt;&amp;gt;&amp;gt; try:
   mod_date = datetime.strptime(sr.annotations['date'], '%d-%b-%Y')
except ValueError, err:
   # if date in wrong format
   ...
&lt;/pre&gt;
&lt;p&gt;A consequence of storing annotations in a dictionary is that there
cannot be two annotations of the same type. This is generally true but
but occasionally files will occur that do have this problem.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;features (list):&lt;/strong&gt; A list of SeqFeatures for data that is associated with specific
location in the sequence. This is a more complicated tiopic that we’ll
discuss in the next installment.&lt;/p&gt;
&lt;p&gt;(In more recent version of Biopython, SeqRecords have an additional
member, &lt;em&gt;letter_annotations&lt;/em&gt;. This is a dictionary of properties for
every location along the sequence, and usually used quality scores (e.g.
Section 16.1.5) or secondary structure information (e.g. from
Stockholm/PFAM alignment files).)&lt;/p&gt;
&lt;p&gt;Previously, I noted how the &lt;em&gt;right&lt;/em&gt; way to do sequence IO was with
Bio.SeqIO. There are two other methods that can be useful for quickly
dumping a SeqRecord to the screen or a file. ‘print’ will throw a
reasonably readable form of the SeqRecord data to the screen:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; print sr2
ID: NM_001083539.1
Name: NM_001083539
Description: Homo sapiens killer cell immunoglobulin-like receptor, three domains, short cytoplasmic tail, 1 (KIR3DS1), mRNA.
Number of features: 26
...
&lt;/pre&gt;
&lt;p&gt;And the 'format' method can be used to choose a specific formal
format:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; print sr_2.format('fasta')
&amp;gt;NM_001083539.1 Homo sapiens killer cell immunoglobulin-like receptor, three domains, short cytoplasmic tail, 1 (KIR3DS1), mRNA.
CCGGCAGCACCATGTTGCTCATGGTCGTCAGCATGGCGTGTGTTGGGTTGTTCTTGGTCC
&lt;/pre&gt;
&lt;p&gt;It’s worth paying attention to how the fields in different file formats
map to the SeqRecord object. For example, the VERSION, LOCUS and
DEFINITION line in a Genbank file become the id, name and description
field of a SeqRecord respectively. When written out to a Fasta file, the
id becomes the first entry on the accession line, with the description
appended. The name is lost, as are the annotations and features. The
moral here is probably to stick to using as few formats as possible and
ones that are complex enough to support the data you are interested in.&lt;/p&gt;
&lt;p&gt;Back in the previous installment, I also noted that Seqs were basically
strings and could do just about anything strings could:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; s = Seq ('ACGTACGT')
&amp;gt;&amp;gt;&amp;gt; 'ACG' in s
True
&amp;gt;&amp;gt;&amp;gt; s[0]
'A'
&amp;gt;&amp;gt;&amp;gt; s[:5]
Seq('ACGTA', Alphabet())
&lt;/pre&gt;
&lt;p&gt;The same holds for SeqRecords in many regards. They can be sliced,
indexed and queried:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; sr = SeqRecord (s)
&amp;gt;&amp;gt;&amp;gt; sr
SeqRecord(seq=Seq('ACGTACGT', Alphabet()), id='&amp;lt;unknown id&amp;gt;', name='&amp;lt;unknown name&amp;gt;', description='&amp;lt;unknown description&amp;gt;', dbxrefs=[])
&amp;gt;&amp;gt;&amp;gt; 'ACG' in sr
True
&amp;gt;&amp;gt;&amp;gt; sr[0]
'A'
&amp;gt;&amp;gt;&amp;gt; sr[:5]
SeqRecord(seq=Seq('ACGTA', Alphabet()), id='&amp;lt;unknown id&amp;gt;', name='&amp;lt;unknown name&amp;gt;', description='&amp;lt;unknown description&amp;gt;', dbxrefs=[])
&lt;/pre&gt;
&lt;p&gt;SeqRecords can even be concatenated:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; sr[:3] + sr[5:]
SeqRecord(seq=Seq('ACGCGT', Alphabet()), id='&amp;lt;unknown id&amp;gt;', name='&amp;lt;unknown name&amp;gt;', description='&amp;lt;unknown description&amp;gt;', dbxrefs=[])
&lt;/pre&gt;
</content><category term="BioPython"></category><category term="biosequences"></category><category term="computational biology"></category><category term="programming"></category><category term="Python"></category></entry><entry><title>Cleaning biosequences</title><link href="http://www.agapow.net/science/computational-biology/scripts/cleaning-biosequences/" rel="alternate"></link><published>2012-01-01T12:00:00+00:00</published><updated>2012-01-01T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2012-01-01:/science/computational-biology/scripts/cleaning-biosequences/</id><summary type="html">&lt;p&gt;&lt;em&gt;A simple script to check and purge sequence files of possible
problems.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Some times you need sequences that are unambiguous (i.e. only 'ACGT',
lacking gaps) whether it's because of the limitations or assumptions of
tools (like omegaMap) or just because you want to know where SNPs or
sequencing ambiguities …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;A simple script to check and purge sequence files of possible
problems.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Some times you need sequences that are unambiguous (i.e. only 'ACGT',
lacking gaps) whether it's because of the limitations or assumptions of
tools (like omegaMap) or just because you want to know where SNPs or
sequencing ambiguities are. This script reads in a sequence file of any
format, reports the location and nature of ambiguous characters, and
optionally corrects these from a consensus sequence, saves the result to
a FASTA file.&lt;/p&gt;
&lt;p&gt;Usage is:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
checkseqs [options] INFILE [INFILE, INFILE ...]
&lt;/pre&gt;
&lt;p&gt;where options are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;--repair-with-conc:&lt;/strong&gt; patch ambiguous characters with the consensus sequence and save&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;--overwrite:&lt;/strong&gt; newly created files can write over pre-existing ones&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Consensus is calculated on a 50% threshold.&lt;/p&gt;
&lt;p&gt;The usual caveats apply: this is a quick hack with little
error-checking. Over enthusiastic application may mask real sequence
problems.&lt;/p&gt;
&lt;p&gt;The file: &lt;a class="reference external" href="checkseqs.rb"&gt;checkseqs.rb&lt;/a&gt;&lt;/p&gt;
</content></entry><entry><title>Coloring dendroscope files</title><link href="http://www.agapow.net/science/computational-biology/tools/coloring-dendroscope-files/" rel="alternate"></link><published>2012-01-01T12:00:00+00:00</published><updated>2012-01-01T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2012-01-01:/science/computational-biology/tools/coloring-dendroscope-files/</id><summary type="html">&lt;p&gt;The need had arisen for the tips of a large phylogeny to be labelled in
a systematic way. Rather than &amp;quot;point and click&amp;quot; within Dendroscope, this
script takes a .den/dendro file and colors the tips according to a
&amp;quot;color description&amp;quot; file. This is a simple csv file with taxa …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The need had arisen for the tips of a large phylogeny to be labelled in
a systematic way. Rather than &amp;quot;point and click&amp;quot; within Dendroscope, this
script takes a .den/dendro file and colors the tips according to a
&amp;quot;color description&amp;quot; file. This is a simple csv file with taxa labels and
a corresponding color. The color may either be an RGB triplet or a
scalar value which will be mapped to a pallete.&lt;/p&gt;
&lt;div class="section" id="usage"&gt;
&lt;h2&gt;Usage&lt;/h2&gt;
&lt;pre class="literal-block"&gt;
color-dendro.rb [options] CLRFILE TREEFILE1 [...]
&lt;/pre&gt;
&lt;p&gt;where the options are:&lt;/p&gt;
&lt;blockquote&gt;
&lt;table class="docutils option-list" frame="void" rules="none"&gt;
&lt;col class="option" /&gt;
&lt;col class="description" /&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="option-group"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;-h&lt;/span&gt;, &lt;span class="option"&gt;--help&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;td&gt;Display this screen&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class="option-group" colspan="2"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;-m&lt;/span&gt;, &lt;span class="option"&gt;--default-color &lt;var&gt;STR&lt;/var&gt;&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;The default color nodes will be given&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class="option-group" colspan="2"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;--map-to-colors&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;The coloring instructions give a float value which will be mapped to a color&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class="option-group"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;--save &lt;var&gt;STR&lt;/var&gt;&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;td&gt;Name output files according this template&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class="option-group" colspan="2"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;-o&lt;/span&gt;, &lt;span class="option"&gt;--overwrite&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;Overwrite pre-existing files&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="limitations"&gt;
&lt;h2&gt;Limitations&lt;/h2&gt;
&lt;p&gt;The color palette / spectrum code is &lt;em&gt;very&lt;/em&gt; primitive and should be
improved.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="files"&gt;
&lt;h2&gt;Files&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="color-dendro.zip"&gt;Script, sample input and output file&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="credits"&gt;
&lt;h2&gt;Credits&lt;/h2&gt;
&lt;p&gt;Thanks to Richard Myers for his original script which this is based on.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Bioruby"></category><category term="phylogenetics"></category><category term="visualisation"></category><category term="Dendroscope"></category></entry><entry><title>Consensus in BioRuby</title><link href="http://www.agapow.net/science/computational-biology/biofoo/consensus-in-bioruby/" rel="alternate"></link><published>2012-01-01T12:00:00+00:00</published><updated>2012-01-01T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2012-01-01:/science/computational-biology/biofoo/consensus-in-bioruby/</id><summary type="html">&lt;p&gt;In BioRuby, alignments are equipped with several methods for obtaining
consensus sequences. Unfortunately, these have terse descriptions which
point you at the BioPerl documentation, with the added bonus of not
&lt;em&gt;quite&lt;/em&gt; working like the BioPerl equivalents.&lt;/p&gt;
&lt;p&gt;First, let's create a very simple alignment, where everything agrees
except the last sequence …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In BioRuby, alignments are equipped with several methods for obtaining
consensus sequences. Unfortunately, these have terse descriptions which
point you at the BioPerl documentation, with the added bonus of not
&lt;em&gt;quite&lt;/em&gt; working like the BioPerl equivalents.&lt;/p&gt;
&lt;p&gt;First, let's create a very simple alignment, where everything agrees
except the last sequence which leads with a differing character and ends
with a gap:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt; require 'bio'
=&amp;gt; true
&amp;gt;&amp;gt; aln = Bio::Alignment.new(['acgt', 'acgt','acgt', 'ccg-'])
=&amp;gt; #&amp;quot;acgt&amp;quot;, 1=&amp;gt;&amp;quot;acgt&amp;quot;, 2=&amp;gt;&amp;quot;acgt&amp;quot;, 3=&amp;gt;&amp;quot;ccg-&amp;quot;}, serial3
&lt;/pre&gt;
&lt;p&gt;First &lt;tt class="docutils literal"&gt;consensus_iupac&lt;/tt&gt; produces a &amp;quot;true&amp;quot; consensus sequence across all
members. If sequences differ, the consensus sequence has an ambiguous
character that sums these differences:&lt;/p&gt;
&lt;blockquote&gt;
&amp;gt;&amp;gt; aln.consensus_iupac()
=&amp;gt; &amp;quot;mcg?&amp;quot;&lt;/blockquote&gt;
&lt;p&gt;Note the first position is m (a or c), but where gaps exist, like the
final position, the final character is marked gnomically as &lt;tt class="docutils literal"&gt;?&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;An extra complication is the handling of gaps. The option &lt;tt class="docutils literal"&gt;:gap_mode&lt;/tt&gt;
takes the values 0, 1 or -1, which correspond to treating gaps like a
character (the default), any gaps at that site appearing in the output
(i.e. effectively stripping no-gap characters) and stripping all gaps
before calculating the consensus:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt; aln.consensus_iupac(:gap_mode=&amp;gt;0)
=&amp;gt; &amp;quot;mcg?&amp;quot;
&amp;gt;&amp;gt; aln.consensus_iupac(:gap_mode=&amp;gt;1)
=&amp;gt; &amp;quot;mcg-&amp;quot;
&amp;gt;&amp;gt; aln.consensus_iupac(:gap_mode=&amp;gt;-1)
=&amp;gt; &amp;quot;mcgt&amp;quot;
&lt;/pre&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;consensus_string&lt;/tt&gt; uses a threshold to calculate the consensus character
at that site: if the most frequent residue meets the threshold, it is
selected. Gap characters are treated as above:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt; aln.consensus_string(threshold=0.5)
=&amp;gt; &amp;quot;acgt&amp;quot;
&amp;gt;&amp;gt; aln.consensus_string(threshold=0.5, :gap_mode=&amp;gt;0)
=&amp;gt; &amp;quot;acgt&amp;quot;
&amp;gt;&amp;gt; aln.consensus_string(threshold=0.5, :gap_mode=&amp;gt;1)
=&amp;gt; &amp;quot;acg-&amp;quot;
&amp;gt;&amp;gt; aln.consensus_string(threshold=0.5, :gap_mode=&amp;gt;-1)
=&amp;gt; &amp;quot;acgt&amp;quot;
&lt;/pre&gt;
</content><category term="bioinformatics"></category><category term="BioRuby"></category><category term="sequence analysis"></category></entry><entry><title>Galaxy miscellanea</title><link href="http://www.agapow.net/science/computational-biology/galaxy/galaxy-miscellanea/" rel="alternate"></link><published>2012-01-01T12:00:00+00:00</published><updated>2012-01-01T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2012-01-01:/science/computational-biology/galaxy/galaxy-miscellanea/</id><summary type="html">&lt;p&gt;&lt;em&gt;Odds and ends and the surprising.&lt;/em&gt;&lt;/p&gt;
&lt;div class="section" id="redirects"&gt;
&lt;h2&gt;Redirects&lt;/h2&gt;
&lt;p&gt;If you are serving the installation with a proxy redirect (e.g. the
galaxy server is running on port 7070 but is being redirect by Apache to
appear at port 80 on &lt;em&gt;/galaxy&lt;/em&gt;), while you can access Galaxy at both
addresses, login will …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;Odds and ends and the surprising.&lt;/em&gt;&lt;/p&gt;
&lt;div class="section" id="redirects"&gt;
&lt;h2&gt;Redirects&lt;/h2&gt;
&lt;p&gt;If you are serving the installation with a proxy redirect (e.g. the
galaxy server is running on port 7070 but is being redirect by Apache to
appear at port 80 on &lt;em&gt;/galaxy&lt;/em&gt;), while you can access Galaxy at both
addresses, login will only work on one. This is because Galaxy tracks
where you are with cookies that record the path of the instance you are
using, so you can use more than one Galaxy instance. This creates a
slightly strange behaviour where you can login on the other port/path
but are instantly logged out.&lt;/p&gt;
&lt;p&gt;The mixup between these cookies can leave you in a situation where you
can't login to your account. The solution is to delete your cookies.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="pytz"&gt;
&lt;h2&gt;Pytz&lt;/h2&gt;
&lt;p&gt;While uploading a sequence file (Upload File), a harmless error was
issued that disrupted the upload:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/home/f0/paul/Installed/lib/python2.6/site-packages/pytz/tzinfo.py:5: DeprecationWarning: the sets module is deprecated from sets import Set
&lt;/pre&gt;
&lt;p&gt;This can be easily fixed by installing the latest version of pytz:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% easy_install pytz
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="tool-config"&gt;
&lt;h2&gt;Tool config&lt;/h2&gt;
&lt;p&gt;Interestingly, if your tool_conf.xml entry is incorrect (e.g. pointing
at a non-existent directory), an error is written to the log and the
tool just simply not appear in the menu. Note that changes to the config
file will require a restart to be detected.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="duplicate-tool-ids"&gt;
&lt;h2&gt;Duplicate tool ids&lt;/h2&gt;
&lt;p&gt;An interesting way to make an invisible mistake: if you register tools
with the same id (the id in the specific tool configuration file), only
the first one gets registered, the others silently fail:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;tool id=&amp;quot;hpa_seqtools_datelabel-seqs&amp;quot; name=&amp;quot;Do this thing&amp;quot;&amp;gt; ... &amp;lt;tool id=&amp;quot;hpa_seqtools_datelabel-seqs&amp;quot; name=&amp;quot;Do the other thing&amp;quot;&amp;gt;
&lt;/pre&gt;
&lt;p&gt;The only way you can tell (apart from the tool not showing up) is to
look in the output of a Galaxy instance run from the commandline. It
prints the id of each tool being registered.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="only-sleeping"&gt;
&lt;h2&gt;Only sleeping&lt;/h2&gt;
&lt;p&gt;It _seems_ as if when Galaxy has not been used for a while, going to
its address produces a strange traceback. However, immediately reloading
the page shows the usual appearance. It's unclear whether it is Galaxy
or Apache, but it's just a cosmetic annoyance. This may be the result of
our local setup.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-biopython-that-wasn-t-there"&gt;
&lt;h2&gt;The BioPython that wasn't there&lt;/h2&gt;
&lt;p&gt;An odd incident that Galaxy provoked, although it was not at fault:
Biopython was installed on the Galaxy python (the egg is in
site-packages), but tools that imported it failed, saying:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
from Bio import SeqIO ImportError: No module named Bio
&lt;/pre&gt;
&lt;p&gt;This perplexed me for a while, until I went to the extent of unzipping
the Biopython egg. It contained nothing but the metadata (i.e. the
EGG-INFO), having no actual module or executables.&lt;/p&gt;
&lt;p&gt;I realise now that I'd seen this before when a library installation
fails or is aborted. The lib can get &amp;quot;half-installed&amp;quot;, leading to the
above problems. Solution: manually delete the egg, edit it's line out of
&lt;em&gt;easy-install.pth&lt;/em&gt; and reinstall the lib.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="templates-not-all-there"&gt;
&lt;h2&gt;Templates not all there&lt;/h2&gt;
&lt;p&gt;The templating for building commandlines lacks one feature of fully
blown Cheetah templates - you can't include Python code between angled
braces, i.e.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;% foo = &amp;quot;bar&amp;quot; %&amp;gt; #this won't work
&lt;/pre&gt;
&lt;p&gt;This is because the xml parser can't cope with the angled brackets. No
biggie.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="template-debugging"&gt;
&lt;h2&gt;Template debugging&lt;/h2&gt;
&lt;p&gt;Some helpful tip from the galaxy-developers list.&lt;/p&gt;
&lt;p&gt;You can embed a direct python command after a ”#silent” directive. This
can be used to print something to STDERR, that won't appear in the
generated tool commandline:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#silent sys.stderr.write(&amp;quot;Hello World from cheetah generated code &amp;quot;);
&lt;/pre&gt;
&lt;p&gt;All available parameters in a template can be dumped with:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#silent sys.stderr.write(&amp;quot;!!!! Cheetah Template Variables !!!! &amp;quot;) #silent sys.stderr.write(&amp;quot; searchList = '%s' &amp;quot; % (str($searchList)) ) #silent sys.stderr.write(&amp;quot;!!!! end-of-list !!!! &amp;quot;)
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;#breakpoint&lt;/em&gt; stops template compilation at any given point and can be
used to bisect template problems. i.e. If the template compiled fine,
then all the statements above the breakpoint are valid.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="parameter-sanitizing"&gt;
&lt;h2&gt;Parameter sanitizing&lt;/h2&gt;
&lt;p&gt;Something that is there in the documentation, but is easy to miss:
Galaxy filters tool form text. As a result, a field like &lt;em&gt;%y-%m-%d&lt;/em&gt; will
get passed to the tool as &lt;em&gt;Xy-Xm-Xd&lt;/em&gt;. You get around this by giving a
&amp;quot;sanitizer&amp;quot; tag to the relevant param. This can switch off param
cleaning, set the characters to be filtered and suggest substitutions:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;lt;param name=&amp;quot;date_fmt&amp;quot; type=&amp;quot;text&amp;quot; label=&amp;quot;Date format&amp;quot;&amp;gt; &amp;lt;sanitizer&amp;gt;
&amp;lt;valid initial=&amp;quot;string.printable&amp;quot;&amp;gt; &amp;lt;remove value=&amp;quot;&amp;amp;apos;&amp;quot;/&amp;gt; &amp;lt;/valid&amp;gt;
&amp;lt;/sanitizer&amp;gt; &amp;lt;/param&amp;gt;&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="stderr-is-an-error"&gt;
&lt;h2&gt;STDERR is an error&lt;/h2&gt;
&lt;p&gt;If a tool writes anything to stderr, this is interpreted as a failure.&lt;/p&gt;
&lt;/div&gt;
</content><category term="computational biology"></category><category term="galaxy"></category></entry><entry><title>More about MrBayes</title><link href="http://www.agapow.net/science/computational-biology/tools/more-about-mrbayes/" rel="alternate"></link><published>2012-01-01T12:00:00+00:00</published><updated>2012-01-01T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2012-01-01:/science/computational-biology/tools/more-about-mrbayes/</id><summary type="html">&lt;p&gt;Some (more) notes about the venerable Bayesian reconstruction program.&lt;/p&gt;
&lt;div class="section" id="error-when-setting-parameter-gap-2"&gt;
&lt;h2&gt;Error when setting parameter &amp;quot;Gap&amp;quot; (2)&lt;/h2&gt;
&lt;p&gt;When attempting to execute a Nexus file, MrBayes kept spitting back this
cryptic error upon loading:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Executing file &amp;quot;c_vp1_nuc_seqs.nxs&amp;quot; [...]
Reading data block Allocated matrix [...]
Data is Dna Gap character matches matching or missing characters …&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Some (more) notes about the venerable Bayesian reconstruction program.&lt;/p&gt;
&lt;div class="section" id="error-when-setting-parameter-gap-2"&gt;
&lt;h2&gt;Error when setting parameter &amp;quot;Gap&amp;quot; (2)&lt;/h2&gt;
&lt;p&gt;When attempting to execute a Nexus file, MrBayes kept spitting back this
cryptic error upon loading:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Executing file &amp;quot;c_vp1_nuc_seqs.nxs&amp;quot; [...]
Reading data block Allocated matrix [...]
Data is Dna Gap character matches matching or missing characters
Error when setting parameter &amp;quot;Gap&amp;quot; (2) Error in command &amp;quot;Execute&amp;quot;
&lt;/pre&gt;
&lt;p&gt;In the header of the &lt;em&gt;data&lt;/em&gt; block, there was a elementary error that
escaped my eye:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
BEGIN DATA;
        dimensions ntax=48 nchar=417;
        format missing=N interleave=yes datatype=DNA gap=N;
&lt;/pre&gt;
&lt;p&gt;That is, both gap and missing data were set to &lt;em&gt;N&lt;/em&gt;. Once corrected,
things ran fine.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="missing-readline"&gt;
&lt;h2&gt;Missing readline&lt;/h2&gt;
&lt;p&gt;It's surprising how many unix systems don't have readline (which MrBayes
can use for nicer command editing). If during compilation you get this
error::&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% make gcc -DUNIX_VERSION -DUSE_READLINE -O3 -Wall -c -o mb.o mb.c
gcc -DUNIX_VERSION -DUSE_READLINE -O3 -Wall -c -o mcmc.o mcmc.c
gcc -DUNIX_VERSION -DUSE_READLINE -O3 -Wall -c -o bayes.o bayes.c [...]
bayes.c:316: warning: implicit declaration of function `add_history'
bayes.c: In function `readline_completion':
bayes.c:386: warning: implicit declaration of function `rl_completion_matches' bayes.c:386: warning: assignment makes pointer from integer without a cast make:
*** [bayes.o] Error 1
&lt;/pre&gt;
&lt;p&gt;or other complaints about &lt;em&gt;rl_completion_matches&lt;/em&gt;, this means you
can't find readline. Go to your Makefile, about 20 lines down find the
lines that automatically include readline and change &amp;quot;yes&amp;quot; to &amp;quot;no&amp;quot;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ifeq ($(strip $(ARCHITECTURE)), unix)
        USEREADLINE ?= yes
else
        USEREADLINE ?= no endif
&lt;/pre&gt;
&lt;/div&gt;
</content></entry><entry><title>More things I done learned about Galaxy tool development</title><link href="http://www.agapow.net/science/computational-biology/galaxy/more-things-i-done-learned-about-galaxy-tool-development/" rel="alternate"></link><published>2012-01-01T12:00:00+00:00</published><updated>2012-01-01T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2012-01-01:/science/computational-biology/galaxy/more-things-i-done-learned-about-galaxy-tool-development/</id><summary type="html">&lt;p&gt;&lt;em&gt;More things I done learned about Galaxy tool development&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A pot-pouri of titbits that are probably documented somewhere, but
weren't obvious to me.&lt;/p&gt;
&lt;div class="section" id="labels-on-the-tool-menu"&gt;
&lt;h2&gt;Labels on the tool menu&lt;/h2&gt;
&lt;p&gt;You can't nest sections on the tool panel - but you can put labels in
sections for the same effect. Look at tool_conf …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;More things I done learned about Galaxy tool development&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A pot-pouri of titbits that are probably documented somewhere, but
weren't obvious to me.&lt;/p&gt;
&lt;div class="section" id="labels-on-the-tool-menu"&gt;
&lt;h2&gt;Labels on the tool menu&lt;/h2&gt;
&lt;p&gt;You can't nest sections on the tool panel - but you can put labels in
sections for the same effect. Look at tool_conf.xml and the &lt;em&gt;NGS: QC
and manipulation&lt;/em&gt; section for an example. Labels looks like a single
closed tag:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;label text=&amp;quot;Illumina data&amp;quot; id=&amp;quot;illumina&amp;quot; /&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="more-advanced-options"&gt;
&lt;h2&gt;More / advanced options&lt;/h2&gt;
&lt;p&gt;The fasta groomer tool is a good demo of how to implement a dropdown to
expose or hide extra options for a tool. To summarize, in your
parameters have a conditional section with a selector and then a when
for the values of the selector:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;option value=&amp;quot;more&amp;quot;&amp;gt;More options&amp;lt;/option&amp;gt;
&amp;lt;/param&amp;gt;
&amp;lt;when value=&amp;quot;less&amp;quot;&amp;gt;
&amp;lt;!-- no options --&amp;gt;
&amp;lt;/when&amp;gt;
&amp;lt;when value=&amp;quot;advanced&amp;quot;&amp;gt; # many parameters &amp;lt;/when&amp;gt;
&amp;lt;/conditional&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="file-formats"&gt;
&lt;h2&gt;File formats&lt;/h2&gt;
&lt;p&gt;The correct file format for text files is txt (no 'e'). Interesting, you
can give a file a bogus or incorrect format (e.g. format=&amp;quot;fsta&amp;quot;) and no
error is generated. The only apparant symptom is that when you click on
the eye icon to view the file, it downloads instead.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="errors-in-the-tool-config-file"&gt;
&lt;h2&gt;Errors in the tool config file&lt;/h2&gt;
&lt;p&gt;Curiously, not all errors in individual tool config file are picked up.
I had a situation where I'd failed to nest &amp;lt;configfile&amp;gt; correctly inside
&amp;lt;configfiles&amp;gt; and no error was signaled: the element just wasn't used.
So beware: just because Galaxy doesn't complain about the file, doesn't
mean it's right.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="config-files"&gt;
&lt;h2&gt;Config files&lt;/h2&gt;
&lt;p&gt;These are very useful ... just not always for the things you might
imagine.&lt;/p&gt;
&lt;p&gt;A config file is unfortunately named, because it actually means a file
that that is generated by the tool config file. You can't set the name
of a config file (e.g. to &amp;quot;myprog.cfg&amp;quot;) to a hardcoded name that is
expected by your executable - It will be something arbitrary. Therefore
the config must be passed on the commandline line. In effect, it's
another input file, just one that is generated for that invocation of
the tool.&lt;/p&gt;
&lt;p&gt;Which brings us to a wider issue in Galaxy tool development: passing
parameters. The need to pass all in- and out- file names to a Galaxy
tool means that your commandline can get astonishingly overloaded, you
have to write parsing code to sort the options out, it all becomes more
complicated than it should be. Config files offer a quick way around all
this mess. The below example uses ruby, but variants will be possible in
most other scripting languages.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;In the tool config file, dump all the parameters, file names etc. into a config file, in the form of a hash:&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;configfile name=&amp;quot;gene_finder_cfg&amp;quot;&amp;gt;
# arguments for the gene_finder script
args = {
 :input_files =&amp;gt; [ #for $in_seq in $input_seq_files { :path =&amp;gt; &amp;quot;$in_seq.in&amp;quot;, :title =&amp;gt; &amp;quot;$in_seq.in.name&amp;quot;, }, #end for ], :ref_files =&amp;gt; [ #for $ref_seq in $ref_seq_files { :path =&amp;gt; &amp;quot;$ref_seq.in&amp;quot;, :title =&amp;gt; &amp;quot;$ref_seq.in.name&amp;quot;, }, #end for ], ... }
&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Also write the tool commandline, so as to pass the config file path&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;command interpreter=&amp;quot;ruby&amp;quot;&amp;gt; gene_finder.rb $gene_finder_cfg &amp;lt;/command&amp;gt;
&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;In the script, grab the config file and read it and evaluate it:&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;pre class="literal-block"&gt;
config_file = ARGV[0] options = eval (File.read (config_file))
&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;All your parameters are now in &amp;quot;options&amp;quot;. Easy.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="tabular-data"&gt;
&lt;h2&gt;Tabular data&lt;/h2&gt;
&lt;p&gt;Must be uploaded as .tsv, i.e. will tab seperated columns. Galaxy
doesn't understand CSV.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="reference-data"&gt;
&lt;h2&gt;Reference data&lt;/h2&gt;
&lt;p&gt;Many tools will require reference data: long lasting data that is not
analysed itself, but is used in the analysis of other data, changes
infrequently and is usually shared. While there's some clear mechanisms
for some of the genomic tools, the general idiom for new sorts of
reference data is unclear. Two obvious mechanisms suggest themselves:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Hardcode it into the tool and put a file reference data in the tool data directory. But this means that the tool can only use one reference (e.g. not one from a selection). Updating means replacing the datafile - easy but no change is propagated to the user.&lt;/li&gt;
&lt;li&gt;Alternatively, you could just unload the reference file, and share it. This would allow the existence of multiple reference files to be chosen from (&lt;em&gt;I need to run this against the E. coli set not the yeast one&lt;/em&gt;) and for easy updates and explicit versioning (&lt;em&gt;v Nov 2011&lt;/em&gt;). It may prove useful semantically to subtype the tables.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="repeating-inputs"&gt;
&lt;h2&gt;Repeating inputs&lt;/h2&gt;
&lt;p&gt;Repeating (i.e. a variable number of) inputs can easily be configured
like so:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;inputs&amp;gt; &amp;lt;repeat name=&amp;quot;maf_filters&amp;quot; title=&amp;quot;Filter&amp;quot;&amp;gt; &amp;lt;param name=&amp;quot;in&amp;quot; type=&amp;quot;data&amp;quot; format=&amp;quot;maf&amp;quot; label=&amp;quot;MAF File&amp;quot;/&amp;gt; &amp;lt;/repeat&amp;gt; &amp;lt;/inputs&amp;gt;
&lt;/pre&gt;
&lt;p&gt;That is, a variable number of MAF files are selected as inputs. Where an
easy mistake can be made is when configuring the commandline. You might
do this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;command&amp;gt; myawesomescript #for $m in $maf_filters: $m #end if &amp;lt;/command&amp;gt;
&lt;/pre&gt;
&lt;p&gt;This will generate an uninformative error message. The problem is that
$m is the value for the repeat interation or loop. To get at the param,
you have to qualify it with the name of the param:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;command&amp;gt; myawesomescript #for $m in $maf_filters: $m.in #end if &amp;lt;/command&amp;gt;
&lt;/pre&gt;
&lt;p&gt;The reason for this is more obvious when you are looping over multiple
things:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;inputs&amp;gt; &amp;lt;repeat name=&amp;quot;maf_filters&amp;quot; title=&amp;quot;Filter&amp;quot;&amp;gt; &amp;lt;param name=&amp;quot;in&amp;quot; type=&amp;quot;data&amp;quot; format=&amp;quot;maf&amp;quot; label=&amp;quot;MAF File&amp;quot;/&amp;gt; &amp;lt;param name=&amp;quot;in_foo&amp;quot; type=&amp;quot;text&amp;quot; label=&amp;quot;What foo value?&amp;quot; value=&amp;quot;bar&amp;quot;/&amp;gt; &amp;lt;/repeat&amp;gt; &amp;lt;/inputs&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;
</content><category term="computational biology"></category><category term="galaxy"></category></entry><entry><title>Ross Crozier 1943-2009</title><link href="http://www.agapow.net/science/academia/ross-crozier-1943-2009/" rel="alternate"></link><published>2012-01-01T12:00:00+00:00</published><updated>2012-01-01T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2012-01-01:/science/academia/ross-crozier-1943-2009/</id><summary type="html">&lt;p&gt;The sudden death of Ross Crozier on the 12th of November was heralded
largely by a slow ripple of email, phone calls and Facebook messages
across the globe.  I found out from an email that started with a short
but singularly complete sentence:&lt;/p&gt;
&lt;blockquote&gt;
&lt;em&gt;Terrible news.&lt;/em&gt;&lt;/blockquote&gt;
&lt;p&gt;It is sobering to think …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The sudden death of Ross Crozier on the 12th of November was heralded
largely by a slow ripple of email, phone calls and Facebook messages
across the globe.  I found out from an email that started with a short
but singularly complete sentence:&lt;/p&gt;
&lt;blockquote&gt;
&lt;em&gt;Terrible news.&lt;/em&gt;&lt;/blockquote&gt;
&lt;p&gt;It is sobering to think that I knew Ross for nearly 20 years, first as
a superannuated and vaguely disreputable PhD candidate and then after
graduation as a regular collaborator. It is difficult to think of a time
before Ross, before his invaluable mentorship, advice and tutelage. It
is difficult to think of a time after.&lt;/p&gt;
&lt;p&gt;Others have listed Ross' accomplishments and awards, his many
contributions across science, in conservation biology, evolutionary
genetics and sociobiology. But to focus only on conventional landmarks
of a successful academic career would be a mistake. Ross' life is most
keenly seen in the countless students, junior scientists and colleagues
that he taught, coached and befriended.&lt;/p&gt;
&lt;p&gt;He was never more at home then when surrounded by young students and
postdocs, excitedly talking about their research and science. Rather
than hold court, he acted more as a ringleader or co-conspirator,
allowing even the least experienced or knowledgeable to have a word or
play their part. If you made a particularly careless mistake or said
something stupid - too often in my case - he might just raise his
eyebrows and say &amp;quot;Hmm. Well.&amp;quot;, a phrase that only in retrospect
translated as &lt;em&gt;I think you might want to examine your theory there&lt;/em&gt;.
When the inevitable and demoralising failures occurred - overly-critical
reviews of papers, unsuccessful job applications, unfunded grants - he
would counsel resting for a few days to lick our wounds before returning
to the fray. When the victories came, he joined you in celebrating.&lt;/p&gt;
&lt;p&gt;His knowledge was voluminous. When when starting a new project, rather
than doing the background research it was often easier to ask Ross what
he knew. I recall passing an early draft of my thesis before him. After
a single glance, he advised that a reference was probably incorrect. &lt;em&gt;I
think it was published in 1981 not 1982. And the authors initial was E,
not F. You should look at that.&lt;/em&gt; He professed a love for classic
science fiction (Asimov and Heinlein, I pointed him in the direction of
William Gibson and Greg Egan without any luck) and a late rediscovery of
Johnny Cash and country music. But Ross's main pastime was science and
emails would arrive from him that were written on a Sunday morning or
late on a weekend night. &lt;em&gt;I've just had a thought ...&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Despite his passion, his demeanour was not that of the obsessive. Owner
of a relentlessly even temper, he leavened it with a dry and playful
humour.  His move from urban Melbourne to the tropical and provincial
James Cook University spurred more dry commentary, with me a supposedly
sympathetic respondent as an ex-Queenslander. One email discussing a
paper in progress ended: &lt;em&gt;Help, our couch is growing fungus!  * Another
time, he mused, &amp;quot;When we moved up here, people warned us that everything
shuts at 7.30, you can't buy *The Australian&lt;/em&gt;, and nobody wears black.
Well, that's untrue. The paper shop at the airport stocks &lt;em&gt;The
Australian&lt;/em&gt;.&amp;quot; Once, he attended an open day for prospective
undergraduates. One eager - and perhaps confused - candidate buttonholed
Ross and told him how she has gotten interested in biology through
&amp;quot;watching &lt;em&gt;The X-Files&lt;/em&gt;&amp;quot;. Ross was polite but curious, returning home to
search for and watch a random episode of the show. The next day he
ranted about &amp;quot;this worm-man creature created by radiation, that
slithered out of pipes and infected people by biting them&amp;quot; before
throwing up his hands up in perplexed delight.&lt;/p&gt;
&lt;p&gt;Ross took a chance when he took me on as a student. He stood by by me
when no others would He borne my complaints and anxieties with equamity.
By my reckoning, one of the last things he must have done was write a
job reference for me. We met in person for the last time last year in
Bonn. Always the prototypical nerdy entomology-wonk, he stood out among
the sharply dressed European scientists in suits, wearing an old
short-sleeved workshirt with too many pens stuffed in the pocket. When
he saw me, his face split into a wide grin as he grabbed for and shook
my hand in joy. I owe him. I am one of many.&lt;/p&gt;
&lt;p&gt;66 years is old and arguably elderly, but Ross' behaviour and energy
was neither. It was a rare week that was without at least one email from
Ross. Often I would find 2, 3 or even 4 emails from him, each adding
another thought or idea. At the time of his death, we had two papers in
progress together. And I was just one of many, one of the far-flung web
of collaborators that he kept up a steady conversation with, a steady
pulse of research. I fear this lead me and others into the silent
assumption that there would always be more, always more ideas, more
incisive critiques, more advice. We owe, I owe, and it was my delusion
there would be more time in which to repay, at least in some small part,
the great debt I owe him.&lt;/p&gt;
&lt;p&gt;I walk within his shadow. I always will.&lt;/p&gt;
&lt;p&gt;-James Cook University: &lt;a class="reference external" href="http://cms.jcu.edu.au/news/JCUPRD_053958"&gt;Leading scientist dies&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;-Alex Wild: &lt;a class="reference external" href="http://myrmecos.wordpress.com/2009/11/12/ross-crozier/"&gt;Ross Crozier is gone&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;-Roberto A. Keller: &lt;a class="reference external" href="http://roberto.kellerperez.com/2009/11/ross-crozier-died-on-november-12th/"&gt;Ross Crozier, pioneer in the study of genetics of social insects&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;-The Age (Melbourne): &lt;a class="reference external" href="http://www.theage.com.au/national/top-tropical-biologist-shone-light-on-insects-20091125-jrub.html"&gt;Top tropical biologist shone light on insects&lt;/a&gt;&lt;/p&gt;
</content></entry><entry><title>What works - NGS assemblers</title><link href="http://www.agapow.net/science/computational-biology/what-works-ngs-assemblers/" rel="alternate"></link><published>2012-01-01T12:00:00+00:00</published><updated>2012-01-01T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2012-01-01:/science/computational-biology/what-works-ngs-assemblers/</id><summary type="html">&lt;p&gt;You could spend all day just keeping up with developments in
next-generation sequencing. Companies announce new and revolutionary
technologies seemingly every month, promising to do more, better and for
less. Yet at the same time, it’s difficult to hack your way through the
marketing tallk and get hard figures …&lt;/p&gt;</summary><content type="html">&lt;p&gt;You could spend all day just keeping up with developments in
next-generation sequencing. Companies announce new and revolutionary
technologies seemingly every month, promising to do more, better and for
less. Yet at the same time, it’s difficult to hack your way through the
marketing tallk and get hard figures. And the road of NGS technologies
is strewn with once promising technologies …&lt;/p&gt;
&lt;p&gt;Fortunate then that a few recent papers have looked at NGS tech and
done some hard comparative studies. For example:&lt;/p&gt;
&lt;blockquote&gt;
Finotello et al. (2012)&amp;nbsp;Comparative analysis of algorithms for
whole-genome assembly of pyrosequencing data. &lt;em&gt;Brief
Bioinform&lt;/em&gt;&amp;nbsp;13(3):269-280.&amp;nbsp;doi:&amp;nbsp;10.1093/bib/bbr063&lt;/blockquote&gt;
&lt;p&gt;Here the vital step we’re talking about is assemblers: how accurate is
the assembly, where and how many gaps result, how good are they at
solving complex genetic regions.&lt;/p&gt;
&lt;p&gt;Of course, the test data set is perhaps critical context: what works
well for one dataset may be inappropriate to others. Here it’s 454 reads
of three different bacterial genomes for which high quality reference
genomes were available: &amp;nbsp;&lt;em&gt;Zymomonas mobilis&lt;/em&gt;, &lt;em&gt;Helicobacter
pylori&lt;/em&gt;&amp;nbsp;and&amp;nbsp;&lt;em&gt;E. coli.&lt;/em&gt;&amp;nbsp;Furthermore, the effects of different degrees of
coverage were estimated by sampling the original data to different
degrees. So the study is essentially doing de novo assembly with
different software and then assessing the results by comparison against
a reference genome.&lt;/p&gt;
&lt;p&gt;The assemblers in question are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Newbler (version 2.3 and 2.5)&lt;/li&gt;
&lt;li&gt;CABOG&lt;/li&gt;
&lt;li&gt;A pre-release version of PCAP&lt;/li&gt;
&lt;li&gt;MIRA&lt;/li&gt;
&lt;li&gt;CLC Assembly Cell&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(Note: this seems like a slightly odd selection of assemblers, but it
may be just my personal experience speaking). A number of popular
assemblers were excluded:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Long read assemblers like PHRAP and PCAP were not used due to
previous work showing them were suboptimal&lt;/li&gt;
&lt;li&gt;Short read assemblers like Velvet and ABySS were not used due to
previous work showing they produce a lot of small contigs and poorer
reconstruction&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So what are the results? There’s a mass of figures and graphs in there
that are&amp;nbsp;difficult&amp;nbsp;to digest but to brutally sumarize them:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;CABOG gives the largest and most complete contiguous assemblies.
Emphasis is on the word “contiguous” – CABOG is very good at putting
things together, although it sometimes does this incorrectly&lt;/li&gt;
&lt;li&gt;Newbler creates very accurate contigs, although more “disconnected”.
There’s a curious story here where the more recent version of the
software (v2.5) is better at linking the contigs at the expense of
more errors&lt;/li&gt;
&lt;li&gt;CLC copes better with lower coverage than other assemblers&lt;/li&gt;
&lt;li&gt;MIRA has a significant error rate is assembling contigs&lt;/li&gt;
&lt;li&gt;PCAP shows a somewhat erratic performance (perhaps because of being
pre-release)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As an extra, the authors also ask what the “sweet spot” for coverage
is – how much is “enough”, how much effort should you invest in
increasing coverage? All assemblers show a rapid improvement up to about
15-20x coverage and then almost none as far as 72x coverage. (Note this
is much lower than previously suggested figures.)&amp;nbsp;The authors take-home
is that more than 20-30x coverage is unlikely to bring much benefit.&amp;nbsp;In
fact they suggest that exceeding this will not only be expensive but may
compromise assembly quality. (The reasoning for this last point is
unclear to me – perhaps the additional of more but uninformative data
will just create &amp;nbsp;larger job for the assembler.)&lt;/p&gt;
&lt;p&gt;The results are a little surprising: no one in my circles uses CABOG
or it’s predecessors, with Mira has a reasonable following. And some of
the differences are quite substantial, on the level of several percent
of the genome being “missed”. Which makes me wonder how much NGS data
we’re going to have to throw out in the coming years when we find how
bad it is …&lt;/p&gt;
</content><category term="science"></category><category term="bioinformatics"></category><category term="ngs"></category></entry><entry><title>Drawing sequence logos</title><link href="http://www.agapow.net/science/computational-biology/scripts/drawing-sequence-logos/" rel="alternate"></link><published>2011-01-01T12:00:00+00:00</published><updated>2011-01-01T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2011-01-01:/science/computational-biology/scripts/drawing-sequence-logos/</id><summary type="html">&lt;p&gt;Sequence logos are a common way of representing SNPs and diversity in
groups of sequences. This script automates the task. It's a bit rough
around the edges and serves mainly as a base for further hacking.&lt;/p&gt;
&lt;p&gt;Usage is:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
drawlogo.rb [options] FILE1 [FILE2 ...]
&lt;/pre&gt;
&lt;p&gt;where options are:&lt;/p&gt;
&lt;blockquote&gt;
&lt;table class="docutils option-list" frame="void" rules="none"&gt;
&lt;col class="option" /&gt;
&lt;col class="description" /&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="option-group"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;-h&lt;/span&gt;, &lt;span class="option"&gt;--help&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;td&gt;Display this …&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;p&gt;Sequence logos are a common way of representing SNPs and diversity in
groups of sequences. This script automates the task. It's a bit rough
around the edges and serves mainly as a base for further hacking.&lt;/p&gt;
&lt;p&gt;Usage is:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
drawlogo.rb [options] FILE1 [FILE2 ...]
&lt;/pre&gt;
&lt;p&gt;where options are:&lt;/p&gt;
&lt;blockquote&gt;
&lt;table class="docutils option-list" frame="void" rules="none"&gt;
&lt;col class="option" /&gt;
&lt;col class="description" /&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="option-group"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;-h&lt;/span&gt;, &lt;span class="option"&gt;--help&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;td&gt;Display this screen&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class="option-group"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;--columns &lt;var&gt;INT&lt;/var&gt;&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;td&gt;How many sites to draw in every row&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class="option-group" colspan="2"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;--relative-cell-height &lt;var&gt;FLOAT&lt;/var&gt;&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;How high to make a site relative to its width&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class="option-group"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;--palette &lt;var&gt;STR&lt;/var&gt;&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;td&gt;Which palette to use&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class="option-group" colspan="2"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;--add-to-palette &lt;var&gt;STR&lt;/var&gt;&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;Add these colors to the palette&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class="option-group"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;--format &lt;var&gt;STR&lt;/var&gt;&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;td&gt;Save output in this format&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class="option-group"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;--save &lt;var&gt;STR&lt;/var&gt;&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;td&gt;Name output files according this template&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class="option-group" colspan="2"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;-o&lt;/span&gt;, &lt;span class="option"&gt;--overwrite&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;Overwrite pre-existing files&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/blockquote&gt;
&lt;p&gt;The input is a CSV file with one row for each different residue at each
site, of the form:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;site index&amp;gt;, &amp;lt;residue&amp;gt;, &amp;lt;proportion&amp;gt;
&lt;/pre&gt;
&lt;p&gt;The output is an image file, by default a PNG, although any format
supported by RMagick is possible. Caveat: SVG output is pathological,
due to Rmagick's poor support of the format.&lt;/p&gt;
&lt;div class="section" id="requirements"&gt;
&lt;h2&gt;Requirements&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Ruby v1.8.x. 1.9.x will work but require a simple change in the CSV reading code, thanks to Ruby changing the way the CSV standard library works. (Thanks guys!)&lt;/li&gt;
&lt;li&gt;The RMagick library.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="files"&gt;
&lt;h2&gt;Files&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;{attach}&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="ruby"></category><category term="bioinformatics"></category><category term="sequence-analysis"></category></entry><entry><title>Reducing a sequence to SNPs</title><link href="http://www.agapow.net/science/computational-biology/scripts/reducing-a-sequence-to-snps/" rel="alternate"></link><published>2010-06-01T12:00:00+01:00</published><updated>2010-06-01T12:00:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2010-06-01:/science/computational-biology/scripts/reducing-a-sequence-to-snps/</id><summary type="html">&lt;p&gt;A largely self-explanatory script. This will &amp;quot;shrink&amp;quot; an alignment,
deleting all sites that don't contain a polymorphism in some member
sequence. A little bit of script candy as well, this takes any number of
files and saves the results in a new file named according to a definable
schema:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#!/usr …&lt;/pre&gt;</summary><content type="html">&lt;p&gt;A largely self-explanatory script. This will &amp;quot;shrink&amp;quot; an alignment,
deleting all sites that don't contain a polymorphism in some member
sequence. A little bit of script candy as well, this takes any number of
files and saves the results in a new file named according to a definable
schema:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#!/usr/bin/env ruby
# Reduce a sequence to solely the SNP sites.

### IMPORTS

require 'test/unit/assertions'
require 'optparse'
require 'pp'

require 'ostruct'
require 'date'
require 'time'
require 'bio'
include Test::Unit::Assertions

### CONSTANTS &amp;amp; DEFINES

### IMPLEMENTATION

# complete bit of frivolity which I use to define formats for strings
def interpolate (str, sub_hash)
        return str.gsub (/{([^}]+)}/) { |m|
                sub_hash[$1]
        }
end

### MAIN

# Parse commandline arguments.
def parse_clargs (arg_arr)
        clopts = {
                :save =&amp;gt; &amp;quot;{root}-snps.fasta&amp;quot;,
                :overwrite =&amp;gt; false,
        }
        pargs = []

        OptionParser.new { |opts|
                opts.program_name = __FILE__
                opts.banner = &amp;quot;Reduce a sequence to solely the SNP sites&amp;quot;
                opts.separator (&amp;quot;&amp;quot;)
                opts.separator (&amp;quot;Usage: #{opts.program_name} [options] ALN1 ...]&amp;quot;)
                opts.on ('-h', '--help', 'Display this screen') {
                        puts opts
                        exit
                }
                opts.on ('', '--save STR',
                        &amp;quot;Name output files according this template&amp;quot;) { |v|
                        clopts[:save] = v
                }
                opts.on ('-o', '--overwrite', &amp;quot;Overwrite pre-existing files&amp;quot;) {
                        clopts[:overwrite] = true
                }
                begin
                        opts.parse! (arg_arr)
                        pargs = arg_arr
                        assert (1 &amp;lt;= pargs.length, &amp;quot;need files to work on&amp;quot;)
                rescue Exception =&amp;gt; e
                        error_msg = e.to_str.split(&amp;quot; &amp;quot;)
                        print &amp;quot;Error: #{error_msg[0]}&amp;quot;
                        print opts
                        exit 1
                end
        }

        return clopts, pargs
end

# Main script functionality.
def main()
        clopts, aln_files = parse_clargs (ARGV)

        aln_files.each { |f|
                # slurp ...
                seqs = [] Bio::FlatFile.open(f) { |rdr|
                        seqs = rdr.collect { |rec|
                                rec.to_seq()
                        }
                }
                # calculate diffs diff_hash = {}
                seqs.each { |s|
                        diff_hash[s.entry_id] = &amp;quot;&amp;quot;
                }
        seq_len = seqs[0].length()
        (0...seq_len).each { |i|
                is_diff = false
                seqs.each { |s1|
                        seqs.each { |s2|
                                if s1 != s2
                                        if s1[i,1] != s2[i,1]
                                                is_diff = true
                                                break
                                        end
                                end
                        }
                        if is_diff == true
                                break
                        end
                }
                if is_diff == true
                        seqs.each { |s|
                                diff_hash[s.entry_id] += s[i,1]
                        }
                end
        }

                # write output

                # make filename
                # this is where my overly ornate templating comes in
                ext = File.extname(f)
                subs = {
                        &amp;quot;ext&amp;quot; =&amp;gt; ext[1, ext.length],
                        &amp;quot;base&amp;quot; =&amp;gt; File.basename(f),
                        &amp;quot;root&amp;quot; =&amp;gt; File.basename(f, ext),
                        &amp;quot;date&amp;quot; =&amp;gt; Date.today.to_s(),
                        &amp;quot;time&amp;quot; =&amp;gt; Time.now.strftime(fmt='%T'),
                        &amp;quot;datetime&amp;quot; =&amp;gt; DateTime.now.strftime (fmt='%FT%T'),
                }
                out_name = interpolate(clopts[:save], subs)

                # do the writing
                puts &amp;quot;Saving results to '#{out_name}' ...&amp;quot;
                if File.exists? (out_name)
                        assert (clopts[:overwrite], &amp;quot;Can't overwrite existing file '#{out_name}'&amp;quot;)
                end
                File.open(out_name, 'w') { |wrtr|
                        diff_hash.each_pair { |k,v|
                                wrtr &amp;lt;&amp;lt; &amp;quot;&amp;gt;#{k}&amp;quot;
                                wrtr &amp;lt;&amp;lt; &amp;quot;#{v}&amp;quot;
                        }
                }
                puts &amp;quot;Saved '#{out_name}'.&amp;quot;
        }
        puts &amp;quot;== Finished.&amp;quot;
end

if $0 == __FILE__
        main()
end

### END
&lt;/pre&gt;
</content><category term="imported"></category><category term="sequence-analysis"></category><category term="script"></category><category term="ruby"></category><category term="bioruby"></category><category term="bioinformatics"></category></entry><entry><title>jsPhyloSVG</title><link href="http://www.agapow.net/science/computational-biology/jsphylosvg/" rel="alternate"></link><published>2010-03-01T12:00:00+00:00</published><updated>2010-03-01T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2010-03-01:/science/computational-biology/jsphylosvg/</id><summary type="html">&lt;p&gt;&lt;a class="reference external" href="http://jsphylosvg.com/"&gt;jsPhyloSVG&lt;/a&gt; (or JPS from this point) is a
nifty Javascript library for displaying phylogenetic trees in your
browser. It can:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;accept trees in a number of formats, encoded in the page or on file or loaded via Ajax&lt;/li&gt;
&lt;li&gt;allow these trees to be exported or saved as SVG&lt;/li&gt;
&lt;li&gt;display trees …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;&lt;a class="reference external" href="http://jsphylosvg.com/"&gt;jsPhyloSVG&lt;/a&gt; (or JPS from this point) is a
nifty Javascript library for displaying phylogenetic trees in your
browser. It can:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;accept trees in a number of formats, encoded in the page or on file or loaded via Ajax&lt;/li&gt;
&lt;li&gt;allow these trees to be exported or saved as SVG&lt;/li&gt;
&lt;li&gt;display trees in several formats&lt;/li&gt;
&lt;li&gt;also display tree annotations &amp;amp; hyperlinks&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On the down side, the documentation is middling and there are several
hidden traps when using it. Here are some pointers from hard-won
experience.&lt;/p&gt;
&lt;p&gt;(Note added during editing: this is not to criticise the creators of JPS
- at least they provide decent documentation and live examples. But the
library is sufficiently powerful and large such that some points are
missed or touched on only lightly, and it's easy for them to get lost.
The below is what I consider to be a selection of the highlights and
easiest things to misunderstand.)&lt;/p&gt;
&lt;div class="section" id="does-it-work-in-internet-explorer"&gt;
&lt;h2&gt;Does it work in Internet Explorer?&lt;/h2&gt;
&lt;p&gt;Given the dubious support within IE for SVG, this is a good question
that the documentation fails to address. It works in IE 8+, but it's
unclear what the story is with 7. Some font and minor features may
appear different (not broken) across platforms.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="what-formats-does-it-accept"&gt;
&lt;h2&gt;What formats does it accept?&lt;/h2&gt;
&lt;p&gt;Newick (the default), PhyloXml, NeXML, JSON (json-ized PhyloXML or
NeXML). I assume Newick is what you're using. It's not very well-defined
and there are lots of minor variants about which can cause issues (see
below). But it's far more ubiquitous than the alternatives. However,
several of the more advanced features of JPS can only be used with
the XML formats.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-canonical-and-complete-basic-example"&gt;
&lt;h2&gt;The canonical and complete basic example&lt;/h2&gt;
&lt;p&gt;Trees can be embedded in a webpage like thus:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;html&amp;gt;
        &amp;lt;head&amp;gt;
                &amp;lt;script type=&amp;quot;text/javascript&amp;quot; src=&amp;quot;raphael-min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
                &amp;lt;script type=&amp;quot;text/javascript&amp;quot; src=&amp;quot;jsphylosvg-min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
        &amp;lt;/head&amp;gt;
        &amp;lt;body&amp;gt;
        &amp;lt;div id=&amp;quot;svgCanvas&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
        &amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;
        var dataObject = { newick: '(foo:0.00823353,(bar:0.0127245,                     baz:0.141467),quux:0.00374251);' };
        phylocanvas = new Smits.PhyloCanvas( dataObject, 'svgCanvas',
                500, 500);
        &amp;lt;/script&amp;gt;
        &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/pre&gt;
&lt;p&gt;Ideally you should pass the tree data and render it in an &lt;tt class="docutils literal"&gt;onLoad&lt;/tt&gt; - to
postpone rendering until after the page loading is complete - but the
above will work. JPS uses  &lt;a class="reference external" href="http://raphaeljs.com/"&gt;Raphael&lt;/a&gt; to do
the drawing, but it is included in the package.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="newick-encoding"&gt;
&lt;h2&gt;Newick encoding&lt;/h2&gt;
&lt;p&gt;The Newick format presents a few problems. By experimentation, these
appear to be the limitations within JPS:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;In this case, the data object you must pass must have the property &lt;tt class="docutils literal"&gt;newick&lt;/tt&gt; with the Newick string as its value&lt;/li&gt;
&lt;li&gt;Taxa names cannot be quoted, e.g. &lt;tt class="docutils literal"&gt;'foo'&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;Spaces within a taxa name are tolerated but not not outside a name. JPS appears to use non-alphanumerics to delimit taxa names and expects other taxanames / tree punctuation to follow immediately.&lt;/li&gt;
&lt;li&gt;While spaces might be okay in a name, hyphens are not&lt;/li&gt;
&lt;li&gt;Very small distances are okay&lt;/li&gt;
&lt;li&gt;The tree specification must be finished with a semi-colon.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So this is okay:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
(Whipped Cream:1,Chocolate Syrup:1,Cafe Mocha:3)
&lt;/pre&gt;
&lt;p&gt;and this isn't:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
('Whipped Cream':1, Chocolate-Syrup:1, Cafe Mocha:3)
&lt;/pre&gt;
&lt;p&gt;If the tree does not meet these requirements, two things could happen:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;a malformed tree is drawn (look for brackets and other &amp;quot;punctuation&amp;quot; embedded in tree names&lt;/li&gt;
&lt;li&gt;the tree-parsing code (apparently) gets stuck in a loop and never returns, causing the page to apparently &amp;quot;hang&amp;quot;. IN Chrome, even stopping the page and reloading would often fail to fix this behaviour. I had to eventually close the tab.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also worth knowing is that branchlengths do not have to be provided on
the tree. Absent ones are assumed to be 1.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="parameters"&gt;
&lt;h2&gt;Parameters&lt;/h2&gt;
&lt;p&gt;JPS spends most of its time on the PhyloXML format, neglecting or only
implying the parameters for direct calls. Here's a few examples. You
can draw a radial tree, like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
phylocanvas = new Smits.PhyloCanvas (
        dataObject,   // a string in Newick or XML
        'svgCanvas',  // the div within which to render the tree
        1000, 1000,   // height &amp;amp; width of tree after rendering, in pixels
        'circular'    // draw a radial tree
);
&lt;/pre&gt;
&lt;p&gt;There's a few other odd things too. For unclear reasons, the circular
depiction of the tree will sometimes overflow its box, giving it a odd
cropped look. 1000 by 1000 seems to work under most circumstances. Note
- and this is completely unclear in the documentation - in the radial
pictures, the branch lengths are drawn as dotted beyond their actual
lengths so that they reach the outer edge of the circle.&lt;/p&gt;
&lt;p&gt;&amp;quot;Interactive features&amp;quot; are restricted to the XML formats.&lt;/p&gt;
&lt;p&gt;Style parameters can be altered from Javascript. The documentation
refers to a &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;render-styles.js&lt;/span&gt;&lt;/tt&gt; but actually everything is in the main
JPS file. These can be altered directly in your code (or passed in
the XML):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Smits.PhyloCanvas.Render.Style.line.stroke = 'rgb(0,0,255)';
// Color lines blue
Smits.PhyloCanvas.Render.Style.text[&amp;quot;font-size&amp;quot;] = 16;
// Increase font size to 16pt
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="save-tree-as-svg"&gt;
&lt;h2&gt;Save tree as SVG&lt;/h2&gt;
&lt;p&gt;There is an example in the documentation that shows how to do this.
However, it's moderately complex and requires one of the
major JS toolkits (JQuery, YUI) to do the necessary popups and handling.&lt;/p&gt;
&lt;/div&gt;
</content><category term="science"></category><category term="tools"></category><category term="phylogenetics"></category><category term="web-development"></category></entry><entry><title>Ordnance Survey locations</title><link href="http://www.agapow.net/science/geospatial/ordnance-survey-locations/" rel="alternate"></link><published>2009-06-01T12:00:00+01:00</published><updated>2009-06-01T12:00:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2009-06-01:/science/geospatial/ordnance-survey-locations/</id><summary type="html">&lt;p&gt;The Ordinance Survey is a UK-peculiar geospatial format, ubiquitous via
street atlases, hiking charts and (yes) farming and epidemiological
maps. It is explained in great detail is several places, but here's a
quick overview:&lt;/p&gt;
&lt;p&gt;The OS grid is a set of 25 squares, 500 kilometers a side, arranged
5-by-5 that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The Ordinance Survey is a UK-peculiar geospatial format, ubiquitous via
street atlases, hiking charts and (yes) farming and epidemiological
maps. It is explained in great detail is several places, but here's a
quick overview:&lt;/p&gt;
&lt;p&gt;The OS grid is a set of 25 squares, 500 kilometers a side, arranged
5-by-5 that is superimposed over the UK. These squares are addressed A
to Z, excluding I, running west-to-east, north-to-south like so:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ABCDE
FGHJK
LMNOP
QRSTU
VWXYZ
&lt;/pre&gt;
&lt;p&gt;In reality, only H, J, N, O, S &amp;amp; T are used, as they cover the mainland
UK and most of the prominent islands. These 500km squares are broken own
again into 25 squares, 100 kilometres a side, arranged 5 by 5 as above.
Within each of these minor squares, a position can be given as an
east-north within that square, from its south-west corner. These are
typically given as 3 digits each, so the lowest digit represents 100
metres. Thus &lt;em&gt;114 525&lt;/em&gt; is 11.4 kilometers east and 52.5 kilometres
north of it's containing square. So a point just outside Ipswich (in
south-east England) can be given as &lt;em&gt;TM 114 525&lt;/em&gt;. (That is, 500km
square T, 100km square M, 11.4 kilometers east and 52.5 kilometres north
of the south-west corner of M.)&lt;/p&gt;
&lt;p&gt;Of course, there are complications. Formatting is variable, with the
spaces sometimes omitted from the reference:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
TM 114 525
TM114 525
TM114525
TM 114525
&lt;/pre&gt;
&lt;p&gt;It's unclear which, if any, is the canonical form. Further more, the
eastings-northings can be given in higher resolutions up to 6 digits
each, where the final digit represents 10cm. Therefore these all map to
the same point:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
TM 114 525
TM 1140 5250
TM 114000 525000
&lt;/pre&gt;
&lt;p&gt;Converting these to a more widely-used coordinate system is non-trivial.
First, the OS system is a true grid (i.e. square) unlike the
conventional lon-lats that are squeezed by the earths shape. The OS grid
is anchored to the conventional coordinates, at a point near the Channel
Isles, but this point is projected so that all coordinates in the UK can
be referred to with positive eastings-northings.&lt;/p&gt;
&lt;p&gt;Finally, the OS references are based on the OS1936 global projection,
not the WGS84 or ETR projections. In plain English, these are models of
the world's shape - the height and width of the ellipsoid - that the
lon-lat grid is laid over. As a consequence, lon-lats in either system
will disagree with the other, although perhaps only by metres.&lt;/p&gt;
&lt;p&gt;Right, now we can look at converting this with Python, elsewhere.&lt;/p&gt;
&lt;div class="section" id="also-see"&gt;
&lt;h2&gt;Also see&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="/software/osgb"&gt;osgb, a Python module for converting Ordinance Survey coordinates&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="osgb"></category></entry><entry><title>Error 1 for Mrbayes</title><link href="http://www.agapow.net/science/computational-biology/tools/error-1-for-mrbayes/" rel="alternate"></link><published>2009-01-01T12:00:00+00:00</published><updated>2009-01-01T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2009-01-01:/science/computational-biology/tools/error-1-for-mrbayes/</id><summary type="html">&lt;p&gt;If this happens to you when trying to compile MrBayes:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% make
gcc -DUNIX_VERSION -DUSE_READLINE -O3 -Wall    -c -o mb.o mb.c
gcc -DUNIX_VERSION -DUSE_READLINE -O3 -Wall    -c -o mcmc.o mcmc.c
gcc -DUNIX_VERSION -DUSE_READLINE -O3 -Wall    -c -o bayes.o bayes.c
bayes.c:45:31: readline/readline …&lt;/pre&gt;</summary><content type="html">&lt;p&gt;If this happens to you when trying to compile MrBayes:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% make
gcc -DUNIX_VERSION -DUSE_READLINE -O3 -Wall    -c -o mb.o mb.c
gcc -DUNIX_VERSION -DUSE_READLINE -O3 -Wall    -c -o mcmc.o mcmc.c
gcc -DUNIX_VERSION -DUSE_READLINE -O3 -Wall    -c -o bayes.o bayes.c
bayes.c:45:31: readline/readline.h: No such file or directory
bayes.c:46:30: readline/history.h: No such file or directory
bayes.c: In function `main':
bayes.c:189: error: `rl_attempted_completion_function' undeclared (first use in this function)
bayes.c:189: error: (Each undeclared identifier is reported only once
bayes.c:189: error: for each function it appears in.)
bayes.c: In function `CommandLine':
bayes.c:311: warning: implicit declaration of function `readline'
bayes.c:311: warning: assignment makes pointer from integer without a cast
bayes.c:316: warning: implicit declaration of function `add_history'
bayes.c: In function `readline_completion':
bayes.c:386: warning: implicit declaration of function `rl_completion_matches'
bayes.c:386: warning: assignment makes pointer from integer without a cast
make: *** [bayes.o] Error 1
&lt;/pre&gt;
&lt;p&gt;This means that make can't find readline. Comment that line out and go
round again.&lt;/p&gt;
</content><category term="mr-bayes"></category><category term="phylogenetics"></category><category term="possibly-obselete"></category></entry><entry><title>Fetch sequences from db</title><link href="http://www.agapow.net/science/computational-biology/scripts/fetch-sequences-from-db/" rel="alternate"></link><published>2007-06-14T12:56:00+01:00</published><updated>2007-06-14T12:56:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2007-06-14:/science/computational-biology/scripts/fetch-sequences-from-db/</id><summary type="html">&lt;p&gt;This just wraps the BioRuby fetch functionality in a friendly
commandline interface. In brief, it can accept accession ids on the
commandline or from a piped file (one accession per line) and save the
corresponding sequences from the db. Sequences may be downloaded via the
bioruby or EBI servers. The …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This just wraps the BioRuby fetch functionality in a friendly
commandline interface. In brief, it can accept accession ids on the
commandline or from a piped file (one accession per line) and save the
corresponding sequences from the db. Sequences may be downloaded via the
bioruby or EBI servers. The file format is Genbank but could easily be
hacked to something else.&lt;/p&gt;
&lt;p&gt;It would be polite to limit requests to a reasoanable number, say 500 in
one go.&lt;/p&gt;
&lt;div class="section" id="usage"&gt;
&lt;h2&gt;Usage&lt;/h2&gt;
&lt;p&gt;Call as:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
fetchdbseqs.rb [options] [ID1 ID2 ...]
&lt;/pre&gt;
&lt;p&gt;where the available options are:&lt;/p&gt;
&lt;blockquote&gt;
&lt;table class="docutils option-list" frame="void" rules="none"&gt;
&lt;col class="option" /&gt;
&lt;col class="description" /&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="option-group"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;-h&lt;/span&gt;, &lt;span class="option"&gt;--help&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;td&gt;Display this screen&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class="option-group"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;--server &lt;var&gt;NAME&lt;/var&gt;&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;td&gt;Which server to query&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class="option-group"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;--read-stdin&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;td&gt;Read sequence ids from standard input&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class="option-group" colspan="2"&gt;
&lt;kbd&gt;&lt;span class="option"&gt;-o&lt;/span&gt;, &lt;span class="option"&gt;--overwrite&lt;/span&gt;&lt;/kbd&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;Overwrite pre-existing files&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="requirements"&gt;
&lt;h2&gt;Requirements&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Ruby&lt;/li&gt;
&lt;li&gt;BioRuby&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="files"&gt;
&lt;h2&gt;Files&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://wordpress.agapow.net/fdgfddfgfd/programming/ruby/fetchseqs-rb"&gt;http://wordpress.agapow.net/fdgfddfgfd/programming/ruby/fetchseqs-rb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="bioruby"></category><category term="sequences"></category><category term="database"></category></entry><entry><title>Installing Galaxy</title><link href="http://www.agapow.net/science/computational-biology/galaxy/installing-galaxy/" rel="alternate"></link><published>2007-06-14T12:56:00+01:00</published><updated>2007-06-14T12:56:00+01:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2007-06-14:/science/computational-biology/galaxy/installing-galaxy/</id><summary type="html">&lt;p&gt;This presents one way to create an optimized production Galaxy instance.
Variations are certainly possible and some of the choices presented
are/were dictated by local culture. Certain settings may be more
suitable for production or development environments. Nonetheless, this
presents a start-to-stop process for installation and setup.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; this …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This presents one way to create an optimized production Galaxy instance.
Variations are certainly possible and some of the choices presented
are/were dictated by local culture. Certain settings may be more
suitable for production or development environments. Nonetheless, this
presents a start-to-stop process for installation and setup.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; this is a living document, will change across time, and is
occasionally terse or cryptic where I have yet to fill it out.&lt;/p&gt;
&lt;div class="section" id="assumptions"&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Running on unix on Fedora or a similar system&lt;/li&gt;
&lt;li&gt;Galaxy will be running off a suburl (e.g. &lt;a class="reference external" href="http://foobar/galaxy"&gt;http://foobar/galaxy&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Superuser privileges may be required at some points&lt;/li&gt;
&lt;li&gt;Apache is used as a frontend server.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="prepping-environment"&gt;
&lt;h2&gt;Prepping environment&lt;/h2&gt;
&lt;p&gt;Create a user for Galaxy to run as and under. Galaxy will be installed
into this users account:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% /usr/sbin/useradd galaxy
% passwd galaxy
&lt;/pre&gt;
&lt;p&gt;Note that we don't install Galaxy &amp;quot;inside&amp;quot; Apache, as this would expose
all of Galaxy (including datasets) to anyone on the web.&lt;/p&gt;
&lt;p&gt;Install virtualenv, so we can later create a sandboxed python
interpreter:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% yum install python-virtualenv.noarch
&lt;/pre&gt;
&lt;p&gt;See &lt;a class="reference external" href="http://virtualenv.openplanning.org"&gt;http://virtualenv.openplanning.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If needed, install mercurial, so the Galaxy repository can be used for
installation (and later updating):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% yum install mercurial
&lt;/pre&gt;
&lt;p&gt;Change to the galaxy user and into its home directory. Clone the Galaxy
repository:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% hg clone https://bitbucket.org/galaxy/galaxy-dist
&lt;/pre&gt;
&lt;p&gt;This will create galaxy-dist in the home directory.&lt;/p&gt;
&lt;p&gt;Create a local sand-boxed Python interpreter for the galaxy user. We'll
install all local data in the &amp;quot;local&amp;quot; dir:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% virtualenv --no-site-packages local
&lt;/pre&gt;
&lt;p&gt;Then activate this interpreter, which will modify $PATH so the
sand-boxed python is used by galaxy:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% source ./local/bin/activate
&lt;/pre&gt;
&lt;p&gt;Alternatively, an entirely separatePython interpreter could be installed
for Galaxy. You could use the system interpreter, but either of these
two schemes avoids library collision or dueling versions.&lt;/p&gt;
&lt;p&gt;Check this installation by running Galaxy:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% cd galaxy-dist % sh run.sh
&lt;/pre&gt;
&lt;p&gt;It may report that numerous &amp;quot;eggs&amp;quot; (Python librararies) are being
updated, before saying that the server is starting. At that point, it
may also report a network error (socket error 98) if another
applpication is using the default socket (8080) or it is blocked from
connecting to it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="adjusting-network-settings"&gt;
&lt;h2&gt;Adjusting network settings&lt;/h2&gt;
&lt;p&gt;Galaxy settings are editted in the file universe_wsgi.ini. Edit the
port Galaxy will use:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
port = 7070
&lt;/pre&gt;
&lt;p&gt;And the addresses it will listen to. With the default settings, Galaxy
only listens to localhost and is not accessible over the network:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
host = 0.0.0.0
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="connecting-to-a-real-database"&gt;
&lt;h2&gt;Connecting to a real database&lt;/h2&gt;
&lt;p&gt;Using Postgres, or an equivalent real db, create a database for Galaxy's
use:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
CREATE DATABASE galaxy_prod;
&lt;/pre&gt;
&lt;p&gt;Give the user permissions to create tables and so on:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
GRANT ALL ON galaxy_prod.* TO galaxy_prod_user&amp;#64;localhost IDENTIFIED BY foobar;
&lt;/pre&gt;
&lt;p&gt;Edit the database connection in universe_wsgi.ini to give the
connection as an SQLAlchemy URI string:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
db = postgres://galaxy_prod_user:foobar&amp;#64;123.45.67.89:5432/galaxy_prod
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Note that the example given in the Galaxy documentation is wrong, or at
least opaque.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Start up the system and see that it works. There will be an extended
period of migrating tables.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="optimizing-database-use"&gt;
&lt;h2&gt;Optimizing database use&lt;/h2&gt;
&lt;p&gt;Many database settings can be tweaked to speed Galaxy. Some are:&lt;/p&gt;
&lt;p&gt;Reduce connection overhead by using only one connection to the database
per thread:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
database_engine_option_strategy = threadlocal
&lt;/pre&gt;
&lt;p&gt;Large queries or datasets may cause issues, so Postgres database cursors
should be cached:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
database_engine_option_server_side_cursors = True
&lt;/pre&gt;
&lt;p&gt;If plagued by errors of insufficient database pool connections, increase
these:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#database_engine_option_pool_size = 5
#database_engine_option_max_overflow = 10
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="setting-up-a-proxy"&gt;
&lt;h2&gt;Setting up a proxy&lt;/h2&gt;
&lt;p&gt;Galaxy can run off its own internal webserver, but in production it is
far preferable to use a proper server as a proxy. These instructions
assume this is Apache and the server is to be accessed at
&lt;a class="reference external" href="http://fobarbaz.com/galaxy-inst"&gt;http://fobarbaz.com/galaxy-inst&lt;/a&gt;. See
&lt;a class="reference external" href="https://bitbucket.org/galaxy/galaxy-central/wiki/Config/ApacheProxy"&gt;https://bitbucket.org/galaxy/galaxy-central/wiki/Config/ApacheProxy&lt;/a&gt; and
&lt;a class="reference external" href="http://docs.uabgrid.uab.edu/wiki/Galaxy#Apache_and_Postgres_Setup"&gt;http://docs.uabgrid.uab.edu/wiki/Galaxy#Apache_and_Postgres_Setup&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Edit the httpd.conf file:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% vi /etc/httpd/conf/httpd.conf
&lt;/pre&gt;
&lt;p&gt;Rewrite requests on the standard port and the suburl to Galaxy:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;VirtualHost *:80&amp;gt;
ServerName 158.119.147.41
RewriteEngine on
#RewriteLog &amp;quot;/etc/httpd/logs/rewrite_log&amp;quot;
#RewriteLogLevel 9
RewriteRule ^/galaxy$ /galaxy/ [R]
#RewriteRule ^/galaxy/static/style/(.*) /home/galaxy/galaxy_dist/static/june_2007_style/blue/$1 [L]
#RewriteRule ^/galaxy/static/scripts/(.*) /home/galaxy/galaxy_dist/static/scripts/packed/$1 [L]
#RewriteRule ^/galaxy/static/(.*) /home/galaxy/galaxy_dist/static/$1 [L]
#RewriteRule ^/galaxy/favicon.ico /home/galaxy/galaxy_dist/static/favicon.ico [L]
#RewriteRule ^/galaxy/robots.txt /home/galaxy/galaxy_dist/static/robots.txt [L]
RewriteRule ^/galaxy(.*) http://localhost:7070$1 [P] &amp;lt;/VirtualHost&amp;gt;
&lt;/pre&gt;
&lt;p&gt;RewriteLog commands can be used to debug the rewrites. See below for
other commented out lines.&lt;/p&gt;
&lt;p&gt;Restart the apache server:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% /etc/init.d/httpd restart
&lt;/pre&gt;
&lt;p&gt;Ideally you'd like to serve static content (images, style sheets etc.)
straight through Apache to take the load off Galaxy. The commented lines
above show failed attempts to do so. The error seems to be outside of
Galaxy in Apache and results in none of the static content showing up
and the error log shows “(13) permission denied” errors. Things tried to
diagnose and correct this:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Logged the rewrite calls to see they rewrite to the correct paths for the static content&lt;/li&gt;
&lt;li&gt;Checked the proxy-filter and filter-with declarations&lt;/li&gt;
&lt;li&gt;Checked the unix permissions on the static dir&lt;/li&gt;
&lt;li&gt;Tested for non-existent or incorrect paths (which generate a different error)&lt;/li&gt;
&lt;li&gt;Inserted directory declarations to “Allow from all” for the static dir&lt;/li&gt;
&lt;li&gt;Checked for and tried .htaccess files&lt;/li&gt;
&lt;li&gt;Checked SELinux is disabled&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="branding"&gt;
&lt;h2&gt;Branding&lt;/h2&gt;
&lt;p&gt;In universe_wsgi.ini, edit the name of the site:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
brand = HPA Bioinformatics
&lt;/pre&gt;
&lt;p&gt;and url linked to by the logo:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
logo_url = http://www.hpa-bioinfotools.org.uk
&lt;/pre&gt;
&lt;p&gt;and the &amp;quot;email comments&amp;quot; address:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
bugs_email = mailto:paul-michael.agapow&amp;#64;hpa.org.uk
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="running-galaxy"&gt;
&lt;h2&gt;Running Galaxy&lt;/h2&gt;
&lt;p&gt;You can run Galaxy as a detached daemon:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% sh ./run.sh --daemon % sh ./run.sh --stop-daemon % sh ./run.sh --status % sh ./run.sh --monitor-restart # restart if stopped
&lt;/pre&gt;
&lt;p&gt;Create a startup (init) script:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% vi /etc/init.d/galaxy
&lt;/pre&gt;
&lt;p&gt;and write it as something like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#!/bin/bash
#
# /etc/rc.d/init.d/galaxy
#
# Manages the Galaxy webserver
# Based on http://www.sensi.org/~alec/unix/redhat/sysvinit.html
#
# chkconfig: 2345 80 20
# description: Manages the Galaxy webserver

# The chkconfig is levels, strat priority, stop priority. Last two should add to 100.
# You get an error/failure if you try to restrat a stopped service.

# Source function library.
. /etc/rc.d/init.d/functions

GALAXY_USER=galaxy
GALAXY_DIST_HOME=/home/galaxy/galaxy_dist
GALAXY_RUN=&amp;quot;${GALAXY_DIST_HOME}/run.sh&amp;quot;
GALAXY_PID=&amp;quot;${GALAXY_DIST_HOME}/paster.pid&amp;quot;

case &amp;quot;$1&amp;quot; in
start)
echo -n &amp;quot;Starting galaxy services: &amp;quot;
daemon --user $GALAXY_USER &amp;quot;${GALAXY_RUN} --daemon --pid-file=${GALAXY_PID}&amp;quot;
touch /var/lock/subsys/galaxy
;;
stop)
echo -n &amp;quot;Shutting down galaxy services: &amp;quot;
daemon --user $GALAXY_USER &amp;quot;${GALAXY_RUN} --stop-daemon&amp;quot;
rm -f /var/lock/subsys/galaxy
;;
status)
daemon --user galaxy &amp;quot;${GALAXY_RUN} --status&amp;quot;
;;
restart)
$0 stop; $0 start
;;
reload)
$0 stop; $0 start
;;
*)
echo &amp;quot;Usage: galaxy {start|stop|status|reload|restart&amp;quot;
exit 1
;;
esac
&lt;/pre&gt;
&lt;p&gt;Set the permissions as 755. Check the owner:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% chmod 755 /etc/init.d/galaxy
% ls -la /etc/init.d/galaxy
&lt;/pre&gt;
&lt;p&gt;Add to the system services and check:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% /sbin/chkconfig --add galaxy
% /sbin/chkconfig --list galaxy
&lt;/pre&gt;
&lt;p&gt;Start the service with:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% /etc/init.d/galaxy start
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="misc"&gt;
&lt;h2&gt;Misc&lt;/h2&gt;
&lt;p&gt;Set Galaxy to use a local area as temporary storage:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% vi ~/.bash_profile
&lt;/pre&gt;
&lt;p&gt;then:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
TEMP=$HOME/galaxy_dist/database/tmp export TEMP
&lt;/pre&gt;
&lt;p&gt;Don't forget:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
% source ~/.bash_profile
&lt;/pre&gt;
&lt;p&gt;The front page can be customized by editing static/welcome.html. You
should at least edit out the &amp;quot;customize this page&amp;quot; message ...&lt;/p&gt;
&lt;p&gt;Other style customizations are possible. Note that some may be cached by
the system and take some time to show up.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="notes"&gt;
&lt;h2&gt;Notes&lt;/h2&gt;
&lt;p&gt;Some documentation refers to your installation dir as &amp;quot;galaxy_dist&amp;quot;,
others as &amp;quot;galaxy-dist&amp;quot;. Look out for this causing errors.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="also-see"&gt;
&lt;h2&gt;Also see&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://bitbucket.org/galaxy/galaxy-central/wiki/Config/ProductionServer"&gt;https://bitbucket.org/galaxy/galaxy-central/wiki/Config/ProductionServer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://docs.uabgrid.uab.edu/wiki/Galaxy"&gt;http://docs.uabgrid.uab.edu/wiki/Galaxy&lt;/a&gt; for NGS setup&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="computational biology"></category><category term="galaxy"></category></entry><entry><title>Parsing Dendroscope nodes</title><link href="http://www.agapow.net/science/computational-biology/tools/parsing-dendroscope-nodes/" rel="alternate"></link><published>2007-01-01T12:00:00+00:00</published><updated>2007-01-01T12:00:00+00:00</updated><author><name>Paul Agapow</name></author><id>tag:www.agapow.net,2007-01-01:/science/computational-biology/tools/parsing-dendroscope-nodes/</id><summary type="html">&lt;p&gt;For when you have to do lots to a big tree.&lt;/p&gt;
&lt;p&gt;Previously, I showed how Dendroscope files can be easily manipulated
with brute-force regex, so you can right scripts to color a mass of
nodes, rather than having to format them one-by-one in the GUI. However,
more complex manipulations require …&lt;/p&gt;</summary><content type="html">&lt;p&gt;For when you have to do lots to a big tree.&lt;/p&gt;
&lt;p&gt;Previously, I showed how Dendroscope files can be easily manipulated
with brute-force regex, so you can right scripts to color a mass of
nodes, rather than having to format them one-by-one in the GUI. However,
more complex manipulations require more powerful approaches. Here is a
more systematic way of parsing - and manipulating - Dendroscope nodes.&lt;/p&gt;
&lt;p&gt;Each node occupies one line and looks like a named set of key-value
pairs:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
137: x=-6.9873 y=3.4021 lc=0 0 0 lb='A_ENG_303_2009'
&lt;/pre&gt;
&lt;p&gt;There's at least a dozen possible keys, all cryptically named. You can
work out what they do by editing a tree in the GUI and seeing what
changes in the file. The good news is that the keys can appear in any
order, and are consistently separated by spaces. The bad news is that
values can be integers, floats, triplets of integers (for colors) or
quoted strings. So with a little regex magic, we can make a class to
parse these strings and stuff them in a hash-like structure:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# Store node information in a handy format
class DendroNodeInfo &amp;lt; Hash
        # Parses a line like &amp;quot;x=-6.9873343E-4 ... lc=0 0 0 lb='A_ENG_303_2009'&amp;quot;
        def self.from_field_str(fld_str)
                info = self.new()
                fld_str.scan(/(w+)=(d+ d+ d+|'[^']\*'|S+)/) { |m| info[m[0]] = m[1]
                        } return info end # Returns an appropriately formatted info string # def
                        to_field_str()
                        # order isn't critical but we do this for neatness
                        ordered_fields = %w[nh nw fg sh x y lx ly ll la lv lc lb] all_fields =
                        (keys - ordered_fields) + ordered_fields pairs =[] all_fields.each {
                        |k| if has_key?(k) pairs &amp;lt;&amp;lt; [k, fetch(k)] end }
                pair_strs = pairs.each() { |p|
                        &amp;quot;#{p[0]}=#{p[1]}&amp;quot;
                }
                return pair_strs.join(' ')
        end
end
&lt;/pre&gt;
&lt;p&gt;Users should feed the field string to the class method from_field_str:&lt;/p&gt;
&lt;blockquote&gt;
field_str = &amp;quot;x=-6.9873 y=3.4021 lc=0 0 0 lb='A_ENG_303_2009'&amp;quot;
fields = DendroNodeInfo.from_field_str(field_str)&lt;/blockquote&gt;
&lt;p&gt;which can then be manipulated:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
fields[&amp;quot;lc&amp;quot;] = &amp;quot;255 50 120&amp;quot;
&lt;/pre&gt;
&lt;p&gt;and used to produce a new field string:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
print &amp;quot;135: #{fields.to_field_str()}&amp;quot;
&lt;/pre&gt;
&lt;p&gt;Note that the class copes with new or unrecognised fields. The order
that they are output is set, just so the keys are arranged in a nice
order.&lt;/p&gt;
</content></entry></feed>